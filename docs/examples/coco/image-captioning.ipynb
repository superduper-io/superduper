{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0e37bb",
   "metadata": {},
   "source": [
    "## Image captioning using recurrent language modelling and transfer learning based on CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1b9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.client import the_client\n",
    "\n",
    "docs = the_client.coco.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f8993",
   "metadata": {},
   "source": [
    "In the final modelling part of this tutorial, we show that a radically different type of model can be created\n",
    "but which also leverages the `create_imputation` functionality. This is possible, because we utilize a\n",
    "different loss, target, and also use a model which has a different inference `forward` pass than training\n",
    "`forward` pass. This is a very common occurrence, in AI, especially when doing, for example, autoregressive \n",
    "training.\n",
    "\n",
    "The model we create, will be input an image, and will write out a sentence describing that image in unconstrained English. This task is known as \"captioning\" in AI speak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d1e01",
   "metadata": {},
   "source": [
    "This model will leverage a fixed vocabulary of \"allowed\" words. Let us first create this quickly in the \n",
    "following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4166411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023937702178955078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 77716,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11bd90ac9ab4e35927d426ff23c05f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm \n",
    "import collections\n",
    "import re\n",
    "\n",
    "all_captions = []\n",
    "n = docs.count_documents({'_fold': 'train'})\n",
    "for r in tqdm.tqdm_notebook(docs.find({'_fold': 'train'}, {'captions': 1, '_id': 0}), total=n):\n",
    "    all_captions.extend(r['captions'])\n",
    "    \n",
    "all_captions = [re.sub('[^a-z ]', '', x.lower()).strip() for x in all_captions]\n",
    "words = ' '.join(all_captions).split(' ')\n",
    "counts = dict(collections.Counter(words))\n",
    "vocab = sorted([w for w in counts if counts[w] > 5 and w])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20f424",
   "metadata": {},
   "source": [
    "Now we can create the model - it utilizes a \"tokenizer\" for preprocessing the captioning data.\n",
    "\n",
    "In `examples.models`:\n",
    "\n",
    "```python\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, tokens, max_length=15):\n",
    "        self.tokens = tokens\n",
    "        if '<unk>' not in tokens:\n",
    "            tokens.append('<unk>')\n",
    "        self._set_tokens = set(self.tokens)\n",
    "        self.lookup = dict(zip(self.tokens, range(len(self.tokens))))\n",
    "        self.dictionary = {k: i for i, k in enumerate(tokens)}\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def preprocess(self, sentence):\n",
    "        sentence = re.sub('[^a-z]]', '', sentence.lower()).strip()\n",
    "        words = [x for x in sentence.split(' ') if x]\n",
    "        words = [x if x in self.tokens else '<unk>' for x in words]\n",
    "        words = words[:self.max_length]\n",
    "        tokenized = list(map(self.lookup.__getitem__, words))\n",
    "        tokenized = tokenized + [len(self) + 1 for _ in range(self.max_length - len(words))]\n",
    "        return torch.tensor(tokenized)\n",
    "\n",
    "\n",
    "class ConditionalLM(torch.nn.Module):\n",
    "    def __init__(self, tokenizer, n_hidden=512, max_length=15, n_condition=1024):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_hidden = n_hidden\n",
    "        self.embedding = torch.nn.Embedding(len(self.tokenizer) + 2, self.n_hidden)\n",
    "        self.conditioning_linear = torch.nn.Linear(n_condition, self.n_hidden)\n",
    "        self.rnn = torch.nn.GRU(self.n_hidden, self.n_hidden, batch_first=True)\n",
    "        self.prediction = torch.nn.Linear(self.n_hidden, len(self.tokenizer) + 2)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def preprocess(self, r):\n",
    "        out = {}\n",
    "        if 'caption' in r:\n",
    "            out['caption'] = [len(self.tokenizer)]  + self.tokenizer.preprocess(r['caption']).tolist()[:-1]\n",
    "        else:\n",
    "            out['caption'] = [len(self.tokenizer)]\n",
    "        out['caption'] = torch.tensor(out['caption'])\n",
    "        if 'img' in r:\n",
    "            out['img'] = r['img']\n",
    "        return out\n",
    "\n",
    "    def train_forward(self, r):\n",
    "        input_ = self.embedding(r['caption'])\n",
    "        img_vectors = self.conditioning_linear(r['img']).unsqueeze(0)\n",
    "        rnn_outputs = self.rnn(input_, img_vectors)[0]\n",
    "        return self.prediction(rnn_outputs)\n",
    "\n",
    "    def forward(self, r):\n",
    "        hidden_states = self.conditioning_linear(r['img']).unsqueeze(0)\n",
    "        predictions = \\\n",
    "            torch.zeros(r['caption'].shape[0], self.max_length).to(r['caption'].device).type(torch.long)\n",
    "        predictions[:, 0] = r['caption'][:, 0]\n",
    "        for i in range(self.max_length - 1):\n",
    "            rnn_outputs, hidden_states = self.rnn(self.embedding(predictions[:, i]).unsqueeze(1),\n",
    "                                                  hidden_states)\n",
    "            logits = self.prediction(rnn_outputs)[:, 0, :]\n",
    "            predictions[:, i + 1] = logits.topk(1, dim=1)[1][:, 0].type(torch.long)\n",
    "        return predictions\n",
    "\n",
    "    def postprocess(self, output):\n",
    "        output = output.tolist()\n",
    "        try:\n",
    "            first_end_token = next(x for x in output if x == len(self.tokenizer) + 2)\n",
    "            output = output[:first_end_token]\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        output = [x for x in output if x < len(self.tokenizer)]\n",
    "        return ' '.join(list(map(self.tokenizer.tokens.__getitem__, output)))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d71d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import ConditionalLM, SimpleTokenizer\n",
    "\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "m = ConditionalLM(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d9b26",
   "metadata": {},
   "source": [
    "Let us know create the required models necessary for training this model. One of the models is fairly \n",
    "trivial, only used to create the prediction target for the learning task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a4cd4be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model('conditional_lm', object=m, active=False, features={'img': 'clip'}, key='_base')\n",
    "docs.create_model('captioning_tokenizer', tokenizer, key='caption', active=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f673e70",
   "metadata": {},
   "source": [
    "We'll use a standard autoregressive loss, of the sort used as a matter of course in language modelling tasks.\n",
    "\n",
    "In `examples.losses`:\n",
    "\n",
    "\n",
    "```python\n",
    "def auto_regressive_loss(x, y):\n",
    "    # start token = x.shape[2] - 2, stop_token = x.shape[2] - 1 (by convention)\n",
    "    stop_token = x.shape[2] - 1\n",
    "    x = x.transpose(2, 1)\n",
    "    losses = torch.nn.functional.cross_entropy(x, y, reduce=False)\n",
    "    not_stops = torch.ones_like(losses)\n",
    "    not_stops[:, 1:] = (y[:, :-1] != stop_token).type(torch.long)\n",
    "    normalizing_factors = not_stops.sum(axis=1).unsqueeze(1)\n",
    "    av_loss_per_row = (losses * not_stops).div(normalizing_factors).sum(axis=1)\n",
    "    return av_loss_per_row.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e501979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.losses import auto_regressive_loss\n",
    "docs.create_loss('autoregressive_loss', auto_regressive_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe8736",
   "metadata": {},
   "source": [
    "Since each record in the database has several captions per image, we'll need to use a so-called \"splitter\", to \n",
    "align the prediction model and prediction target during training. You can see that the splitter randomly chooses\n",
    "one of the captions to train on for an iteration.\n",
    "\n",
    "In `examples.splitters`:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "\n",
    "def captioning_splitter(r):\n",
    "    index = random.randrange(len(r['captions']))\n",
    "    target = {}\n",
    "    target['caption'] = r['captions'][index]\n",
    "    r['caption'] = r['captions'][index]\n",
    "    return r, target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2902496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_id': ObjectId('63f4d31b99e15ed933e61fcd'),\n",
       "  'captions': ['A restaurant has modern wooden tables and chairs.',\n",
       "   'A long restaurant table with rattan rounded back chairs.',\n",
       "   'a long table with a plant on top of it surrounded with wooden chairs ',\n",
       "   'A long table with a flower arrangement in the middle for meetings',\n",
       "   'A table is adorned with wooden chairs with blue accents.'],\n",
       "  'img': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x168>,\n",
       "  '_fold': 'train',\n",
       "  '_outputs': {'img': {'clip': tensor([ 0.0203,  0.0837,  0.0035,  ..., -0.0788,  0.0529, -0.1146]),\n",
       "    'clip_projection': tensor([ 0.0012,  0.1153, -0.0723, -0.0510,  0.1098, -0.1030,  0.0434, -0.1056,\n",
       "            -0.1817, -0.0636, -0.1248, -0.0559,  0.0486,  0.0592,  0.0267,  0.0602,\n",
       "            -0.0153, -0.0122,  0.1966, -0.2138,  0.1524, -0.0079, -0.0866, -0.0067,\n",
       "            -0.1458,  0.2234, -0.0030,  0.0827, -0.0748,  0.0598,  0.0271, -0.0271,\n",
       "             0.0626, -0.0612,  0.0378,  0.1458,  0.0533,  0.1429,  0.0745,  0.0584,\n",
       "             0.0604,  0.0142,  0.0372,  0.1013, -0.0388,  0.1581, -0.0568, -0.1002,\n",
       "            -0.0545, -0.1128]),\n",
       "    'attribute_predictor': ['chairs', 'table', 'room', 'chair', 'living']},\n",
       "   'captions': {'noun_words': ['accents',\n",
       "     'arrangement',\n",
       "     'chairs',\n",
       "     'flower',\n",
       "     'meetings',\n",
       "     'middle',\n",
       "     'plant',\n",
       "     'restaurant',\n",
       "     'table',\n",
       "     'tables',\n",
       "     'top']}},\n",
       "  'caption': 'a long table with a plant on top of it surrounded with wooden chairs '},\n",
       " {'caption': 'a long table with a plant on top of it surrounded with wooden chairs '})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from examples.splitters import captioning_splitter\n",
    "\n",
    "docs.create_splitter('captioning_splitter', captioning_splitter)\n",
    "captioning_splitter(docs.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f82d9",
   "metadata": {},
   "source": [
    "Since we have this new splitter, we need to create a new validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10344946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                   | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading content from retrieved urls\n",
      "found 0 urls\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                            | 1/10 [00:01<00:09,  1.07s/it]\u001b[A\n",
      " 20%|███████████████████████████████▏                                                                                                                            | 2/10 [00:02<00:07,  1.00it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████▊                                                                                                             | 3/10 [00:02<00:06,  1.03it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [00:03<00:05,  1.05it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [00:04<00:04,  1.06it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [00:05<00:03,  1.07it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7/10 [00:06<00:02,  1.08it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 8/10 [00:07<00:01,  1.08it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 9/10 [00:08<00:00,  1.08it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip_projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 13081.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████████████████████▌                                                                                                                          | 100/500 [00:14<00:56,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████████▏                                                                                                                         | 102/500 [00:14<00:56,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading content from retrieved urls\n",
      "found 0 urls\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                            | 1/10 [00:00<00:08,  1.07it/s]\u001b[A\n",
      " 20%|███████████████████████████████▏                                                                                                                            | 2/10 [00:01<00:07,  1.09it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████▊                                                                                                             | 3/10 [00:02<00:06,  1.09it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [00:03<00:05,  1.09it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [00:04<00:04,  1.08it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [00:05<00:03,  1.09it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7/10 [00:06<00:02,  1.07it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 8/10 [00:07<00:01,  1.07it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 9/10 [00:08<00:00,  1.07it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip_projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5177.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████████▏                                                                                           | 200/500 [00:26<00:38,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "downloading content from retrieved urls\n",
      "found 0 urls\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                            | 1/10 [00:00<00:08,  1.06it/s]\u001b[A\n",
      " 20%|███████████████████████████████▏                                                                                                                            | 2/10 [00:01<00:07,  1.05it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████▊                                                                                                             | 3/10 [00:02<00:06,  1.07it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [00:03<00:05,  1.08it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [00:04<00:04,  1.08it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [00:05<00:03,  1.08it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7/10 [00:06<00:02,  1.09it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 8/10 [00:07<00:01,  1.08it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 9/10 [00:08<00:00,  1.08it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip_projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 11748.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 300/500 [00:37<00:24,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "downloading content from retrieved urls\n",
      "found 0 urls\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                            | 1/10 [00:00<00:08,  1.03it/s]\u001b[A\n",
      " 20%|███████████████████████████████▏                                                                                                                            | 2/10 [00:01<00:07,  1.04it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████▊                                                                                                             | 3/10 [00:02<00:06,  1.05it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [00:03<00:05,  1.06it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [00:04<00:04,  1.06it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [00:05<00:03,  1.06it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7/10 [00:06<00:02,  1.06it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 8/10 [00:07<00:01,  1.07it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 9/10 [00:08<00:00,  1.07it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip_projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10012.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 400/500 [00:49<00:12,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "downloading content from retrieved urls\n",
      "found 0 urls\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                            | 1/10 [00:00<00:08,  1.04it/s]\u001b[A\n",
      " 20%|███████████████████████████████▏                                                                                                                            | 2/10 [00:01<00:07,  1.07it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████▊                                                                                                             | 3/10 [00:02<00:06,  1.08it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████▍                                                                                             | 4/10 [00:03<00:05,  1.09it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 5/10 [00:04<00:04,  1.07it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 6/10 [00:05<00:03,  1.09it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 7/10 [00:06<00:02,  1.09it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 8/10 [00:07<00:01,  1.08it/s]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 9/10 [00:08<00:00,  1.08it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip_projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10466.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n",
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:01<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk writing...\n",
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs.create_validation_set('captioning', splitter=docs.splitters['captioning_splitter'],\n",
    "                           sample_size=500, chunk_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b8c3c",
   "metadata": {},
   "source": [
    "Now we're ready to start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa5079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_imputation(\n",
    "    'image_captioner',\n",
    "    model='conditional_lm',\n",
    "    loss='autoregressive_loss',\n",
    "    target='captioning_tokenizer',\n",
    "    splitter='captioning_splitter',\n",
    "    validation_sets=['captioning'],\n",
    "    batch_size=50,\n",
    "    lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81fbab",
   "metadata": {},
   "source": [
    "Let's test the model on a sample data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4784f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_docs = list(docs.find().limit(20))\n",
    "images = list(docs.find({}, {'img': 1}).limit(100))\n",
    "\n",
    "results = docs.apply_model('conditional_lm', test_docs, batch_size=10)\n",
    "\n",
    "for r, res in zip(images, results):\n",
    "    display(r['img'])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de1319",
   "metadata": {},
   "source": [
    "Now we have trained and evaluated several models of various types. This includes multiple interacting models with mutual dependencies. In the case of our own efficient semantic search, and also the attribute predictor, these models are downstream of the image clip model, in the sense that at inference time, clip must be present in order to be able to execute these models. In the case of attribute prediction, the training task was downstream from the \n",
    "spacy pipeline for part-of-speech tagging; these tags were used to produce targets for training. However at run-time, the spacy pipeline won't be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74500ec3",
   "metadata": {},
   "source": [
    "The models which we've added and trained are now ready to go, and when new data is added or updated to the collection, they will automatically process this data, and insert the model outputs into the collection documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15fe60",
   "metadata": {},
   "source": [
    "Here is the complete set of models which exist in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6eedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1fe7c",
   "metadata": {},
   "source": [
    "Not all of these respond to incoming data, for that we need to specify the `active` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f54582",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models(active=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689545a",
   "metadata": {},
   "source": [
    "We can see that these models have processed all documents and their outputs saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

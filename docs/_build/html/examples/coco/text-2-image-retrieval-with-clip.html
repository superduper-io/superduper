<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text-2-Image document retrieval using pretrained CLIP &mdash; SuperDuperDB  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Bespoke retrieval based on CLIP embedding vectors" href="bespoke-retriever-using-clip-embeddings.html" />
    <link rel="prev" title="Inserting and getting data" href="inserting-and-getting-data.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            SuperDuperDB
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Quick  start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../minimum_working_example.html">Minimum working example</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials and examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../mnist/index.html">MNIST Dataset</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">CoCo (Common Objects in Context) Dataset</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="setup-and-installation.html">Setup and installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="inserting-and-getting-data.html">Inserting and getting data</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Text-2-Image document retrieval using pretrained CLIP</a></li>
<li class="toctree-l3"><a class="reference internal" href="bespoke-retriever-using-clip-embeddings.html">Bespoke retrieval based on CLIP embedding vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="attribute-prediction.html">Attribute prediction using “imputations” with preparation in SpaCy</a></li>
<li class="toctree-l3"><a class="reference internal" href="image-captioning.html">Image captioning using recurrent language modelling and transfer learning based on CLIP</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../concepts.html">SuperDuperDB Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../types.html">Types in SuperDuperDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../content.html">Adding interesting content to SuperDuperDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Models - an extension of PyTorch models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../watchers.html">Watchers in SuperDuperDB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../semantic_indexes.html">Semantic indexes for flexibly searching data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../imputations.html">Imputations for filling in data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs.html">Jobs - scheduling of training and model outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cluster.html">Setting up a SuperDuperDB cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../full_usage.html">Full usage</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">SuperDuperDB</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Tutorials and examples</a></li>
          <li class="breadcrumb-item"><a href="index.html">CoCo (Common Objects in Context) Dataset</a></li>
      <li class="breadcrumb-item active">Text-2-Image document retrieval using pretrained CLIP</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/examples/coco/text-2-image-retrieval-with-clip.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Text-2-Image-document-retrieval-using-pretrained-CLIP">
<h1>Text-2-Image document retrieval using pretrained CLIP<a class="headerlink" href="#Text-2-Image-document-retrieval-using-pretrained-CLIP" title="Permalink to this heading"></a></h1>
<p>In the first AI task which we implement for this collection of data, we’ll be setting up a model to retrieve relevant images using provided text. We’ll use the data from the <code class="docutils literal notranslate"><span class="pre">captions</span></code> field to retrieve the <code class="docutils literal notranslate"><span class="pre">img</span></code> field.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from superduperdb.client import the_client

docs = the_client.coco.documents
</pre></div>
</div>
</div>
<p>Let’s start adding a model to the collection. A nice open source model to test text-2-image retrieval is <a class="reference external" href="https://openai.com/blog/clip/">CLIP</a> which understands images and texts and embeds these in a common vector space.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pygmentize examples/coco/clip.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-bold" style="color: rgb(0,128,0)">import</span> <span class="ansi-bold" style="color: rgb(0,0,255)">torch</span>
<span class="ansi-bold" style="color: rgb(0,128,0)">from</span> <span class="ansi-bold" style="color: rgb(0,0,255)">clip</span> <span class="ansi-bold" style="color: rgb(0,128,0)">import</span> load <span class="ansi-bold" style="color: rgb(0,128,0)">as</span> load_clip, tokenize <span class="ansi-bold" style="color: rgb(0,128,0)">as</span> clip_tokenize


<span class="ansi-bold" style="color: rgb(0,128,0)">class</span> <span class="ansi-bold" style="color: rgb(0,0,255)">CLIP</span>(torch<span style="color: rgb(102,102,102)">.</span>nn<span style="color: rgb(102,102,102)">.</span>Module):
    <span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">__init__</span>(<span style="color: rgb(0,128,0)">self</span>, name):
        <span style="color: rgb(0,128,0)">super</span>()<span style="color: rgb(102,102,102)">.</span><span style="color: rgb(0,0,255)">__init__</span>()
        <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>model, <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>image_preprocess <span style="color: rgb(102,102,102)">=</span> load_clip(name)

    <span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">preprocess</span>(<span style="color: rgb(0,128,0)">self</span>, r):
        <span class="ansi-bold" style="color: rgb(0,128,0)">if</span> <span style="color: rgb(0,128,0)">isinstance</span>(r, <span style="color: rgb(0,128,0)">str</span>):
            <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> clip_tokenize(r, truncate<span style="color: rgb(102,102,102)">=</span><span class="ansi-bold" style="color: rgb(0,128,0)">True</span>)[<span style="color: rgb(102,102,102)">0</span>, :]
        <span class="ansi-bold" style="color: rgb(0,128,0)">elif</span> <span style="color: rgb(0,128,0)">isinstance</span>(r, <span style="color: rgb(0,128,0)">list</span>) <span class="ansi-bold" style="color: rgb(170,34,255)">and</span> <span style="color: rgb(0,128,0)">isinstance</span>(r[<span style="color: rgb(102,102,102)">0</span>], <span style="color: rgb(0,128,0)">str</span>):
            <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> clip_tokenize(<span style="color: rgb(186,33,33)">&#39;</span><span style="color: rgb(186,33,33)"> </span><span style="color: rgb(186,33,33)">&#39;</span><span style="color: rgb(102,102,102)">.</span>join(r), truncate<span style="color: rgb(102,102,102)">=</span><span class="ansi-bold" style="color: rgb(0,128,0)">True</span>)[<span style="color: rgb(102,102,102)">0</span>, :]
        <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>image_preprocess(r)

    <span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">forward</span>(<span style="color: rgb(0,128,0)">self</span>, r):
        <span class="ansi-bold" style="color: rgb(0,128,0)">if</span> <span style="color: rgb(0,128,0)">len</span>(r<span style="color: rgb(102,102,102)">.</span>shape) <span style="color: rgb(102,102,102)">==</span> <span style="color: rgb(102,102,102)">2</span>:
            <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>model<span style="color: rgb(102,102,102)">.</span>encode_text(r)
        <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>model<span style="color: rgb(102,102,102)">.</span>encode_image(r)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from examples.coco.clip import CLIP

docs.create_model(
    name=&#39;clip&#39;,
    object=CLIP(&#39;RN50&#39;),
    type=&#39;float_tensor&#39;,
)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs.create_watcher(model=&#39;clip&#39;, key=&#39;img&#39;, filter_={}, loader_kwargs={&#39;batch_size&#39;: 10, &#39;num_workers&#39;: 0},
                    verbose=True)
</pre></div>
</div>
</div>
<p>We’ll also create a measure which tests how similar to each other two outputs might be. Since CLIP was trained with cosine-similarity we’ll use that here too.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pygmentize examples/coco/measures.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">dot</span>(x, y):
    <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> x<span style="color: rgb(102,102,102)">.</span>matmul(y<span style="color: rgb(102,102,102)">.</span>T)


<span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">css</span>(x, y):
    x <span style="color: rgb(102,102,102)">=</span> x<span style="color: rgb(102,102,102)">.</span>div(x<span style="color: rgb(102,102,102)">.</span>norm(dim<span style="color: rgb(102,102,102)">=</span><span style="color: rgb(102,102,102)">1</span>)[:, <span class="ansi-bold" style="color: rgb(0,128,0)">None</span>])
    y <span style="color: rgb(102,102,102)">=</span> y<span style="color: rgb(102,102,102)">.</span>div(y<span style="color: rgb(102,102,102)">.</span>norm(dim<span style="color: rgb(102,102,102)">=</span><span style="color: rgb(102,102,102)">1</span>)[:, <span class="ansi-bold" style="color: rgb(0,128,0)">None</span>])
    <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> dot(x, y)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from examples.coco.measures import css

docs.create_measure(&#39;css&#39;, css)
</pre></div>
</div>
</div>
<p>In order to be able to measure performance on the validation set, we’ll add a <strong>metric</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pygmentize examples/coco/recall.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-bold" style="color: rgb(0,128,0)">class</span> <span class="ansi-bold" style="color: rgb(0,0,255)">RatK</span>:
    <span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">__init__</span>(<span style="color: rgb(0,128,0)">self</span>, k):
        <span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>k <span style="color: rgb(102,102,102)">=</span> k

    <span class="ansi-bold" style="color: rgb(0,128,0)">def</span> <span style="color: rgb(0,0,255)">__call__</span>(<span style="color: rgb(0,128,0)">self</span>, x, y):
        <span class="ansi-bold" style="color: rgb(0,128,0)">return</span> y <span class="ansi-bold" style="color: rgb(170,34,255)">in</span> x[:<span style="color: rgb(0,128,0)">self</span><span style="color: rgb(102,102,102)">.</span>k]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from examples.coco.recall import RatK

docs.create_metric(&#39;p_at_10&#39;, RatK(10))
</pre></div>
</div>
</div>
<p>Now we’re ready to go to add a <strong>semantic index</strong>. This is a tuple of models, one of which is activated in order to populate the collection with vectors. The idea is that any of the models in the <strong>semantic index</strong> can be used to query the collection using nearest neighbour lookup based on the <strong>measure</strong> chosen.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from examples.coco.clip import CLIP

docs.create_semantic_index(
    &#39;clip&#39;,
    models=[&#39;clip&#39;, &#39;clip&#39;],
    keys=[&#39;img&#39;, &#39;captions&#39;],
    measure=&#39;css&#39;,
    metrics=[&#39;p_at_10&#39;],
)
</pre></div>
</div>
</div>
<p>Now the semantic index has been created, we can search through the data using that index.</p>
<p>We can see that we can get nice meaningful retrievals using the CLIP model from short descriptive pieces of text. This is very useful, since the model is now deployed to the database, listening for incoming queries.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from IPython.display import display

docs.semantic_index = &#39;clip&#39;
r = docs.find_one()

print(&#39;QUERY 1&#39;)
# example using item id directly
for r in docs.find(like={&#39;_id&#39;: r[&#39;_id&#39;]}, n=10):
    display(r[&#39;img&#39;])

print(&#39;QUERY 2&#39;)
# or a query which is interpreted by the CLIP model
for r in docs.find(like={&#39;captions&#39;: [&#39;Dog catches a frisbee&#39;]}, n=10):
    display(r[&#39;img&#39;])
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
QUERY 1
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "db571f9524a34c1ea99186b33b1e7e97", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
loading hashes: &#34;clip&#34;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_3.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_4.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_5.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_6.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_7.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_7.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_8.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_8.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_9.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_9.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_10.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_10.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_11.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_11.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_12.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_12.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
QUERY 2
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_14.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_14.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_15.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_15.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_16.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_16.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_17.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_17.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_18.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_18.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_19.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_19.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_20.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_20.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_21.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_21.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_22.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_22.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_23.png" src="../../_images/examples_coco_text-2-image-retrieval-with-clip_16_23.png" />
</div>
</div>
<p>Let’s now evaluate the quality of this semantic index</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs.create_validation_set(
    &#39;text2image_retrieval&#39;,
    filter={},
    splitter=lambda x: ({&#39;img&#39;: x[&#39;img&#39;]}, {&#39;captions&#39;: [x[&#39;captions&#39;][0]]}),
    sample_size=1000,
)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3358830ee20e4f43adeef18085b968f4", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
downloading content from retrieved urls
found 0 urls
computing chunk (1/1)
finding documents under filter
done.
processing with clip
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fae09d8ccd754265bd1b297d8f15fa6c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bulk writing...
done.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs.validate_semantic_index(&#39;clip&#39;, [&#39;text2image_retrieval&#39;], [&#39;p_at_10&#39;])
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9e1d182693fc4a9d8b546eada82f0335", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "71025071287a40e7a2567ac7d28f7286", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
loading hashes: &#34;clip&#34;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>docs[&#39;_objects&#39;].find_one({&#39;varieties&#39;: &#39;semantic_index&#39;, &#39;name&#39;: &#39;clip&#39;})[&#39;final_metrics&#39;]
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;text2image_retrieval&#39;: {&#39;p_at_10&#39;: 0.859}}
</pre></div></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="inserting-and-getting-data.html" class="btn btn-neutral float-left" title="Inserting and getting data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bespoke-retriever-using-clip-embeddings.html" class="btn btn-neutral float-right" title="Bespoke retrieval based on CLIP embedding vectors" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Duncan Blythe duncan@superduperdb.com.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d92f42b-7160-4965-a0ef-5e4ce46bd529",
   "metadata": {},
   "source": [
    "# Fine tune LLM on database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock:///test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get LLM Finetuning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5169e-ab2f-4eac-bd3f-30fd845f2a1b",
   "metadata": {},
   "source": [
    "The following are examples of training data in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37c7dc-390a-428b-916a-09d191678cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "from datasets import load_dataset\n",
    "from superduper.base.document import Document\n",
    "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "train_documents = [\n",
    "    Document({**example, \"_fold\": \"train\"})\n",
    "    for example in train_dataset\n",
    "]\n",
    "eval_documents = [\n",
    "    Document({**example, \"_fold\": \"valid\"})\n",
    "    for example in eval_dataset\n",
    "]\n",
    "\n",
    "datas = train_documents + eval_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7902bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Prompt-Response>\n",
    "from datasets import load_dataset\n",
    "\n",
    "from superduper.base.document import Document\n",
    "dataset_name = \"mosaicml/instruct-v3\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "train_documents = [\n",
    "    Document({**example, \"_fold\": \"train\"})\n",
    "    for example in train_dataset\n",
    "]\n",
    "eval_documents = [\n",
    "    Document({**example, \"_fold\": \"valid\"})\n",
    "    for example in eval_dataset\n",
    "]\n",
    "\n",
    "datas = train_documents + eval_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c05195-3372-48c2-95c8-5ef51d65bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Chat>\n",
    "from datasets import load_dataset\n",
    "from superduper.base.document import Document\n",
    "dataset_name = \"philschmid/dolly-15k-oai-style\"\n",
    "dataset = load_dataset(dataset_name)['train'].train_test_split(0.9)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "train_documents = [\n",
    "    Document({**example, \"_fold\": \"train\"})\n",
    "    for example in train_dataset\n",
    "]\n",
    "eval_documents = [\n",
    "    Document({**example, \"_fold\": \"valid\"})\n",
    "    for example in eval_dataset\n",
    "]\n",
    "\n",
    "datas = train_documents + eval_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a4705-e7d6-4244-9150-bfa8372f85ba",
   "metadata": {},
   "source": [
    "We can define different training parameters to handle this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824212e-0c4f-4b93-b3fa-4d2a105fc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "# Function for transformation after extracting data from the database\n",
    "transform = None\n",
    "key = ('text')\n",
    "training_kwargs=dict(dataset_text_field=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d583a-a0f3-432d-b737-356ab3cd4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Prompt-Response>\n",
    "# Function for transformation after extracting data from the database\n",
    "def transform(prompt, response):\n",
    "    return {'text': prompt + response + \"</s>\"}\n",
    "\n",
    "key = ('prompt', 'response')\n",
    "training_kwargs=dict(dataset_text_field=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cdb09-d060-4d45-bcf3-cae92fb22ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Chat>\n",
    "# Function for transformation after extracting data from the database\n",
    "transform = None\n",
    "\n",
    "key = ('messages')\n",
    "training_kwargs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a1ec0-bf28-4b59-8be1-e7bcfd4eeccc",
   "metadata": {},
   "source": [
    "Example input_text and output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8c36c-97f8-40f4-8b8d-736d55352138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "data = datas[0]\n",
    "input_text, output_text = data[\"text\"].rsplit(\"### Assistant: \", maxsplit=1)\n",
    "input_text += \"### Assistant: \"\n",
    "output_text = output_text.rsplit(\"### Human:\")[0]\n",
    "print(\"Input: --------------\")\n",
    "print(input_text)\n",
    "print(\"Response: --------------\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef4a4-478d-43f1-8f40-b3b1e5923639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Prompt-Response>\n",
    "data = datas[0]\n",
    "input_text = data[\"prompt\"]\n",
    "output_text = data[\"response\"]\n",
    "print(\"Input: --------------\")\n",
    "print(input_text)\n",
    "print(\"Response: --------------\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e8612-9c58-4688-a3af-8c408f9b3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Chat>\n",
    "data = datas[0]\n",
    "messages = data[\"messages\"]\n",
    "input_text = messages[:-1]\n",
    "output_text = messages[-1][\"content\"]\n",
    "print(\"Input: --------------\")\n",
    "print(input_text)\n",
    "print(\"Response: --------------\")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bc0ba",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Document\n",
    "\n",
    "table_or_collection = db['docs']\n",
    "\n",
    "ids = db.execute(table_or_collection.insert([Document(data) for data in datas]))\n",
    "select = table_or_collection.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46a283-4fef-40d8-8df4-7023479ec2dd",
   "metadata": {},
   "source": [
    "## Select a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0e1e-22ea-4af3-b914-1a3eed23a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "model_kwargs = dict()\n",
    "tokenizer_kwargs = dict()\n",
    "\n",
    "# or \n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# token = \"hf_xxxx\"\n",
    "# model_kwargs = dict(token=token)\n",
    "# tokenizer_kwargs = dict(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf339d2-6eaa-4a90-8718-6d6e6120c400",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build A Trainable LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c2662-ce55-4767-8e3d-ef3901fd31ee",
   "metadata": {},
   "source": [
    "**Create an LLM Trainer for training**\n",
    "\n",
    "The parameters of this LLM Trainer are basically the same as `transformers.TrainingArguments`, but some additional parameters have been added for easier training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deed34b-189c-4662-8972-aed92718225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_transformers import LLM, LLMTrainer\n",
    "\n",
    "trainer = LLMTrainer(\n",
    "    identifier=\"llm-finetune-trainer\",\n",
    "    output_dir=\"output/finetune\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_seq_length=512,\n",
    "    key=key,\n",
    "    select=select,\n",
    "    transform=transform,\n",
    "    training_kwargs=training_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bc70f-00e0-4a13-a438-658146efd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Lora>\n",
    "trainer.use_lora = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab34bc-999c-4300-aa47-d40a78536d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: QLora>\n",
    "trainer.use_lora = True\n",
    "trainer.bits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392ffec-80aa-4be7-b40f-665c2803e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Deepspeed>\n",
    "!pip install deepspeed\n",
    "deepspeed = {\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "    },\n",
    "}\n",
    "trainer.use_lora = True\n",
    "trainer.bits = 4\n",
    "trainer.deepspeed = deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414fc61-2466-4bf6-8ea2-460524806880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Multi-GPUS>\n",
    "trainer.use_lora = True\n",
    "trainer.bits = 4\n",
    "trainer.num_gpus = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370f6c8-ce2f-443e-ae89-a4e95c4375a8",
   "metadata": {},
   "source": [
    "Create a trainable LLM model and add it to the database, then the training task will run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c1ebb-345e-4030-9f9e-96099f53664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    identifier=\"llm\",\n",
    "    model_name_or_path=model_name,\n",
    "    trainer=trainer,\n",
    "    model_kwargs=model_kwargs,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    ")\n",
    "\n",
    "db.apply(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd846d-aa81-456f-b2ea-fc2d230a41a2",
   "metadata": {},
   "source": [
    "## Load the trained model\n",
    "There are two methods to load a trained model:\n",
    "\n",
    "- **Load the model directly**: This will load the model with the best metrics (if the transformers' best model save strategy is set) or the last version of the model.\n",
    "- **Use a specified checkpoint**: This method downloads the specified checkpoint, then initializes the base model, and finally merges the checkpoint with the base model. This approach supports custom operations such as resetting flash_attentions, model quantization, etc., during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e1a0d-c760-4a01-b4bf-c6e83296ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Load Trained Model Directly>\n",
    "llm = db.load(\"model\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fbf38-8f2b-4c3f-9ae8-c184001b4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Use a specified checkpoint>\n",
    "from superduper_transformers import LLM\n",
    "\n",
    "experiment_id = db.show(\"checkpoint\")[-1]\n",
    "version = None # None means the last checkpoint\n",
    "checkpoint = db.load(\"checkpoint\", experiment_id, version=version)\n",
    "llm = LLM(\n",
    "    identifier=\"llm\",\n",
    "    model_name_or_path=model_name,\n",
    "    adapter_id=checkpoint,\n",
    "    model_kwargs=dict(load_in_4bit=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8933b-723d-481c-9d6e-dff14d256377",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "llm.predict(input_text, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77eb56-5aa4-4d5a-a285-6724c936bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template\n",
    "\n",
    "t = Template('llm-finetune', template=llm, substitutions={'docs': 'collection', model_name: 'model_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e57ff-6355-4685-93de-ff6f9ad0b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbab9c35-9c81-4b6b-838a-569dda0febe3",
   "metadata": {},
   "source": [
    "# PDF RAG\n",
    "\n",
    "This is a PDF-based RAG application. While answering questions, it accesses relevant information from the PDF and displays the corresponding paragraphs in the form of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77615ed-ca3f-4e91-b953-c4fead5ac436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "APPLY = False\n",
    "EAGER = False\n",
    "COLLECTION_NAME = '<var:table_name>' if not APPLY else 'sample_pdf_rag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e55ddd-45db-493f-8cc0-26ba2959160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import superduper, CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52e7cb0-a612-4c9d-85ec-9e95dd8ce8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Dec-04 13:22:50.01\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.misc.plugins\u001b[0m:\u001b[36m13  \u001b[0m | \u001b[1mLoading plugin: mongodb\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:50.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m68  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:50.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.build\u001b[0m:\u001b[36m184 \u001b[0m | \u001b[1mConfiguration: \n",
      " +---------------+------------------+\n",
      "| Configuration |      Value       |\n",
      "+---------------+------------------+\n",
      "|  Data Backend | mongomock://test |\n",
      "+---------------+------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db = superduper('mongomock://test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fdda75-70f6-4907-becd-6bcf916fac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getter():\n",
    "    import subprocess\n",
    "    import os\n",
    "    subprocess.run(['curl', '-O', 'https://superduperdb-public-demo.s3.amazonaws.com/pdfs.zip'])\n",
    "    subprocess.run(['unzip', '-o', 'pdfs.zip'])\n",
    "    subprocess.run(['rm', 'pdfs.zip'])\n",
    "    pdf_folder = \"pdfs\"\n",
    "    pdf_names = [pdf for pdf in os.listdir(pdf_folder) if pdf.endswith(\".pdf\")]\n",
    "    pdf_paths = [os.path.join(pdf_folder, pdf) for pdf in pdf_names]\n",
    "    data = [{\"url\": pdf_path, \"file\": pdf_path} for pdf_path in pdf_paths]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f452d7-017d-4fea-a87d-2ccdb6276b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    data = getter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e4001-84be-453c-902e-a5f0a8934472",
   "metadata": {},
   "source": [
    "## Create a table to store PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0eb6c25-f091-4099-b84c-5bafe55f0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from superduper import Schema, Table\n",
    "from superduper.components.datatype import file\n",
    "\n",
    "schema = Schema(identifier=\"myschema\", fields={'url': 'str', 'file': file})\n",
    "table = Table(identifier=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "if APPLY:\n",
    "    db.apply(table, force=True)\n",
    "    db[COLLECTION_NAME].insert(data).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96bdf0-e664-493b-8fc1-dee711b64e9e",
   "metadata": {},
   "source": [
    "## Split the PDF file into images for later result display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e64072-920c-4e0d-bfa2-424fd0c5c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import ObjectModel, logging\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "\n",
    "def split_image(pdf_path):\n",
    "    logging.info(f\"Splitting images from {pdf_path}\")\n",
    "\n",
    "    image_folders = \"data/pdf-images\"\n",
    "    pdf_name = os.path.basename(pdf_path)\n",
    "    images = convert_from_path(pdf_path)\n",
    "    logging.info(f\"Number of images: {len(images)}\")\n",
    "\n",
    "    image_folder = os.path.join(image_folders, pdf_name)\n",
    "    if not os.path.exists(image_folder):\n",
    "        os.makedirs(image_folder)\n",
    "\n",
    "    data = []\n",
    "    for i, image in enumerate(images):\n",
    "        path = os.path.join(image_folder, f\"{i}.jpg\")\n",
    "        image.save(os.path.join(path))\n",
    "        data.append(path)\n",
    "    return data\n",
    "\n",
    "\n",
    "model_split_image = ObjectModel(\n",
    "    identifier=\"split_image\",\n",
    "    object=split_image,\n",
    "    datatype=file,\n",
    ")\n",
    "\n",
    "listener_split_image = model_split_image.to_listener(\n",
    "    key=\"file\",\n",
    "    select=db[COLLECTION_NAME].find(),\n",
    "    flatten=True,\n",
    ")\n",
    "\n",
    "if EAGER and APPLY:\n",
    "    db.apply(listener_split_image, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14dd50-1c52-4ebe-bdff-3c45e5277882",
   "metadata": {},
   "source": [
    "## Build a chunks model and return chunk results with coordinate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75857086-8c8f-4109-a427-2c2f510cfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sidebars(elements):\n",
    "    import re\n",
    "    from collections import defaultdict\n",
    "\n",
    "    from unstructured.documents.elements import ElementType\n",
    "\n",
    "    if not elements:\n",
    "        return elements\n",
    "    points_groups = defaultdict(list)\n",
    "    min_x = 99999999\n",
    "    max_x = 0\n",
    "    e2index = {e.id: i for i, e in enumerate(elements)}\n",
    "    for e in elements:\n",
    "        x_l = int(e.metadata.coordinates.points[0][0])\n",
    "        x_r = int(e.metadata.coordinates.points[2][0])\n",
    "        points_groups[(x_l, x_r)].append(e)\n",
    "        min_x = min(min_x, x_l)\n",
    "        max_x = max(max_x, x_r)\n",
    "    sidebars_elements = set()\n",
    "    for (x_l, x_r), es in points_groups.items():\n",
    "        first_id = e2index[es[0].id]\n",
    "        last_id = e2index[es[-1].id]\n",
    "        on_left = first_id == 0 and x_l == min_x\n",
    "        on_right = (last_id == len(elements) - 2) and x_r == max_x\n",
    "        loc_match = [on_left, on_right]\n",
    "        total_text = \"\".join(map(str, es))\n",
    "        condiction = [\n",
    "            any(loc_match),\n",
    "            len(es) >= 3,\n",
    "            re.findall(\"^[A-Z\\s\\d,]+$\", total_text),\n",
    "        ]\n",
    "        if not all(condiction):\n",
    "            continue\n",
    "        sidebars_elements.update(map(lambda x: x.id, es))\n",
    "        if on_left:\n",
    "            check_page_num_e = elements[last_id + 1]\n",
    "        else:\n",
    "            check_page_num_e = elements[-1]\n",
    "        if (\n",
    "            check_page_num_e.category == ElementType.UNCATEGORIZED_TEXT\n",
    "            and check_page_num_e.text.strip().isalnum()\n",
    "        ):\n",
    "            sidebars_elements.add(check_page_num_e.id)\n",
    "\n",
    "    elements = [e for e in elements if e.id not in sidebars_elements]\n",
    "    return elements\n",
    "\n",
    "\n",
    "def remove_annotation(elements):\n",
    "    from collections import Counter\n",
    "\n",
    "    from unstructured.documents.elements import ElementType\n",
    "\n",
    "    page_num = max(e.metadata.page_number for e in elements)\n",
    "    un_texts_counter = Counter(\n",
    "        [e.text for e in elements if e.category == ElementType.UNCATEGORIZED_TEXT]\n",
    "    )\n",
    "    rm_text = set()\n",
    "    for text, count in un_texts_counter.items():\n",
    "        if count / page_num >= 0.5:\n",
    "            rm_text.add(text)\n",
    "    elements = [e for e in elements if e.text not in rm_text]\n",
    "    return elements\n",
    "\n",
    "\n",
    "def create_chunk_and_metadatas(page_elements, stride=3, window=10):\n",
    "    page_elements = remove_sidebars(page_elements)\n",
    "    for index, page_element in enumerate(page_elements):\n",
    "        page_element.metadata.num = index\n",
    "    datas = []\n",
    "    for i in range(0, len(page_elements), stride):\n",
    "        windown_elements = page_elements[i : i + window]\n",
    "        chunk = \"\\n\".join([e.text for e in windown_elements])\n",
    "        source_elements = [e.to_dict() for e in windown_elements]\n",
    "        datas.append(\n",
    "            {\n",
    "                \"txt\": chunk,\n",
    "                \"source_elements\": source_elements,\n",
    "            }\n",
    "        )\n",
    "    return datas\n",
    "\n",
    "\n",
    "def get_chunks(pdf):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    from unstructured.documents.coordinates import RelativeCoordinateSystem\n",
    "    from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "    elements = partition_pdf(pdf)\n",
    "    elements = remove_annotation(elements)\n",
    "\n",
    "    pages_elements = defaultdict(list)\n",
    "    for element in elements:\n",
    "        element.convert_coordinates_to_new_system(\n",
    "            RelativeCoordinateSystem(), in_place=True\n",
    "        )\n",
    "        pages_elements[element.metadata.page_number].append(element)\n",
    "\n",
    "    all_chunks_and_links = sum(\n",
    "        [\n",
    "            create_chunk_and_metadatas(page_elements)\n",
    "            for _, page_elements in pages_elements.items()\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    return all_chunks_and_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6e62e1-f94f-4363-b534-8b6f52bf509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.schema import FieldType\n",
    "\n",
    "model_chunk = ObjectModel(\n",
    "    identifier=\"chunk\",\n",
    "    object=get_chunks,\n",
    "    datatype=FieldType(identifier=\"json\")\n",
    ")\n",
    "\n",
    "listener_chunk = model_chunk.to_listener(\n",
    "    key=\"file\",\n",
    "    select=db[COLLECTION_NAME].select(),\n",
    "    flatten=True,\n",
    ")\n",
    "\n",
    "if EAGER and APPLY:\n",
    "    db.apply(listener_chunk, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb48164-2cf8-4253-9b3f-b3ae37a6b5f3",
   "metadata": {},
   "source": [
    "## Build a vector index for vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a27a8e-8982-48ba-975d-c102c26ef6a3",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c90813-08f2-4629-b6fb-e8340e55a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai import OpenAIEmbedding\n",
    "from superduper.components.datatype import Vector\n",
    "openai_embedding = OpenAIEmbedding(identifier='embedding', model='text-embedding-ada-002', datatype=Vector(shape=(1536,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "918d0092-b01f-4881-9870-70ca49bef61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai.model import OpenAIEmbedding\n",
    "from superduper import VectorIndex\n",
    "from superduper.components.datatype import Vector\n",
    "\n",
    "listener_embedding = openai_embedding.to_listener(\n",
    "    key=f\"{listener_chunk.outputs}.txt\",\n",
    "    select=db[listener_chunk.outputs].select(),\n",
    ")\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    identifier=\"vector-index\",\n",
    "    indexing_listener=listener_embedding,\n",
    ")\n",
    "\n",
    "if EAGER and APPLY:\n",
    "    db.apply(vector_index, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f991fc6-b0e2-48bf-9158-49281ceb1c7e",
   "metadata": {},
   "source": [
    "## Create a plugin\n",
    "\n",
    "When applying the processor, saves the plugin in the database, thereby saving the related dependencies as well.\n",
    "\n",
    "The processor will integrate the returned chunks information with the images, and return a visualized image.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c21a46e-3110-4ca9-b250-f4f87c8b144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Plugin\n",
    "from utils import Processor\n",
    "\n",
    "processor = Processor(\n",
    "    identifier=\"processor\",\n",
    "    db=db,\n",
    "    chunk_key=listener_chunk.outputs,\n",
    "    split_image_key=listener_split_image.outputs,\n",
    "    plugins=[Plugin(path=\"./utils.py\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f43f76-a186-4c9f-9b0c-34caefab20d8",
   "metadata": {},
   "source": [
    "## Create a RAG model\n",
    "\n",
    "Create a RAG model to perform retrieval-augmented generation (RAG) and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d45bb3-c400-478f-9c03-1ef9f9364a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Model, logging\n",
    "\n",
    "\n",
    "class Rag(Model):\n",
    "    llm_model: Model\n",
    "    prompt_template: str\n",
    "    processor: None | Model = None\n",
    "    vector_index: VectorIndex\n",
    "\n",
    "    def __post_init__(self, *args, **kwargs):\n",
    "        assert \"{context}\" in self.prompt_template, 'The prompt_template must include \"{context}\"'\n",
    "        assert \"{query}\" in self.prompt_template, 'The prompt_template must include \"{query}\"'\n",
    "        super().__post_init__(*args, **kwargs)\n",
    "\n",
    "    def predict(self, query, top_k=5, format_result=False):\n",
    "        vector_search_out = self.vector_search(query, top_k=top_k)\n",
    "        key = self.vector_index.indexing_listener.key\n",
    "        context = \"\\n\\n---\\n\\n\".join([x[key] for x in vector_search_out])\n",
    "        \n",
    "        prompt = self.prompt_template.format(context=context, query=query)\n",
    "        output = self.llm_model.predict(prompt)\n",
    "        result = {\n",
    "            \"answer\": output,\n",
    "            \"docs\": vector_search_out,\n",
    "        }\n",
    "        if format_result and self.processor:\n",
    "            result[\"images\"] = list(self.processor.predict(\n",
    "                vector_search_out,\n",
    "                match_text=output,\n",
    "            ))\n",
    "        return result\n",
    "\n",
    "    def vector_search(self, query, top_k=5, format_result=False):\n",
    "        logging.info(f\"Vector search query: {query}\")\n",
    "        select = self.db[self.vector_index.indexing_listener.select.table].like(\n",
    "            {self.vector_index.indexing_listener.key:query},\n",
    "            vector_index=self.vector_index.identifier, \n",
    "            n=top_k,\n",
    "        ).select()\n",
    "        out = select.execute()\n",
    "        if out:\n",
    "            out = sorted(out, key=lambda x: x[\"score\"], reverse=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "114f89ce-7d3e-42be-831a-85c77b9379de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai import OpenAIChatCompletion\n",
    "\n",
    "llm_openai = OpenAIChatCompletion(identifier='llm-openai', model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6697652b-550b-4e48-b456-8c1b28554139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai.model import OpenAIChatCompletion\n",
    "\n",
    "prompt_template = (\n",
    "    \"The following is a document and question\\n\"\n",
    "    \"Only provide a very concise answer\\n\"\n",
    "    \"Context:\\n\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question:{query}\\n\"\n",
    "    \"answer:\"\n",
    ")\n",
    "\n",
    "rag = Rag(\n",
    "    identifier=\"rag\",\n",
    "    llm_model=llm_openai,\n",
    "    vector_index=vector_index, \n",
    "    prompt_template=prompt_template,\n",
    "    db=db,\n",
    "    processor=processor,\n",
    "    upstream=[vector_index],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde11162-e994-4621-af36-b5fa9bc3f258",
   "metadata": {},
   "source": [
    "## Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e81c270f-8be9-4050-a7df-07b62c17330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Dec-04 13:22:51.01\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.application\u001b[0m:\u001b[36m39  \u001b[0m | \u001b[1mResorting components based on topological order.\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.02\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.application\u001b[0m:\u001b[36m56  \u001b[0m | \u001b[1mNew order of components: ['table:<var:table_name>:0a98584ccc914712', 'listener:split_image:7f8ffadc367a40cd', 'listener:chunk:051bd7f119134ccf', 'vector_index:vector-index:b02b1b9dcf7a4da2', 'model:rag:a433627c3e1c4d43']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import Application\n",
    "\n",
    "app = Application(\n",
    "    'pdf-rag',\n",
    "    components=[\n",
    "        table,\n",
    "        listener_split_image,\n",
    "        listener_chunk,\n",
    "        vector_index,\n",
    "        rag\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a56e631-4a27-4119-b007-70daed387ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb81f74-1036-4a1f-87ec-023ce8dd2a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, Markdown, display\n",
    "\n",
    "if APPLY:\n",
    "    db.apply(rag, force=True)\n",
    "    result = rag.predict(\"Tell me about the documents?\", format_result=True)\n",
    "    \n",
    "    display(Markdown(result[\"answer\"]))\n",
    "    \n",
    "    for message, img in result[\"images\"]:\n",
    "        display(Markdown(message))\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81346b3c-9c2d-4f40-a78d-b830ee74597d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Dec-04 13:22:51.03\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf str already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.03\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.04\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:file already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.04\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.04\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf vector_index:vector-index already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf listener:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf model:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:vector[1536] already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf outputs-chunk-051bd7f119134ccf-select already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf vector_index:vector-index already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf listener:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf model:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:vector[1536] already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf outputs-chunk-051bd7f119134ccf-select already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf vector_index:vector-index already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf listener:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m74  \u001b[0m | \u001b[33m\u001b[1moutput_table not found in listener.dict()\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf model:embedding already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:vector[1536] already exists\u001b[0m\n",
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf outputs-chunk-051bd7f119134ccf-select already exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import Template, CFG, Table\n",
    "from superduper.components.dataset import RemoteData\n",
    "\n",
    "template = Template(\n",
    "    'pdf-rag',\n",
    "    db=db,\n",
    "    template=app,\n",
    "    substitutions={\n",
    "        prompt_template: \n",
    "        'prompt_template',\n",
    "        COLLECTION_NAME: 'table_name',\n",
    "        'gpt-3.5-turbo': 'llm_model',\n",
    "        'text-embedding-ada-002': 'embedding_model'\n",
    "    },\n",
    "    template_variables=['table_name', 'prompt_template', 'llm_model', 'embedding_model'],\n",
    "    default_table=Table(\n",
    "        'sample_pdf_rag',\n",
    "        schema=Schema(\n",
    "            'sample_pdf_rag/schema',\n",
    "            fields={\"url\": \"str\", \"file\": file}\n",
    "        ),\n",
    "        data=RemoteData('sample_pdfs', getter=getter),\n",
    "    ),\n",
    "    types={\n",
    "        'prompt_template':{\n",
    "            'type': 'str',\n",
    "            'default': prompt_template\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': 'sample_pdf_rag'\n",
    "        },\n",
    "        'llm_model': {\n",
    "            'type': 'str',\n",
    "            'default': 'gpt-3.5-turbo',\n",
    "        },\n",
    "        'embedding_model': {\n",
    "            'type': 'str',\n",
    "            'default': 'text-embedding-ada-002',\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e82d71e0-ab21-48a2-849a-57e494ae3a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Dec-04 13:22:51.05\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m558 \u001b[0m | \u001b[33m\u001b[1mLeaf str already exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "template.export(\".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

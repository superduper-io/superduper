{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.2"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "c288025e-2326-4e8b-ab52-6fb8a5f9560f", "metadata": {}, "source": ["<!-- TABS -->\n", "# Transfer learning"]}, {"cell_type": "markdown", "id": "f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6", "metadata": {}, "source": ["<!-- TABS -->\n", "## Configure your production system"]}, {"cell_type": "markdown", "id": "81e7cd59-67d0-4776-aea1-4864aa768f95", "metadata": {}, "source": [":::note\n", "If you would like to use the production features \n", "of SuperDuperDB, then you should set the relevant \n", "connections and configurations in a configuration \n", "file. Otherwise you are welcome to use \"development\" mode \n", "to get going with SuperDuperDB quickly.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "62014646-ccd4-4d10-ac26-1c470f88f2f2", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.makedirs('.superduperdb', exist_ok=True)\n", "os.environ['SUPERDUPERDB_CONFIG'] = '.superduperdb/config.yaml'"]}, {"cell_type": "code", "execution_count": null, "id": "8e50edd2-438d-44ab-9da0-0b72197df262", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Community>\n", "CFG = '''\n", "data_backend: mongodb://127.0.0.1:27017/documents\n", "artifact_store: filesystem://./artifact_store\n", "cluster:\n", "  cdc:\n", "    strategy: null\n", "    uri: ray://127.0.0.1:20000\n", "  compute:\n", "    uri: ray://127.0.0.1:10001\n", "  vector_search:\n", "    backfill_batch_size: 100\n", "    type: in_memory\n", "    uri: http://127.0.0.1:21000\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1ad9ee67-6402-45ea-8311-3efb039b5df3", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Atlas>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: native\n", "databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9c9e8351-b17f-4882-bda6-5ad51dbc7e1f", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: sqlite://<path-to-db>.db\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mysql://<user>:<password>@<host>:<port>/database\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9b7ac715-712c-4ec7-be90-0aaa22518977", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mssql://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "f21fad9c-cc0e-4cf5-83f0-41a3a614c6af", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: postgres://<user>:<password>@<host>:<port</<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1badb5a3-823c-4463-ab79-6f4f9239dabe", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: snowflake://<user>:<password>@<account>/<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "ae7807d9-9fc1-4c18-8027-a512f827783d", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: clickhouse://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "fc40c13b-9bc5-47ac-86d6-ef7a379c45ee", "metadata": {}, "outputs": [], "source": ["with open(os.environ['SUPERDUPERDB_CONFIG'], 'w') as f:\n", "    f.write(CFG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Start your cluster"]}, {"cell_type": "markdown", "metadata": {}, "source": [":::note\n", "Starting a SuperDuperDB cluster is useful in production and model development\n", "if you want to enable scalable compute, access to the models by multiple users for collaboration, \n", "monitoring.\n", "\n", "If you don't need this, then it is simpler to start in development mode.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Experimental Cluster>\n", "!python -m superduperdb local-cluster up"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Docker-Compose>\n", "!make build_sandbox\n", "!make testenv_init"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from superduperdb import superduper\n", "db = superduper('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from superduperdb import superduper\n", "\n", "user = 'superduper'\n", "password = 'superduper'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from superduperdb import superduper\n", "\n", "user = 'sa'\n", "password = 'Superduper#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = superduper(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "!pip install psycopg2\n", "from superduperdb import superduper\n", "\n", "user = 'postgres'\n", "password = 'postgres'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "db_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n", "\n", "db = superduper(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from superduperdb import superduper\n", "\n", "user = \"superduperuser\"\n", "password = \"superduperpassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = superduper(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from superduperdb import superduper\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from superduperdb import superduper\n", "\n", "db = superduper(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "547751e5", "metadata": {}, "outputs": [], "source": ["# <tab: Text-Classification>\n", "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/text_classification.json\n", "import json\n", "\n", "with open(\"text_classification.json\", \"r\") as f:\n", "    data = json.load(f)\n", "num_classes = 2"]}, {"cell_type": "code", "execution_count": null, "id": "1b28f6bf", "metadata": {}, "outputs": [], "source": ["# <tab: Image-Classification>\n", "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/images_classification.zip && unzip images_classification.zip\n", "import json\n", "from PIL import Image\n", "\n", "with open('images/images.json', 'r') as f:\n", "    data = json.load(f)\n", "\n", "data = [{'x': Image.open(d['image_path']), 'y': d['label']} for d in data]\n", "num_classes = 2"]}, {"cell_type": "markdown", "id": "eedb0bc4-826f-43fe-bd34-869bf69f2db0", "metadata": {}, "source": ["After obtaining the data, we insert it into the database."]}, {"cell_type": "code", "execution_count": null, "id": "7598ec1a-4f23-46f0-ae9f-617bce855e65", "metadata": {}, "outputs": [], "source": ["# <tab: Text-Classification>\n", "datas = [{'txt': d['x'], 'label': d['y']} for d in data]"]}, {"cell_type": "code", "execution_count": null, "id": "89e856c2-7407-431f-a7de-3a6d51d17be6", "metadata": {}, "outputs": [], "source": ["# <tab: Image-Classification>\n", "datas = [{'image': d['x'], 'label': d['y']} for d in data]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert simple data\n", "\n", "After turning on auto_schema, we can directly insert data, and superduperdb will automatically analyze the data type, and match the construction of the table and datatype."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from superduperdb import Document\n", "\n", "table_or_collection = db['documents']\n", "\n", "ids = db.execute(table_or_collection.insert([Document(data) for data in datas]))\n", "select = table_or_collection.select()"]}, {"cell_type": "markdown", "id": "9e703b58-a46d-4b1f-98fd-f50d46b168fe", "metadata": {}, "source": ["<!-- TABS -->\n", "## Compute features"]}, {"cell_type": "code", "execution_count": null, "id": "ae2e1588-fec8-45a6-b678-fef05fc7b57f", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "key = 'txt'\n", "import sentence_transformers\n", "from superduperdb import vector, Listener\n", "from superduperdb.ext.sentence_transformers import SentenceTransformer\n", "\n", "superdupermodel = SentenceTransformer(\n", "    identifier=\"embedding\",\n", "    object=sentence_transformers.SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"),\n", "    postprocess=lambda x: x.tolist(),\n", ")\n", "\n", "jobs, listener = db.apply(\n", "    Listener(\n", "        model=superdupermodel,\n", "        select=select,\n", "        key=key,\n", "        identifier=\"features\"\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "17de589c-4d75-4483-b2ca-77d5c25c2fb8", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "key = 'image'\n", "import torchvision.models as models\n", "from torchvision import transforms\n", "from superduperdb.ext.torch import TorchModel\n", "from superduperdb import Listener\n", "from PIL import Image\n", "\n", "class TorchVisionEmbedding:\n", "    def __init__(self):\n", "        # Load the pre-trained ResNet-18 model\n", "        self.resnet = models.resnet18(pretrained=True)\n", "        \n", "        # Set the model to evaluation mode\n", "        self.resnet.eval()\n", "        \n", "    def preprocess(self, image):\n", "        # Preprocess the image\n", "        preprocess = preprocess = transforms.Compose([\n", "            transforms.Resize(256),\n", "            transforms.CenterCrop(224),\n", "            transforms.ToTensor(),\n", "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n", "        ])\n", "        tensor_image = preprocess(image)\n", "        return tensor_image\n", "        \n", "model = TorchVisionEmbedding()\n", "superdupermodel = TorchModel(identifier='my-vision-model-torch', object=model.resnet, preprocess=model.preprocess, postprocess=lambda x: x.numpy().tolist())\n", "\n", "jobs, listener = db.apply(\n", "    Listener(\n", "        model=superdupermodel,\n", "        select=select,\n", "        key=key,\n", "        identifier=\"features\"\n", "    )\n", ")"]}, {"cell_type": "markdown", "id": "3d9329cd-1ef3-4997-ba2f-9353091907a8", "metadata": {}, "source": ["## Choose features key from feature listener"]}, {"cell_type": "code", "execution_count": null, "id": "90980578-4f7e-4872-9b64-517f464bb8fb", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "input_key = listener.outputs\n", "training_select = select"]}, {"cell_type": "code", "execution_count": null, "id": "9651e3a6-89f3-41db-80e6-afc294f4daa1", "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "input_key = listener.outputs\n", "training_select = select.outputs(listener.predict_id)"]}, {"cell_type": "markdown", "id": "ea4ddf88-468b-4ca5-b78b-37f8c3231ef7", "metadata": {}, "source": ["We can find the calculated feature data from the database."]}, {"cell_type": "code", "execution_count": null, "id": "aa1b85e7-a562-4efe-8af1-16889bd35bf7", "metadata": {}, "outputs": [], "source": ["feature = list(training_select.limit(1).execute())[0][input_key]\n", "feature_size = len(feature)"]}, {"cell_type": "markdown", "id": "c2da0ab6-8fc0-41fc-b8c9-0f8a127d9e8d", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build and train classifier"]}, {"cell_type": "code", "execution_count": null, "id": "d3b94fca-3a0b-433f-88cf-aab5b71b8596", "metadata": {}, "outputs": [], "source": ["# <tab: Scikit-Learn>\n", "from superduperdb.ext.sklearn import Estimator, SklearnTrainer\n", "from sklearn.svm import SVC\n", "\n", "model = Estimator(\n", "    identifier=\"my-model\",\n", "    object=SVC(),\n", "    trainer=SklearnTrainer(\n", "        \"my-trainer\",\n", "        key=(input_key, \"label\"),\n", "        select=training_select,\n", "    ),\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "5256e0fb-db16-411e-a1c1-8d44feb26c29", "metadata": {}, "outputs": [], "source": ["# <tab: Torch>\n", "import torch\n", "from torch import nn\n", "from superduperdb.ext.torch.model import TorchModel\n", "from superduperdb.ext.torch.training import TorchTrainer\n", "from torch.nn.functional import cross_entropy\n", "\n", "\n", "class SimpleModel(nn.Module):\n", "    def __init__(self, input_size=16, hidden_size=32, num_classes=3):\n", "        super(SimpleModel, self).__init__()\n", "        self.fc1 = nn.Linear(input_size, hidden_size)\n", "        self.relu = nn.ReLU()\n", "        self.fc2 = nn.Linear(hidden_size, num_classes)\n", "\n", "    def forward(self, x):\n", "        out = self.fc1(x)\n", "        out = self.relu(out)\n", "        out = self.fc2(out)\n", "        return out\n", "\n", "preprocess = lambda x: torch.tensor(x)\n", "\n", "# Postprocess function for the model output    \n", "def postprocess(x):\n", "    return int(x.topk(1)[1].item())\n", "\n", "def data_transform(features, label):\n", "    return torch.tensor(features), label\n", "\n", "# Create a Logistic Regression model\n", "# feature_length is the input feature size\n", "model = SimpleModel(feature_size, num_classes=num_classes)\n", "model = TorchModel(\n", "    identifier='my-model',\n", "    object=model,         \n", "    preprocess=preprocess,\n", "    postprocess=postprocess,\n", "    trainer=TorchTrainer(\n", "        key=(input_key, 'label'),\n", "        identifier='my_trainer',\n", "        objective=cross_entropy,\n", "        loader_kwargs={'batch_size': 10},\n", "        max_iterations=1000,\n", "        validation_interval=100,\n", "        select=select,\n", "        transform=data_transform,\n", "    ),\n", ")"]}, {"cell_type": "markdown", "id": "1af37887-59bc-4e13-b3b1-fee7d6108473", "metadata": {}, "source": ["Define a validation for evaluating the effect after training."]}, {"cell_type": "code", "execution_count": null, "id": "94fb7506-2abc-41fe-b259-8c4922d79516", "metadata": {}, "outputs": [], "source": ["from superduperdb import Dataset, Metric, Validation\n", "\n", "def acc(x, y):\n", "    return sum([xx == yy for xx, yy in zip(x, y)]) / len(x)\n", "\n", "\n", "accuracy = Metric(identifier=\"acc\", object=acc)\n", "validation = Validation(\n", "    \"transfer_learning_performance\",\n", "    key=(input_key, \"label\"),\n", "    datasets=[\n", "        Dataset(identifier=\"my-valid\", select=training_select.add_fold('valid'))\n", "    ],\n", "    metrics=[accuracy],\n", ")\n", "model.validation = validation"]}, {"cell_type": "markdown", "id": "513478b1-2736-4fa5-bc2a-6fdb9c8e232d", "metadata": {}, "source": ["If we execute the apply function, then the model will be added to the database, and because the model has a Trainer, it will perform training tasks."]}, {"cell_type": "code", "execution_count": null, "id": "79a39054-aef2-480a-a57e-7180914e6f7f", "metadata": {}, "outputs": [], "source": ["db.apply(model)"]}, {"cell_type": "markdown", "id": "52ab9838-9e5e-4402-a572-bd8339020963", "metadata": {}, "source": ["Get the training metrics"]}, {"cell_type": "code", "execution_count": null, "id": "b7478a2a-3071-4d71-9ab8-95d7d7dd3d32", "metadata": {}, "outputs": [], "source": ["# <tab: Scikit-Learn>\n", "# Load the model from the database\n", "model = db.load('model', model.identifier)\n", "model.metric_values"]}, {"cell_type": "code", "execution_count": null, "id": "8096e816-06b3-4d7f-8660-f8715f759109", "metadata": {}, "outputs": [], "source": ["# <tab: Torch>\n", "!pip -q install matplotlib\n", "from matplotlib import pyplot as plt\n", "\n", "# Load the model from the database\n", "model = db.load('model', model.identifier)\n", "\n", "# Plot the accuracy values\n", "plt.plot(model.trainer.metric_values['my-valid/acc'])\n", "plt.show()"]}]}
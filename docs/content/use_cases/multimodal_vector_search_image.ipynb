{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.2"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Multimodal vector search - Image"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from superduperdb import superduper\n", "db = superduper('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from superduperdb import superduper\n", "\n", "user = 'superduper'\n", "password = 'superduper'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from superduperdb import superduper\n", "\n", "user = 'sa'\n", "password = 'Superduper#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = superduper(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "!pip install psycopg2\n", "from superduperdb import superduper\n", "\n", "user = 'postgres'\n", "password = 'postgres'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "db_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n", "\n", "db = superduper(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from superduperdb import superduper\n", "\n", "user = \"superduperuser\"\n", "password = \"superduperpassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = superduper(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from superduperdb import superduper\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from superduperdb import superduper\n", "\n", "db = superduper(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "0828031a", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/images.zip && unzip images.zip\n", "import os\n", "from PIL import Image\n", "\n", "data = [f'images/{x}' for x in os.listdir('./images') if x.endswith(\".png\")][:200]\n", "data = [ Image.open(path) for path in data]"]}, {"cell_type": "code", "execution_count": null, "id": "44a702b1-faf9-4edb-8a55-efc4add84a83", "metadata": {}, "outputs": [], "source": ["datas = [{'img': d} for d in data[:100]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert simple data\n", "\n", "After turning on auto_schema, we can directly insert data, and superduperdb will automatically analyze the data type, and match the construction of the table and datatype."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from superduperdb import Document\n", "\n", "table_or_collection = db['documents']\n", "\n", "ids = db.execute(table_or_collection.insert([Document(data) for data in datas]))\n", "select = table_or_collection.select()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build multimodal embedding models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Some embedding models such as [CLIP](https://github.com/openai/CLIP) come in pairs of `model` and `compatible_model`.\n", "Otherwise:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Text-Image>\n", "!pip install git+https://github.com/openai/CLIP.git\n", "import clip\n", "from superduperdb import vector\n", "from superduperdb.ext.torch import TorchModel\n", "\n", "# Load the CLIP model and obtain the preprocessing function\n", "model, preprocess = clip.load(\"RN50\", device='cpu')\n", "\n", "# Define a vector with shape (1024,)\n", "\n", "output_datatpye = vector(shape=(1024,))\n", "\n", "# Create a TorchModel for text encoding\n", "compatible_model = TorchModel(\n", "    identifier='clip_text', # Unique identifier for the model\n", "    object=model, # CLIP model\n", "    preprocess=lambda x: clip.tokenize(x)[0],  # Model input preprocessing using CLIP \n", "    postprocess=lambda x: x.tolist(), # Convert the model output to a list\n", "    datatype=output_datatpye,  # Vector encoder with shape (1024,)\n", "    forward_method='encode_text', # Use the 'encode_text' method for forward pass \n", ")\n", "\n", "# Create a TorchModel for visual encoding\n", "model = TorchModel(\n", "    identifier='clip_image',  # Unique identifier for the model\n", "    object=model.visual,  # Visual part of the CLIP model    \n", "    preprocess=preprocess, # Visual preprocessing using CLIP\n", "    postprocess=lambda x: x.tolist(), # Convert the output to a list \n", "    datatype=output_datatpye, # Vector encoder with shape (1024,)\n", ")"]}, {"cell_type": "markdown", "id": "3d0119da-9cfd-4a60-8847-c3bfdf37697f", "metadata": {}, "source": ["Because we use multimodal models, we define different keys to specify which model to use for embedding calculations in the vector_index."]}, {"cell_type": "code", "execution_count": 4, "id": "12e75fab-8504-4d17-a7d9-f98667a5d6aa", "metadata": {}, "outputs": [], "source": ["indexing_key = 'img' # we use img key for img embedding\n", "compatible_key = 'text' # we use text key for text embedding"]}, {"cell_type": "markdown", "id": "41b8b40d-3750-4d7b-aa60-62e07b734b04", "metadata": {}, "source": ["## Create vector-index"]}, {"cell_type": "code", "execution_count": null, "id": "66ee3ff4-880e-477b-bbdf-5b8d89c56de2", "metadata": {}, "outputs": [], "source": ["vector_index_name = 'my-vector-index'"]}, {"cell_type": "code", "execution_count": null, "id": "4cede653", "metadata": {}, "outputs": [], "source": ["# <tab: 2-Modalities>\n", "from superduperdb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        ),\n", "        compatible_listener=Listener(\n", "            key=compatible_key,      # the `Document` key `model` should ingest to create embedding\n", "            model=compatible_model,         # a `_Predictor` how to convert data to embeddings\n", "            active=False,\n", "            select=None,\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "067a1203-8dbc-4d0a-aa4a-705d99902d52", "metadata": {}, "outputs": [], "source": ["query_table_or_collection = select.table_or_collection"]}, {"cell_type": "markdown", "id": "b8a87f9d-581a-419a-81b8-a743250413e9", "metadata": {}, "source": ["## Perform a vector search\n", "\n", "We can perform the vector searches using two types of data:\n", "\n", "- Text: By text description, we can find images similar to the text description.\n", "- Image: By using an image, we can find images similar to the provided image."]}, {"cell_type": "code", "execution_count": null, "id": "ce565823-4655-488c-8684-2240107fa30d", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "item = Document({compatible_key: \"Find a black dog\"})"]}, {"cell_type": "code", "execution_count": null, "id": "d8059626-dff8-4fe0-b872-97b8eb8b1b01", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "from IPython.display import display\n", "search_image = data[0]\n", "display(search_image)\n", "item = Document({indexing_key: search_image})"]}, {"cell_type": "markdown", "id": "fc3ba07d-1124-4d94-a117-60d2e72581f7", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows."]}, {"cell_type": "code", "execution_count": null, "id": "a061de0b-2694-4b36-844c-7753a465360f", "metadata": {}, "outputs": [], "source": ["select = query_table_or_collection.like(item, vector_index=vector_index_name, n=5).select()\n", "results = list(db.execute(select))"]}, {"cell_type": "markdown", "id": "9b6d9af9-a012-42bd-aad4-31b92d089caa", "metadata": {}, "source": ["## Visualize Results"]}, {"cell_type": "code", "execution_count": null, "id": "9e2ecea5-3a58-457c-ac50-ddc742484f2d", "metadata": {}, "outputs": [], "source": ["from IPython.display import display\n", "for result in results:\n", "    display(result[indexing_key])"]}, {"cell_type": "markdown", "id": "693b4878-39a2-444d-8e17-72a00e6c246d", "metadata": {}, "source": ["## Check the system stays updated\n", "\n", "You can add new data; once the data is added, all related models will perform calculations according to the underlying constructed model and listener, simultaneously updating the vector index to ensure that each query uses the latest data."]}, {"cell_type": "code", "execution_count": null, "id": "5ef97f5a-bb41-46ca-a85e-489824741216", "metadata": {}, "outputs": [], "source": ["new_datas = [{'img': d} for d in data[100:200]]\n", "ids = db.execute(table_or_collection.insert(new_datas))"]}]}
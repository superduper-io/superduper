{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef4439d-a3d7-45d8-9c73-f74654a83dbb",
   "metadata": {},
   "source": [
    "# Chunked vector-search using multiple inputs per document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd44b9a-b2d3-4e72-9877-d060c4129a80",
   "metadata": {},
   "source": [
    "In this example, we demonstrate how to implement vector-search, where the targets of search are envisaged\n",
    "to be smaller units of text than the raw data. For example, a developer might like to store whole documents, \n",
    "but search within those documents, finding substrings and references to the original document. \n",
    "\n",
    "This workflow is much trickier to implement than vanilla vector-search. Luckily, with `superduperdb`, it is just one extra command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271d54e-312b-4f87-bd68-589fe015e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017\"\n",
    "# mongodb_uri = \"mongodb://superduper:superduper@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from superduperdb import superduper\n",
    "db = superduper(mongodb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d853e3b-17ce-4ee2-9f84-b32c42d38d0f",
   "metadata": {},
   "source": [
    "To demonstrate this type of search with larger chunks of text, we use a wikipedia sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2308a-c15a-4b6c-a26a-3f9ca5d5d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/wikipedia-sample.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b405de91-a8ec-406b-9133-bae5ac7dde66",
   "metadata": {},
   "source": [
    "As before we insert the data using `pymongo`-similar syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb350a-eae2-4699-a7e8-eb7460e3dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from superduperdb.db.mongodb.query import Collection\n",
    "from superduperdb.container.document import Document as D\n",
    "\n",
    "with open('wikipedia-sample.json') as f:\n",
    "    data = json.load(f)[:100]\n",
    "\n",
    "db.execute(Collection('wikipedia').insert_many([D(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121415f-5597-4fbc-9d8a-715267e93c4a",
   "metadata": {},
   "source": [
    "Let's have a look at a document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50285fab-1fa3-4649-9395-328d7eec6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.db.mongodb.query import Collection\n",
    "\n",
    "r = db.execute(Collection('wikipedia').find_one()).unpack()\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d61062-fa81-4283-bfff-5261c0b1b989",
   "metadata": {},
   "source": [
    "To create the search functionality, we set up a simple model, whose sole purpose is to chunk \n",
    "the raw text into parts, and save those parts in another collecion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a467f-066e-4354-8f3d-78328ea93ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.model import Model\n",
    "\n",
    "def splitter(r):\n",
    "    out = [r['title']]\n",
    "    split = r['abstract'].split(' ')\n",
    "    for i in range(0, len(split) - 5, 5):\n",
    "        out.append(' '.join(split[i: i + 5]))\n",
    "    out = [x for x in out if x]\n",
    "    return out\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    identifier='splitter',\n",
    "    object=splitter,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={'document_embedded': False},\n",
    ")\n",
    "\n",
    "model.predict(r, one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b422e9-f679-4dd1-9a25-ec69d7ecfcf5",
   "metadata": {},
   "source": [
    "Let's apply this model to the whole input collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870f664-aa12-45a6-8a8b-9682bc1a479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\n",
    "    X='_base', \n",
    "    db=db,\n",
    "    select=Collection('wikipedia').find()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487675eb-191a-45ce-b5b6-f61d9f7127a9",
   "metadata": {},
   "source": [
    "Now let's look at the split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe622094-d213-4225-8fe9-028db4bef00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(Collection('_outputs._base.splitter').find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381232e4-c444-496e-99bd-c0f219df55de",
   "metadata": {},
   "source": [
    "We can search this data in a manner similar to previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04687f7-361f-401d-8ea0-448ebddb3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.vector_index import VectorIndex\n",
    "from superduperdb.container.listener import Listener\n",
    "from superduperdb.ext.numpy.array import array\n",
    "from superduperdb.ext.openai.model import OpenAIEmbedding\n",
    "\n",
    "model = OpenAIEmbedding(model='text-embedding-ada-002')\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier=f'chunked-documents',\n",
    "        indexing_listener=Listener(\n",
    "            model=model,\n",
    "            key='_outputs._base.splitter',\n",
    "            select=Collection('_outputs._base.splitter').find(),\n",
    "            predict_kwargs={'max_chunk_size': 1000},\n",
    "        ),\n",
    "        compatible_listener=Listener(\n",
    "            model=model,\n",
    "            key='_base',\n",
    "            select=None,\n",
    "            active=False,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e04b8-3961-4927-a5ed-591a162019b7",
   "metadata": {},
   "source": [
    "Now we can search through the split-text collection and recall the full original documents,\n",
    "highlighting which text was found to be relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfabe2f-88d6-4ad9-b449-51a798608895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.db.mongodb.query import Collection\n",
    "from superduperdb.container.document import Document as D\n",
    "from IPython.display import *\n",
    "\n",
    "query = 'politics'\n",
    "\n",
    "shingle_collection = Collection('_outputs._base.splitter')\n",
    "main_collection = Collection('wikipedia')\n",
    "\n",
    "result = db.execute(\n",
    "    shingle_collection\n",
    "        .like(D({'_base': query}), vector_index='chunked-documents', n=5)\n",
    "        .find({}, {'_outputs._base.text-embedding-ada-002': 0})\n",
    ")\n",
    "\n",
    "display(Markdown(f'---'))\n",
    "for shingle in result:\n",
    "    original = db.execute(main_collection.find_one({'_id': shingle['_source']}))\n",
    "\n",
    "    display(Markdown(f'# {original[\"title\"]}\"'))\n",
    "    \n",
    "    start = original['abstract'].find(shingle['_outputs']['_base']['splitter'])\n",
    "\n",
    "    to_format = (\n",
    "        original[\"abstract\"][:start] + '**' + '<span style=\"color:red\">' +\n",
    "        shingle[\"_outputs\"][\"_base\"][\"splitter\"].upper() + '**' + '<span style=\"color:black\">' +\n",
    "        original[\"abstract\"][start + len(shingle[\"_outputs\"][\"_base\"][\"splitter\"]):]\n",
    "    )\n",
    "    \n",
    "    display(Markdown(to_format))\n",
    "    display(Markdown(f'---'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

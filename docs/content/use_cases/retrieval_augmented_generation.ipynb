{"cells":[{"cell_type":"markdown","id":"38c1a328-fd86-4c5f-bd54-b8664f433608","metadata":{},"source":["<!-- TABS -->\n","# Retrieval augmented generation"]},{"cell_type":"markdown","id":"f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6","metadata":{},"source":["<!-- TABS -->\n","## Configure your production system"]},{"cell_type":"markdown","id":"81e7cd59-67d0-4776-aea1-4864aa768f95","metadata":{},"source":[":::note\n","If you would like to use the production features \n","of Superduper, then you should set the relevant \n","connections and configurations in a configuration \n","file. Otherwise you are welcome to use \"development\" mode \n","to get going with Superduper quickly.\n",":::"]},{"cell_type":"code","execution_count":null,"id":"62014646-ccd4-4d10-ac26-1c470f88f2f2","metadata":{},"outputs":[],"source":["import os\n","\n","os.makedirs('.superduper', exist_ok=True)\n","os.environ['SUPERDUPER_CONFIG'] = '.superduper/config.yaml'"]},{"cell_type":"code","execution_count":null,"id":"8e50edd2-438d-44ab-9da0-0b72197df262","metadata":{},"outputs":[],"source":["# <tab: MongoDB Community>\n","CFG = '''\n","data_backend: mongodb://127.0.0.1:27017/documents\n","artifact_store: filesystem://./artifact_store\n","cluster:\n","  cdc:\n","    strategy: null\n","    uri: ray://127.0.0.1:20000\n","  compute:\n","    uri: ray://127.0.0.1:10001\n","  vector_search:\n","    backfill_batch_size: 100\n","    type: in_memory\n","    uri: http://127.0.0.1:21000\n","'''"]},{"cell_type":"code","execution_count":null,"id":"1ad9ee67-6402-45ea-8311-3efb039b5df3","metadata":{},"outputs":[],"source":["# <tab: MongoDB Atlas>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","        type: native\n","databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n","'''"]},{"cell_type":"code","execution_count":null,"id":"9c9e8351-b17f-4882-bda6-5ad51dbc7e1f","metadata":{},"outputs":[],"source":["# <tab: SQLite>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: sqlite://<path-to-db>.db\n","'''"]},{"cell_type":"code","execution_count":null,"id":"d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad","metadata":{},"outputs":[],"source":["# <tab: MySQL>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: mysql://<user>:<password>@<host>:<port>/database\n","'''"]},{"cell_type":"code","execution_count":null,"id":"9b7ac715-712c-4ec7-be90-0aaa22518977","metadata":{},"outputs":[],"source":["# <tab: Oracle>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: mssql://<user>:<password>@<host>:<port>\n","'''"]},{"cell_type":"code","execution_count":null,"id":"f21fad9c-cc0e-4cf5-83f0-41a3a614c6af","metadata":{},"outputs":[],"source":["# <tab: PostgreSQL>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: postgres://<user>:<password>@<host>:<port</<database>\n","'''"]},{"cell_type":"code","execution_count":null,"id":"1badb5a3-823c-4463-ab79-6f4f9239dabe","metadata":{},"outputs":[],"source":["# <tab: Snowflake>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","metadata_store: sqlite://<path-to-sqlite-db>.db\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: snowflake://<user>:<password>@<account>/<database>\n","'''"]},{"cell_type":"code","execution_count":null,"id":"ae7807d9-9fc1-4c18-8027-a512f827783d","metadata":{},"outputs":[],"source":["# <tab: Clickhouse>\n","CFG = '''\n","artifact_store: filesystem://<path-to-artifact-store>\n","metadata_store: sqlite://<path-to-sqlite-db>.db\n","cluster: \n","    compute: ray://<ray-host>\n","    cdc:    \n","        uri: http://<cdc-host>:<cdc-port>\n","    vector_search:\n","        uri: http://<vector-search-host>:<vector-search-port>\n","databackend: clickhouse://<user>:<password>@<host>:<port>\n","'''"]},{"cell_type":"code","execution_count":null,"id":"fc40c13b-9bc5-47ac-86d6-ef7a379c45ee","metadata":{},"outputs":[],"source":["with open(os.environ['SUPERDUPER_CONFIG'], 'w') as f:\n","    f.write(CFG)"]},{"cell_type":"markdown","metadata":{},"source":["<!-- TABS -->\n","## Start your cluster"]},{"cell_type":"markdown","metadata":{},"source":[":::note\n","Starting a superduper cluster is useful in production and model development\n","if you want to enable scalable compute, access to the models by multiple users for collaboration, \n","monitoring.\n","\n","If you don't need this, then it is simpler to start in development mode.\n",":::"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# <tab: Experimental Cluster>\n","!python -m superduper local-cluster up"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# <tab: Docker-Compose>\n","!make build_sandbox\n","!make testenv_init"]},{"cell_type":"markdown","id":"32f8484d-2e35-472a-9b24-1a30ec1d144b","metadata":{},"source":["<!-- TABS -->\n","## Connect to Superduper"]},{"cell_type":"markdown","id":"06d66021-ce62-4021-a2c5-158dee92b3bb","metadata":{},"source":[":::note\n","Note that this is only relevant if you are running Superduper in development mode.\n","Otherwise refer to \"Configuring your production system\".\n",":::"]},{"cell_type":"code","execution_count":null,"id":"61976f44-8139-41c0-a73e-569c6d16c4b1","metadata":{},"outputs":[],"source":["# <tab: MongoDB>\n","from superduper import superduper\n","\n","db = superduper('mongodb://localhost:27017/documents')"]},{"cell_type":"code","execution_count":null,"id":"e981a457","metadata":{},"outputs":[],"source":["# <tab: SQLite>\n","from superduper import superduper\n","db = superduper('sqlite://my_db.db')"]},{"cell_type":"code","execution_count":null,"id":"19ecf7c0-b730-4503-9b5d-e97697b3bcee","metadata":{},"outputs":[],"source":["# <tab: MySQL>\n","from superduper import superduper\n","\n","user = 'superduper'\n","password = 'superduper'\n","port = 3306\n","host = 'localhost'\n","database = 'test_db'\n","\n","db = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]},{"cell_type":"code","execution_count":null,"id":"df208e8c-4fd0-438f-af29-22a763a2aebd","metadata":{},"outputs":[],"source":["# <tab: Oracle>\n","from superduper import superduper\n","\n","user = 'sa'\n","password = 'Superduper#1'\n","port = 1433\n","host = 'localhost'\n","\n","db = superduper(f\"mssql://{user}:{password}@{host}:{port}\")"]},{"cell_type":"code","execution_count":null,"id":"d2297295","metadata":{},"outputs":[],"source":["# <tab: PostgreSQL>\n","!pip install psycopg2\n","from superduper import superduper\n","\n","user = 'postgres'\n","password = 'postgres'\n","port = 5432\n","host = 'localhost'\n","database = 'test_db'\n","db_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n","\n","db = superduper(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))"]},{"cell_type":"code","execution_count":null,"id":"cc6c8517","metadata":{},"outputs":[],"source":["# <tab: Snowflake>\n","from superduper import superduper\n","\n","user = \"superduperuser\"\n","password = \"superduperpassword\"\n","account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n","database = \"FREE_COMPANY_DATASET/PUBLIC\"\n","\n","snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n","\n","db = superduper(\n","    snowflake_uri, \n","    metadata_store='sqlite:///your_database_name.db',\n",")"]},{"cell_type":"code","execution_count":null,"id":"05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44","metadata":{},"outputs":[],"source":["# <tab: Clickhouse>\n","from superduper import superduper\n","\n","user = 'default'\n","password = ''\n","port = 8123\n","host = 'localhost'\n","\n","db = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]},{"cell_type":"code","execution_count":null,"id":"0e89c8dd-d845-423a-9acc-97e3360d370c","metadata":{},"outputs":[],"source":["# <tab: DuckDB>\n","from superduper import superduper\n","\n","db = superduper('duckdb://mydb.duckdb')"]},{"cell_type":"code","execution_count":null,"id":"2de71562","metadata":{},"outputs":[],"source":["# <tab: Pandas>\n","from superduper import superduper\n","\n","db = superduper(['my.csv'], metadata_store=f'mongomock://meta')"]},{"cell_type":"code","execution_count":null,"id":"cb029a5e-fedf-4f07-8a31-d220cfbfbb3d","metadata":{},"outputs":[],"source":["# <tab: MongoMock>\n","from superduper import superduper\n","\n","db = superduper('mongomock:///test_db')"]},{"cell_type":"markdown","id":"032c2e7b-3f54-4263-b778-0fef60596efb","metadata":{},"source":["<!-- TABS -->\n","## Get useful sample data"]},{"cell_type":"code","execution_count":null,"id":"4e7902bd","metadata":{},"outputs":[],"source":["# <tab: Text>\n","!curl -O https://superduper-public-demo.s3.amazonaws.com/text.json\n","import json\n","\n","with open('text.json', 'r') as f:\n","    data = json.load(f)"]},{"cell_type":"code","execution_count":null,"id":"33486ec7-0316-4e0c-a409-c09ab4c16669","metadata":{},"outputs":[],"source":["# <tab: PDF>\n","!curl -O https://superduper-public-demo.s3.amazonaws.com/pdfs.zip && unzip -o pdfs.zip\n","import os\n","\n","data = [f'pdfs/{x}' for x in os.listdir('./pdfs') if x.endswith('.pdf')]"]},{"cell_type":"code","execution_count":null,"id":"b745ed54-3818-4685-a3b5-6ab4e2afc44d","metadata":{},"outputs":[],"source":["datas = [{'x': d} for d in data]"]},{"cell_type":"markdown","metadata":{},"source":["<!-- TABS -->\n","## Insert simple data\n","\n","After turning on auto_schema, we can directly insert data, and Superduper will automatically analyze the data type, and match the construction of the table and datatype."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from superduper import Document\n","\n","table_or_collection = db['documents']\n","\n","ids = db.execute(table_or_collection.insert([Document(data) for data in datas]))\n","select = table_or_collection.select()"]},{"cell_type":"markdown","id":"54fea927-ee4a-44cd-aaf2-634b574c316d","metadata":{},"source":["<!-- TABS -->\n","## Apply a chunker for search"]},{"cell_type":"markdown","id":"06d90bda-e8c4-494e-a38c-837fb63689ae","metadata":{},"source":[":::note\n","Note that applying a chunker is ***not*** mandatory for search.\n","If your data is already chunked (e.g. short text snippets or audio) or if you\n","are searching through something like images, which can't be chunked, then this\n","won't be necessary.\n",":::"]},{"cell_type":"code","execution_count":null,"id":"2d20eaa0-a416-4483-938e-23f79845739a","metadata":{},"outputs":[],"source":["# <tab: Text>\n","from superduper import model\n","\n","CHUNK_SIZE = 200\n","\n","@model(flatten=True, model_update_kwargs={'document_embedded': False})\n","def chunker(text):\n","    text = text.split()\n","    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n","    return chunks"]},{"cell_type":"code","execution_count":null,"id":"facd7dc0-fffa-40d8-af72-2b9e4852ad79","metadata":{},"outputs":[],"source":["# <tab: PDF>\n","!pip install -q \"unstructured[pdf]\"\n","from superduper import model\n","from unstructured.partition.pdf import partition_pdf\n","\n","CHUNK_SIZE = 500\n","\n","@model(flatten=True, model_update_kwargs={'document_embedded': False})\n","def chunker(pdf_file):\n","    elements = partition_pdf(pdf_file)\n","    text = '\\n'.join([e.text for e in elements])\n","    chunks = [text[i:i + CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n","    return chunks"]},{"cell_type":"markdown","id":"b33a16f9-3bac-45bb-80ac-3ccf265dce5f","metadata":{},"source":["Now we apply this chunker to the data by wrapping the chunker in `Listener`:"]},{"cell_type":"code","execution_count":null,"id":"93d21872-d4dc-40dc-abab-fb07ba102ea3","metadata":{},"outputs":[],"source":["from superduper import Listener\n","\n","upstream_listener = Listener(\n","    model=chunker,\n","    select=select,\n","    key='x',\n","    uuid=\"chunk\",\n",")\n","\n","db.apply(upstream_listener)"]},{"cell_type":"markdown","id":"7c5377c0-4c9b-4ba9-8f08-5e866b9220b5","metadata":{},"source":["## Select outputs of upstream listener"]},{"cell_type":"markdown","id":"809f5f62-95c3-483b-ae74-a5cdb5c1c83d","metadata":{},"source":[":::note\n","This is useful if you have performed a first step, such as pre-computing \n","features, or chunking your data. You can use this query to \n","operate on those outputs.\n",":::"]},{"cell_type":"code","execution_count":null,"id":"e49b116d-34f5-438a-995e-a8bd59e1dd80","metadata":{},"outputs":[],"source":["indexing_key = upstream_listener.outputs_key\n","select = upstream_listener.outputs_select"]},{"cell_type":"markdown","id":"c9a2cd87-723f-4cee-87c7-9b8181c9e54b","metadata":{},"source":["<!-- TABS -->\n","## Build text embedding model"]},{"cell_type":"code","execution_count":null,"id":"a9b1f538-65ca-499e-b6d0-2dd733f81723","metadata":{},"outputs":[],"source":["# <tab: OpenAI>\n","!pip install openai\n","from superduper.ext.openai import OpenAIEmbedding\n","\n","embedding_model = OpenAIEmbedding(identifier='text-embedding-ada-002')"]},{"cell_type":"code","execution_count":null,"id":"e83facd8-8823-492f-a2c6-659f38d8e6ec","metadata":{},"outputs":[],"source":["# <tab: JinaAI>\n","import os\n","from superduper.ext.jina import JinaEmbedding\n","\n","os.environ[\"JINA_API_KEY\"] = \"jina_xxxx\"\n"," \n","# define the model\n","embedding_model = JinaEmbedding(identifier='jina-embeddings-v2-base-en')"]},{"cell_type":"code","execution_count":null,"id":"3b4a9a60-41df-461d-b165-1d136ee25694","metadata":{},"outputs":[],"source":["# <tab: Sentence-Transformers>\n","!pip install sentence-transformers\n","from superduper import vector\n","import sentence_transformers\n","from superduper.ext.sentence_transformers import SentenceTransformer\n","\n","embedding_model = SentenceTransformer(\n","    identifier=\"embedding\",\n","    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-small-en\"),\n","    datatype=vector(shape=(1024,)),\n","    postprocess=lambda x: x.tolist(),\n","    predict_kwargs={\"show_progress_bar\": True},\n",")"]},{"cell_type":"code","execution_count":null,"id":"b1219380-13ce-4301-90e6-6ede2eee1497","metadata":{},"outputs":[],"source":["# <tab: Transformers>\n","from superduper import vector\n","from superduper.components.model import Model, ensure_initialized, Signature\n","from transformers import AutoTokenizer, AutoModel\n","import torch\n","\n","class TransformerEmbedding(Model):\n","    signature: Signature = 'singleton'\n","    pretrained_model_name_or_path : str\n","\n","    def init(self):\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.pretrained_model_name_or_path)\n","        self.model = AutoModel.from_pretrained(self.pretrained_model_name_or_path)\n","        self.model.eval()\n","\n","    @ensure_initialized\n","    def predict(self, x):\n","        return self.predict([x])[0]\n","        \n","    @ensure_initialized\n","    def predict(self, dataset):\n","        encoded_input = self.tokenizer(dataset, padding=True, truncation=True, return_tensors='pt')\n","        # Compute token embeddings\n","        with torch.no_grad():\n","            model_output = self.model(**encoded_input)\n","            # Perform pooling. In this case, cls pooling.\n","            sentence_embeddings = model_output[0][:, 0]\n","        # normalize embeddings\n","        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n","        return sentence_embeddings.tolist()\n","\n","\n","embedding_model = TransformerEmbedding(identifier=\"embedding\", pretrained_model_name_or_path=\"BAAI/bge-small-en\", datatype=vector(shape=(384, )))"]},{"cell_type":"code","execution_count":null,"id":"b9b238cf-56d5-44b4-87b0-9d8d55bdf36f","metadata":{},"outputs":[],"source":["print(len(embedding_model.predict(\"What is superduper\")))"]},{"cell_type":"markdown","id":"f31843db-8638-458a-a770-96a79041be88","metadata":{},"source":["## Create vector-index"]},{"cell_type":"code","execution_count":null,"id":"4663fa4b-c2ec-427d-bf8b-b8b109cc2ccf","metadata":{},"outputs":[],"source":["from superduper import VectorIndex, Listener\n","\n","vector_index_name = 'vector-index'\n","\n","jobs, _ = db.add(\n","    VectorIndex(\n","        vector_index_name,\n","        indexing_listener=Listener(\n","            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n","            select=select,       # a `Select` query telling which data to search over\n","            model=embedding_model,         # a `_Predictor` how to convert data to embeddings\n","            uuid=\"embedding\"\n","        )\n","    )\n",")\n","query_table_or_collection = select.table_or_collection"]},{"cell_type":"code","execution_count":null,"id":"053183e1-fee8-4b7b-a567-62ce97845c98","metadata":{},"outputs":[],"source":["query = \"Tell me about the Superduper\""]},{"cell_type":"markdown","id":"91142c55-b256-4025-94c2-6c4d215c6975","metadata":{},"source":["<!-- TABS -->\n","## Create Vector Search Model"]},{"cell_type":"code","execution_count":null,"id":"b5b99541-fd10-41c1-b6a7-1da6c1d4dbd7","metadata":{},"outputs":[],"source":["item = {indexing_key: '<var:query>'}"]},{"cell_type":"code","execution_count":null,"id":"d47799ab-b688-4eb8-82d4-6c0aa1204801","metadata":{},"outputs":[],"source":["from superduper.components.model import QueryModel\n","\n","vector_search_model = QueryModel(\n","    identifier=\"VectorSearch\",\n","    select=query_table_or_collection.like(item, vector_index=vector_index_name, n=5).select(),\n","    # The _source is the identifier of the upstream data, which can be used to locate the data from upstream sources using `_source`.\n","    postprocess=lambda docs: [{\"text\": doc[indexing_key], \"_source\": doc[\"_source\"]} for doc in docs],\n","    db=db\n",")"]},{"cell_type":"code","execution_count":null,"id":"56c5b28e-1f9d-4e9a-8238-537b71c07d2b","metadata":{},"outputs":[],"source":["vector_search_model.predict(query=query)"]},{"cell_type":"markdown","id":"1179a67b-4e40-496b-9851-98f32d42faa0","metadata":{},"source":["<!-- TABS -->\n","## Build LLM"]},{"cell_type":"code","execution_count":null,"id":"f98e5ff4","metadata":{},"outputs":[],"source":["# <tab: OpenAI>\n","!pip install openai\n","from superduper.ext.openai import OpenAIChatCompletion\n","\n","llm = OpenAIChatCompletion(identifier='llm', model='gpt-3.5-turbo')"]},{"cell_type":"code","execution_count":null,"id":"9bf39c47","metadata":{},"outputs":[],"source":["# <tab: Anthropic>\n","!pip install anthropic\n","from superduper.ext.anthropic import AnthropicCompletions\n","import os\n","\n","os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-xxx\"\n","\n","predict_kwargs = {\n","    \"max_tokens\": 1024,\n","    \"temperature\": 0.8,\n","}\n","\n","llm = AnthropicCompletions(identifier='llm', model='claude-2.1', predict_kwargs=predict_kwargs)"]},{"cell_type":"code","execution_count":null,"id":"95e48deb","metadata":{},"outputs":[],"source":["# <tab: vLLM>\n","!pip install vllm\n","from superduper.ext.vllm import VllmModel\n","\n","predict_kwargs = {\n","    \"max_tokens\": 1024,\n","    \"temperature\": 0.8,\n","}\n","\n","\n","llm = VllmModel(\n","    identifier=\"llm\",\n","    model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n","    vllm_kwargs={\n","        \"gpu_memory_utilization\": 0.7,\n","        \"max_model_len\": 1024,\n","        \"quantization\": \"awq\",\n","    },\n","    predict_kwargs=predict_kwargs,\n",")"]},{"cell_type":"code","execution_count":null,"id":"fe4ac344","metadata":{},"outputs":[],"source":["# <tab: Transformers>\n","!pip install transformers datasets bitsandbytes accelerate\n","from superduper.ext.transformers import LLM\n","\n","llm = LLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", load_in_8bit=True, device_map=\"cuda\", identifier=\"llm\", predict_kwargs=dict(max_new_tokens=128))"]},{"cell_type":"code","execution_count":null,"id":"1fdbfae2-af7d-4845-bce5-0cb230e3614e","metadata":{},"outputs":[],"source":["# <tab: Llama.cpp>\n","!pip install llama_cpp_python\n","# !huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF mistral-7b-instruct-v0.2.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n","\n","from superduper.ext.llamacpp.model import LlamaCpp\n","llm = LlamaCpp(identifier=\"llm\", model_name_or_path=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\")"]},{"cell_type":"code","execution_count":null,"id":"7d39a98d-c2f2-4496-b50e-ff82a59d7204","metadata":{},"outputs":[],"source":["# test the llm model\n","llm.predict(\"Tell me about the superduper\")"]},{"cell_type":"markdown","id":"60ae6203-dcc4-493c-a8f8-f727f0f75778","metadata":{},"source":["## Answer question with LLM"]},{"cell_type":"code","execution_count":null,"id":"44baeb09-6f35-4cf2-b814-46283a59f7e9","metadata":{},"outputs":[],"source":["from superduper import model\n","from superduper.components.graph import Graph, input_node\n","\n","prompt_template = (\n","    \"Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n\"\n","    \"{context}\\n\\n\"\n","    \"Here's the question: {query}\"\n",")\n","\n","\n","@model\n","def build_prompt(query, docs):\n","    chunks = [doc[\"text\"] for doc in docs]\n","    context = \"\\n\\n\".join(chunks)\n","    prompt = prompt_template.format(context=context, query=query)\n","    return prompt\n","    \n","\n","# We build a graph to handle the entire pipeline\n","\n","# create a input node, only have one input parameter `query`\n","in_ = input_node('query')\n","# pass the query to the vector search model\n","vector_search_results = vector_search_model(query=in_)\n","# pass the query and the search results to the prompt builder\n","prompt = build_prompt(query=in_, docs=vector_search_results)\n","# pass the prompt to the llm model\n","answer = llm(prompt)\n","# create a graph, and the graph output is the answer\n","rag = answer.to_graph(\"rag\")\n","print(rag.predict(query)[0])"]},{"cell_type":"markdown","id":"183bf5b6-4644-4e4c-b65b-e6bafdc6b49f","metadata":{},"source":["By applying the RAG model to the database, it will subsequently be accessible for use in other services."]},{"cell_type":"code","execution_count":null,"id":"e6787c78-4b14-4a72-818b-450408a74331","metadata":{},"outputs":[],"source":["db.add(rag)"]},{"cell_type":"markdown","id":"5da0306b-0969-49ab-95c4-0eb93c39f515","metadata":{},"source":["You can now load the model elsewhere and make predictions using the following command.\n","\n","```python\n","rag = db.load(\"model\", 'context_llm')\n","print(rag.predict(\"Tell me about the superduper\")[0])\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":5}

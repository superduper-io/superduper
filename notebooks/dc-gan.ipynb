{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc57be3d",
   "metadata": {},
   "source": [
    "# Bespoke training loop using GAN on Celeb Dataset\n",
    "\n",
    "\n",
    "SuperDuperDB supports a wide variety of learning tasks out of the box, using:\n",
    "\n",
    "- `collection.create_imputation`\n",
    "- `collection.create_semantic_index`\n",
    "\n",
    "This allows users to get going quickly training custom models with their database.\n",
    "\n",
    "In some cases, the learning problem may not fit the cases supported by SuperDuperDB. For this, one can add one's own custom trainer class. To demonstrate this, we show you how to train a GAN to generate celebrity faces together with the database.\n",
    "\n",
    "You can get the data [here](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d60361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "from superduperdb.training.trainer import Trainer\n",
    "from superduperdb.mongodb.client import SuperDuperClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862fd28",
   "metadata": {},
   "source": [
    "We instatiate a new collection for this task. Each training image will occupy it's own record in MongoDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = SuperDuperClient()\n",
    "docs = c.celebs.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0052dd",
   "metadata": {},
   "source": [
    "In order to speed up data injestion, we see the number of download workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.database['_meta'].insert_one({'key': 'n_download_workers', 'value': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2dc84",
   "metadata": {},
   "source": [
    "Inserting data creates an asynchronous job which inserts the images referred to below into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eb633",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'img': {'_content': {'url': f'file://notebooks/data/img_align_celeba/{x}', 'type': 'image'}}}\n",
    "    for x in os.listdir('data/img_align_celeba/')\n",
    "]\n",
    "docs.remote = True\n",
    "_, jobs = docs.insert_many(data)\n",
    "docs.database.watch_job(jobs['_download_content'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12202caf",
   "metadata": {},
   "source": [
    "We can watch this job like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.database.watch_job(jobs['_download_content'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f317b3",
   "metadata": {},
   "source": [
    "In order to be able to load these images, and also potentially tensors from the database, we need to define 2 custom data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6b7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "import PIL.JpegImagePlugin\n",
    "import PIL.PngImagePlugin\n",
    "\n",
    "\n",
    "class Image:\n",
    "    types = (PIL.JpegImagePlugin.JpegImageFile, PIL.Image.Image,\n",
    "             PIL.PngImagePlugin.PngImageFile)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        buffer = io.BytesIO()\n",
    "        x.save(buffer, format='png')\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        return PIL.Image.open(io.BytesIO(bytes_))\n",
    "    \n",
    "    \n",
    "class FloatTensor:\n",
    "    types = (torch.FloatTensor, torch.Tensor)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        x = x.numpy()\n",
    "        assert x.dtype == numpy.float32\n",
    "        return memoryview(x).tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        array = numpy.frombuffer(bytes_, dtype=numpy.float32)\n",
    "        return torch.from_numpy(array).type(torch.float)\n",
    "\n",
    "\n",
    "docs.create_type('image', Image(), serializer='dill')\n",
    "docs.create_type('float_tensor', FloatTensor(), serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67384a21",
   "metadata": {},
   "source": [
    "Now we're ready to define the generator and discriminator models. As in other examples, where relevant we \n",
    "set up pre- and post-processing where the models need to interface with the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=100, ngf=64, nc=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def preprocess(self, r=None):\n",
    "        if not isinstance(r, torch.Tensor):\n",
    "            r = torch.rand(self.nz, 1, 1)\n",
    "        return r\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "    def postprocess(self, image_tensor):\n",
    "        return transforms.ToPILImage()(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(self.ndf),\n",
    "            transforms.CenterCrop(self.ndf),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])(image)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.main(input)\n",
    "        return out[:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67b43c",
   "metadata": {},
   "source": [
    "We use `dill` serialization, since the models are defined inside this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "docs.create_model('generator', generator, serializer='dill')\n",
    "docs.create_model('discriminator', discriminator, serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7c446",
   "metadata": {},
   "source": [
    "Here is our custom trainer object. Inside our trainer, we're free to write sample model outputs to the database, \n",
    "and also to redefine any of the standard methods in `superduperdb.training.trainer.Trainer`. \n",
    "\n",
    "The main functionality occurs in `.train`, which we redefine here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ea386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class GANTrainer(Trainer):\n",
    "    def create_samples(self):\n",
    "        noise = torch.randn(8, self.models[0].nz, 1, 1)\n",
    "        images = []\n",
    "        import tqdm\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm.tqdm(range(8)):\n",
    "                images.append(self.database.apply_model(self.models[0], None))\n",
    "        self.database.infer_types\n",
    "        info = self.database.get_object_info(self.train_name, 'learning_task')\n",
    "        encoder = self.database.types['image']\n",
    "        info['train_samples'] = [\n",
    "            {'_content': {'bytes': encoder.encode(i), 'type': 'image'}}\n",
    "            for i in images\n",
    "        ]\n",
    "        self.database['_objects'].replace_one({'_id': info['_id']}, info)\n",
    "        \n",
    "    def train(self):\n",
    "        iterations = 0\n",
    "        netG, netD = self.models\n",
    "        device = next(netG.parameters()).device\n",
    "        optimizerG, optimizerD = self.optimizers\n",
    "        train_loader = self.data_loaders[0]\n",
    "        real_label = 1\n",
    "        fake_label = 0\n",
    "        criterion = self.objective\n",
    "        print('')\n",
    "        it = 0\n",
    "        epoch = 0\n",
    "        while True:\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                \n",
    "                if it % self.validation_interval == 0:\n",
    "                    self.create_samples()\n",
    "                    self.log_weight_traces()\n",
    "                    for m, mn in zip(self.models, self.model_names):\n",
    "                        self.save(mn, m)\n",
    "                noise, batch = batch\n",
    "                \n",
    "                batch = batch.to(device)\n",
    "                iterations += 1\n",
    "                b_size = batch.shape[0]\n",
    "                label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "                netD.zero_grad()\n",
    "                output = netD(batch).view(-1)\n",
    "                netD.zero_grad()\n",
    "                errD_real = self.objective(output, label)\n",
    "                errD_real.backward()\n",
    "                \n",
    "                noise = noise.to(device)\n",
    "                fake = netG.forward(noise)\n",
    "                label.fill_(fake_label)\n",
    "                output = netD(fake.detach()).view(-1)\n",
    "                errD_fake = criterion(output, label)\n",
    "                errD_fake.backward()\n",
    "                errD = errD_real + errD_fake\n",
    "                optimizerD.step()\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                label.fill_(real_label)\n",
    "                output = netD(fake).view(-1)\n",
    "                errG = self.objective(output, label)\n",
    "                errG.backward()\n",
    "                optimizerG.step()\n",
    "                print(f'Epoch {epoch}; Iteration ({i}/ {len(train_loader)}); errD: {errD}; errG; {errG};\\r', end='')\n",
    "                    \n",
    "                it += 1\n",
    "\n",
    "            epoch += 1\n",
    "            if self.n_epochs is not None and epoch >= self.n_epochs:\n",
    "                return\n",
    "            \n",
    "docs.create_trainer('gan_trainer', GANTrainer, serializer='dill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491d015",
   "metadata": {},
   "source": [
    "Now we're ready to do the training. The following command starts the trainer on one of the worker nodes.\n",
    "We can watch the job output with the `watch_job` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85114ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = docs.create_learning_task(\n",
    "    'face_generation',\n",
    "    'gan_trainer',\n",
    "    'gan',\n",
    "    ['generator', 'discriminator'],\n",
    "    ['_base', 'img'],\n",
    "    objective='bce',\n",
    "    trainer_kwargs={'batch_size': 100, 'validation_interval': 100, 'log_weights': True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0badcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(jobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea4bee",
   "metadata": {},
   "source": [
    "We can also inspect the example outputs created during the training process here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for im in docs.database.get_object_info('face_generation', 'learning_task', decode_types=True)['train_samples']:\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab873766",
   "metadata": {},
   "source": [
    "The model is served on the model server by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b1e004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAAsUlEQVR4nO3YwQ6EIAxFUfT//xk3LtSAChTyKPdsnSC80ppMCAAAtNokl1pHNFhj+uAtQtB7FUpkChO/f4K76cfBIHLXSW5DyHvvstxTerOBSXg0WULvUAj9L8ukSL2C7YQeMu8TdfZY+ueZ+JaiRvfe2I3WcdfE7g50Mdk0atpuzzqa5SheEM+9kMQ/eUqoQBHxYYIQ5O602HZGOI/8v1voqwLyF0p+g70tHwAAAJB0AEEZHfc573NFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.apply_model('generator', torch.randn(100, 1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d92f42b-7160-4965-a0ef-5e4ce46bd529",
   "metadata": {},
   "source": [
    "# Fine tune LLM on database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b39819c-2bc3-49a3-b285-d13b6ccc1242",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "APPLY = True\n",
    "TABLE_NAME = 'sample_llm_finetuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:07.84\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.misc.importing\u001b[0m:\u001b[36m13  \u001b[0m | \u001b[1mLoading plugin: mongodb\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:07.89\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m178 \u001b[0m | \u001b[1mCreating artifact store directory\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:07.91\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m51  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:07.91\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m68  \u001b[0m | \u001b[1mData Layer built\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:07.92\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.backends.base.cluster\u001b[0m:\u001b[36m112 \u001b[0m | \u001b[1mCluster initialized in 0.00 seconds.\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:07.92\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.build\u001b[0m:\u001b[36m150 \u001b[0m | \u001b[1mConfiguration: \n",
      " +----------------+-------------------------------+\n",
      "| Configuration  |             Value             |\n",
      "+----------------+-------------------------------+\n",
      "|  Data Backend  |      mongomock://test_db      |\n",
      "| Artifact Store | filesystem://./artifact_store |\n",
      "|     Cache      |           in-process          |\n",
      "+----------------+-------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock://test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get LLM Finetuning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5169e-ab2f-4eac-bd3f-30fd845f2a1b",
   "metadata": {},
   "source": [
    "The following are examples of training data in different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b37c7dc-390a-428b-916a-09d191678cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-26 20:51:08] datasets INFO PyTorch version 2.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from superduper.base.document import Document\n",
    "\n",
    "def getter():\n",
    "\n",
    "    dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"test\"]\n",
    "    \n",
    "    train_documents = [{**example, \"_fold\": \"train\"} for example in train_dataset][:10]\n",
    "    eval_documents = [{**example, \"_fold\": \"valid\"} for example in eval_dataset][:5]\n",
    "    \n",
    "    data = train_documents + eval_documents\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef3a6a1-732c-4896-b00b-8624876533a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "[2025-03-26 20:51:09] huggingface_hub.repocard WARNING Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "if APPLY:\n",
    "    data = getter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a4705-e7d6-4244-9150-bfa8372f85ba",
   "metadata": {},
   "source": [
    "We can define different training parameters to handle this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c824212e-0c4f-4b93-b3fa-4d2a105fc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "key = ('text')\n",
    "training_kwargs=dict(dataset_text_field=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a1ec0-bf28-4b59-8be1-e7bcfd4eeccc",
   "metadata": {},
   "source": [
    "Example input_text and output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb8c36c-97f8-40f4-8b8d-736d55352138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: --------------\n",
      "### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \n",
      "Response: --------------\n",
      "\"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\n",
      "\n",
      "Recent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\n",
      "\n",
      "Overall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\n",
      "\n",
      "References:\n",
      "Bivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.\n"
     ]
    }
   ],
   "source": [
    "if APPLY:\n",
    "    d = data[0]\n",
    "    input_text, output_text = d[\"text\"].rsplit(\"### Assistant: \", maxsplit=1)\n",
    "    input_text += \"### Assistant: \"\n",
    "    output_text = output_text.rsplit(\"### Human:\")[0]\n",
    "    print(\"Input: --------------\")\n",
    "    print(input_text)\n",
    "    print(\"Response: --------------\")\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bc0ba",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbdf015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'sample_llm_finetuning')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m89  \u001b[0m | \u001b[1mFound these changes and/ or additions that need to be made:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m91  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m92  \u001b[0m | \u001b[1mMETADATA EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m93  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m104 \u001b[0m | \u001b[1m[0]: Table:sample_llm_finetuning:4d10ae1f24e5b7094036ec76a1fc738b: create\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m106 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m107 \u001b[0m | \u001b[1mJOBS EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m108 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m112 \u001b[0m | \u001b[1mNo job events...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m123 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.event\u001b[0m:\u001b[36m142 \u001b[0m | \u001b[1mCreating superduper.components.table.Table:sample_llm_finetuning:4d10ae1f24e5b7094036ec76a1fc738b\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Table')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.backends.local.compute\u001b[0m:\u001b[36m39  \u001b[0m | \u001b[33m\u001b[1mCould not release futures for context 4d10ae1f24e5b7094036ec76a1fc738b\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:11.76\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'sample_llm_finetuning')) from metadata...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import Table\n",
    "\n",
    "table_or_collection = db[TABLE_NAME]\n",
    "\n",
    "if APPLY:\n",
    "    db.apply(\n",
    "        Table(\n",
    "            TABLE_NAME,\n",
    "            fields={'text': 'str', '_fold': 'str'},\n",
    "        ),\n",
    "        force=True\n",
    "    )\n",
    "    \n",
    "    table_or_collection.insert(data)\n",
    "\n",
    "select = table_or_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46a283-4fef-40d8-8df4-7023479ec2dd",
   "metadata": {},
   "source": [
    "## Select a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ef0e1e-22ea-4af3-b914-1a3eed23a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model_kwargs = dict()\n",
    "tokenizer_kwargs = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf339d2-6eaa-4a90-8718-6d6e6120c400",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build A Trainable LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c2662-ce55-4767-8e3d-ef3901fd31ee",
   "metadata": {},
   "source": [
    "**Create an LLM Trainer for training**\n",
    "\n",
    "The parameters of this LLM Trainer are basically the same as `transformers.TrainingArguments`, but some additional parameters have been added for easier training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5deed34b-189c-4662-8972-aed92718225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_transformers import LLM, LLMTrainer\n",
    "\n",
    "trainer = LLMTrainer(\n",
    "    identifier=\"llm-finetune-trainer\",\n",
    "    output_dir=\"output/finetune\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=10,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    key=key,\n",
    "    select=select,\n",
    "    transform=transform,\n",
    "    training_kwargs=training_kwargs,\n",
    "    use_lora=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370f6c8-ce2f-443e-ae89-a4e95c4375a8",
   "metadata": {},
   "source": [
    "Create a trainable LLM model and add it to the database, then the training task will run automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400c1ebb-345e-4030-9f9e-96099f53664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    identifier=\"llm\",\n",
    "    model_name_or_path=model_name,\n",
    "    trainer=trainer,\n",
    "    model_kwargs=model_kwargs,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb0dd6a-2bc8-4288-9b99-49e1ab214965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:13.56\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('LLM', 'llm')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.56\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('LLMTrainer', 'llm-finetune-trainer')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m89  \u001b[0m | \u001b[1mFound these changes and/ or additions that need to be made:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m91  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m92  \u001b[0m | \u001b[1mMETADATA EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m93  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m100 \u001b[0m | \u001b[1m[0]: LLMTrainer:llm-finetune-trainer:2bd3f6003ba38731e4c8d18972dd920a: create ~ [1]\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m104 \u001b[0m | \u001b[1m[1]: LLM:llm:368e94ede0053dbd49d25ef9bf22d852: create\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m106 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m107 \u001b[0m | \u001b[1mJOBS EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m108 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m121 \u001b[0m | \u001b[1m[0]: LLM:llm:368e94ede0053dbd49d25ef9bf22d852.fit_in_db: fit_in_db\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m116 \u001b[0m | \u001b[1m[1]: LLM:llm:368e94ede0053dbd49d25ef9bf22d852.set_status: set_status ~ [0]\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m123 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.event\u001b[0m:\u001b[36m142 \u001b[0m | \u001b[1mCreating superduper_transformers.training.LLMTrainer:llm-finetune-trainer:2bd3f6003ba38731e4c8d18972dd920a\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ArtifactRelations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Table')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'LLMTrainer')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.59\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ParentChildAssociations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.60\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.event\u001b[0m:\u001b[36m142 \u001b[0m | \u001b[1mCreating superduper_transformers.model.LLM:llm:368e94ede0053dbd49d25ef9bf22d852\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.60\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ArtifactRelations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.60\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Table')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.60\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'LLM')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:13.62\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Job')) from metadata...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:15.34\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m290 \u001b[0m | \u001b[1mStart training, experiment_id: 36f73c9bf63b6ec25ee7488c8a83bc8db9cfc91b\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m493 \u001b[0m | \u001b[1mStart training LLM model\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m494 \u001b[0m | \u001b[1mtraining_args: LLMTrainer(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "bits=None,\n",
      "compute_kwargs={},\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=100,\n",
      "eval_strategy=steps,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "identifier=llm-finetune-trainer,\n",
      "ignore_data_skip=False,\n",
      "in_memory=True,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "key=text,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "log_to_db=True,\n",
      "logging_dir=output/finetune/runs/Mar26_20-51-15_Duncans-MBP.fritz.box,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1,\n",
      "logging_strategy=steps,\n",
      "lora_alpha=16,\n",
      "lora_bias=none,\n",
      "lora_dropout=0.05,\n",
      "lora_r=8,\n",
      "lora_target_modules=all-linear,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_seq_length=512,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "metric_values={},\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_gpus=None,\n",
      "num_train_epochs=2,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=output/finetune,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_configs=None,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/finetune,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=10,\n",
      "seed=42,\n",
      "select={'parts': (), 'table': 'sample_llm_finetuning'},\n",
      "setup_chat_format=False,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "training_kwargs={'dataset_text_field': 'text'},\n",
      "transform=None,\n",
      "upstream=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_lora=True,\n",
      "use_mps_device=False,\n",
      "validation=None,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m515 \u001b[0m | \u001b[1mOverwriting model_kwargs for LLM training\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m516 \u001b[0m | \u001b[1mquantization_config: None\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m517 \u001b[0m | \u001b[1mdevice_map: mps\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:15.35\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m521 \u001b[0m | \u001b[1mmodel_kwargs: {'pretrained_model_name_or_path': 'Qwen/Qwen2.5-0.5B', 'quantization_config': None, 'device_map': 'mps'}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.10.13/envs/superduper-3.10/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:16.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m525 \u001b[0m | \u001b[1mtokenizer_kwargs: %s {'pretrained_model_name_or_path': 'Qwen/Qwen2.5-0.5B'}\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:16.38\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m540 \u001b[0m | \u001b[1mPreparing LoRA training\u001b[0m\n",
      "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.10.13/envs/superduper-3.10/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/dodo/.pyenv/versions/3.10.13/envs/superduper-3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/Users/dodo/.pyenv/versions/3.10.13/envs/superduper-3.10/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e107c1f757443b9fae0e41fbd60292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a0d0f231844428917f11bf6b7f43bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:16.66\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.training\u001b[0m:\u001b[36m556 \u001b[0m | \u001b[1mAdd callback <superduper_transformers.training.LLMCallback object at 0x2d1b44e50>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:26.82\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('LLM', 'llm')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.84\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('LLMTrainer', 'llm-finetune-trainer')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945 already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/b7595e2a863957fc6c225ed540d335dd1e859dd3032451c2e11bceb0329defa6 already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/fe2d01de4181686ab3446912f6b2a6f37c94ceb41b6da8d772951878450be403 already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/140bedbf9c3f6d56a9846d2ba7088798683f4da0c248231336e6a05679e4fdfe already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Checkpoint', '36f73c9bf63b6ec25ee7488c8a83bc8db9cfc91b')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.artifacts\u001b[0m:\u001b[36m243 \u001b[0m | \u001b[33m\u001b[1mFile ./artifact_store/e234ee35f82c5dd3f2f20ef0835225e326805e56b5fe83ee5e56c0f899f4901d already exists\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.87\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m86  \u001b[0m | \u001b[1mFound this diff:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">llm\n",
       "â”œâ”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">llm</span>\n",
       "â”‚   â””â”€â”€ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">status: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">update</span>\n",
       "â””â”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">llm-finetune-trainer</span>\n",
       "    â””â”€â”€ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">status: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">update</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "llm\n",
       "â”œâ”€â”€ \u001b[1;33mllm\u001b[0m\n",
       "â”‚   â””â”€â”€ \u001b[1;36mstatus: \u001b[0m\u001b[1;34mupdate\u001b[0m\n",
       "â””â”€â”€ \u001b[1;33mllm-finetune-trainer\u001b[0m\n",
       "    â””â”€â”€ \u001b[1;36mstatus: \u001b[0m\u001b[1;34mupdate\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m89  \u001b[0m | \u001b[1mFound these changes and/ or additions that need to be made:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m91  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m92  \u001b[0m | \u001b[1mMETADATA EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m93  \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m100 \u001b[0m | \u001b[1m[0]: LLMTrainerllm-finetune-trainer:2bd3f6003ba38731e4c8d18972dd920a: update ~ [2]\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m100 \u001b[0m | \u001b[1m[1]: Checkpoint:36f73c9bf63b6ec25ee7488c8a83bc8db9cfc91b:e2973c41a7d01b0262f5dcadea1649dd: create ~ [2]\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m104 \u001b[0m | \u001b[1m[2]: LLMllm:368e94ede0053dbd49d25ef9bf22d852: update\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m106 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m107 \u001b[0m | \u001b[1mJOBS EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m108 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m112 \u001b[0m | \u001b[1mNo job events...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.apply\u001b[0m:\u001b[36m123 \u001b[0m | \u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ArtifactRelations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.event\u001b[0m:\u001b[36m142 \u001b[0m | \u001b[1mCreating superduper.components.training.Checkpoint:36f73c9bf63b6ec25ee7488c8a83bc8db9cfc91b:e2973c41a7d01b0262f5dcadea1649dd\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Table')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Checkpoint')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ParentChildAssociations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.88\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'ArtifactRelations')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:26.90\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m408 \u001b[0m | \u001b[1mLoad (('Table', 'Job')) from metadata...\u001b[0m\n",
      "\u001b[32m2025-Mar-26 20:51:27.73\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_transformers.model\u001b[0m:\u001b[36m346 \u001b[0m | \u001b[1mLoading adapter from output/finetune/checkpoint-10\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "if APPLY:\n",
    "    db.apply(llm, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3440967-bd90-40d7-b78d-caab78f9472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template, Table, Application\n",
    "from superduper.components.dataset import RemoteData\n",
    "\n",
    "llm.trainer.use_lora = \"<var:use_lora>\"\n",
    "llm.trainer.num_train_epochs = \"<var:num_train_epochs>\"\n",
    "\n",
    "app = Application(identifier=\"llm\", components=[llm])\n",
    "\n",
    "t = Template(\n",
    "    'llm-finetune',\n",
    "    template=app,\n",
    "    substitutions={\n",
    "        TABLE_NAME: 'table_name',\n",
    "        model_name: 'model_name',\n",
    "    },\n",
    "    default_tables=[\n",
    "        Table(\n",
    "            'sample_llm_finetuning',\n",
    "            fields={'x': 'str', 'y': 'int'},\n",
    "            data=RemoteData(\n",
    "                'llm_finetuning',\n",
    "                getter=getter,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    template_variables=['table_name', 'model_name', 'use_lora', 'num_train_epochs'],\n",
    "    types={\n",
    "        'collection': {\n",
    "            'type': 'str',\n",
    "            'default': 'dataset',\n",
    "        },\n",
    "        'model_name': {\n",
    "            'type': 'str',\n",
    "            'default': 'Qwen/Qwen2.5-0.5B',\n",
    "        },\n",
    "        'use_lora': {\n",
    "            'type': 'bool',\n",
    "            'default': True,\n",
    "        },\n",
    "        'num_train_epochs': {\n",
    "            'type': 'int',\n",
    "            'default': 3\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': 'sample_llm_finetuning',\n",
    "        },\n",
    "    },\n",
    "    db=db,\n",
    ")\n",
    "\n",
    "t.export('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd846d-aa81-456f-b2ea-fc2d230a41a2",
   "metadata": {},
   "source": [
    "## Load the trained model\n",
    "There are two methods to load a trained model:\n",
    "\n",
    "- **Load the model directly**: This will load the model with the best metrics (if the transformers' best model save strategy is set) or the last version of the model.\n",
    "- **Use a specified checkpoint**: This method downloads the specified checkpoint, then initializes the base model, and finally merges the checkpoint with the base model. This approach supports custom operations such as resetting flash_attentions, model quantization, etc., during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e1a0d-c760-4a01-b4bf-c6e83296ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    llm = db.load(\"LLM\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8933b-723d-481c-9d6e-dff14d256377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    print(llm.predict(input_text, max_new_tokens=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fea927-ee4a-44cd-aaf2-634b574c316d",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Apply a chunker for search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90bda-e8c4-494e-a38c-837fb63689ae",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that applying a chunker is ***not*** mandatory for search.\n",
    "If your data is already chunked (e.g. short text snippets or audio) or if you\n",
    "are searching through something like images, which can't be chunked, then this\n",
    "won't be necessary.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20eaa0-a416-4483-938e-23f79845739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "from superduperdb import objectmodel\n",
    "\n",
    "CHUNK_SIZE = 200\n",
    "\n",
    "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False})\n",
    "def chunker(text):\n",
    "    text = text.split()\n",
    "    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd7dc0-fffa-40d8-af72-2b9e4852ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: PDF>\n",
    "!pip install -q \"unstructured[pdf]\"\n",
    "from superduperdb import objectmodel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import PyPDF2\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False})\n",
    "def chunker(pdf_file):\n",
    "    elements = partition_pdf(pdf_file)\n",
    "    text = '\\n'.join([e.text for e in elements])\n",
    "    chunks = [text[i:i + CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51026c79-a221-4bb5-bcff-bfec129056c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <testing: >\n",
    "!curl -O 'https://arxiv.org/pdf/2303.08774.pdf?fbclid=IwAR2XS6JT2NLIP4MjFn9npot34FhddoqStNbLwIvWETf5ZGlCPsIbuYneo8s&mibextid=Zxz2cZ'\n",
    "chunks = chunker('2303.08774.pdf')\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093a6d0-9d2f-4ecf-b1bd-0027302c62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Video>\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from superduperdb.ext.pillow import pil_image\n",
    "from superduperdb import objectmodel, Schema\n",
    "\n",
    "\n",
    "@objectmodel(\n",
    "    flatten=True,\n",
    "    model_update_kwargs={'document_embedded': False},\n",
    ")\n",
    "def chunker(video_file):\n",
    "    # Set the sampling frequency for frames\n",
    "    sample_freq = 10\n",
    "    \n",
    "    # Open the video file using OpenCV\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # Initialize variables\n",
    "    frame_count = 0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    extracted_frames = []\n",
    "    progress = tqdm.tqdm()\n",
    "\n",
    "    # Iterate through video frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Get the current timestamp based on frame count and FPS\n",
    "        current_timestamp = frame_count // fps\n",
    "        \n",
    "        # Sample frames based on the specified frequency\n",
    "        if frame_count % sample_freq == 0:\n",
    "            extracted_frames.append({\n",
    "                'image': Image.fromarray(frame[:,:,::-1]),  # Convert BGR to RGB\n",
    "                'current_timestamp': current_timestamp,\n",
    "            })\n",
    "        frame_count += 1\n",
    "        progress.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Return the list of extracted frames\n",
    "    return extracted_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4db9f-bea2-4156-bd78-11eb3bbcf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Audio>\n",
    "from superduperdb import objectmodel, Schema\n",
    "\n",
    "CHUNK_SIZE = 10  # in seconds\n",
    "\n",
    "@objectmodel(\n",
    "    flatten=True,\n",
    "    model_update_kwargs={'document_embedded': False},\n",
    "    output_schema=Schema(identifier='output-schema', fields={'audio': datatype}),\n",
    ")\n",
    "def chunker(audio):\n",
    "    chunks = []\n",
    "    for i in range(0, len(audio), CHUNK_SIZE):\n",
    "        chunks.append(audio[1][i: i + CHUNK_SIZE])\n",
    "    return [(audio[0], chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f",
   "metadata": {},
   "source": [
    "Now we apply this chunker to the data by wrapping the chunker in `Listener`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb import Listener\n",
    "\n",
    "upstream_listener = Listener(\n",
    "    model=chunker,\n",
    "    select=select,\n",
    "    key='x',\n",
    "    uuid=\"chunk\",\n",
    ")\n",
    "\n",
    "db.apply(upstream_listener)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

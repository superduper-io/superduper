{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213682c6",
   "metadata": {},
   "source": [
    "# Image retrieval, captioning and classification with CoCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38bc025",
   "metadata": {},
   "source": [
    "This tutorial uses the [CoCo dataset \"Common objects in Context\"](https://cocodataset.org/#home) to show case some of the key-features of SuperDuperDB. In this example, you'll learn how to:\n",
    "\n",
    "- Prepare data in the best way for SuperDuperDB usage\n",
    "- Define data types\n",
    "- Upload and query data to and from the data base\n",
    "- Define multiple models on the database, including models with dependencies\n",
    "- Define a searchable semantic index based on existing models\n",
    "- Train a semantic index from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66577c0c",
   "metadata": {},
   "source": [
    "If you haven't downloaded the data already, execute the lines of bash below. We've tried to keep it clean,\n",
    "and for reasons of efficiency have resized the images using imagemagick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -o data/coco/\n",
    "!curl http://images.cocodataset.org/annotations/annotations_trainval2014.zip -o data/coco/raw.zip\n",
    "!unzip data/coco/raw.zip\n",
    "!mv data/coco/annotations/captions_train2014.json data/coco/\n",
    "!rm -rf data/coco/annotations\n",
    "!rm data/coco/raw.zip\n",
    "!curl http://images.cocodataset.org/zips/train2014.zip -o data/coco/images.zip\n",
    "!unzip data/coco/images.zip\n",
    "!rm data/coco/images.zip\n",
    "!sudo apt install imagemagick\n",
    "!mogrify -resize 224x data/coco/images/*.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455a1c8",
   "metadata": {},
   "source": [
    "SuperDuperDB uses MongoDB for data storage. If you haven't done so already, install it using the following lines of bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ec394",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "!sudo apt-get install gnupg\n",
    "!wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "!echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y mongodb-org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6dc87",
   "metadata": {},
   "source": [
    "In case you haven't done so already, install the dependencies for this tutorial, including SuperDuperDB,\n",
    "which is a simple pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install torch\n",
    "!pip install superduperdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1e6e1",
   "metadata": {},
   "source": [
    "SuperDuperDB can handle data in any format, including images. The documents in the database are MongoDB `bson` documents, which mix `json` with raw bytes and `ObjectId` objects. SuperDuperDB takes advantage of this by \n",
    "serializing more sophisticated objects to bytes, and reinstantiating the objects in memory, when data is queried.\n",
    "\n",
    "In order to tell SuperDuperDB what type an object has, one specifies this with a subdocument of the form:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"bytes\": ...,\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If however, the content is located on the web or the filesystem, one can specify the URLs directly:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"url\": \"<url-or-file>\",\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's see this now in action. We reformat the CoCo data, so that each image is associated in one document with all of the captions which describe it, and add the location of the images using the `_content` formalism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/coco/captions_train2014.json') as f:\n",
    "    raw = json.load(f)\n",
    "    \n",
    "raw['images'] = {x['id']: x for x in raw['images']}\n",
    "\n",
    "for im in raw['images']:\n",
    "    raw['images'][im]['captions'] = []\n",
    "    \n",
    "for a in raw['annotations']:\n",
    "    raw['images'][a['image_id']]['captions'].append(a['caption'])\n",
    "\n",
    "raw = list(raw['images'].values())\n",
    "\n",
    "for i, im in enumerate(raw):\n",
    "    # if image is already in memory, then add 'bytes': b'...' instead of 'url': '...'\n",
    "    # for content located on the web, use 'http://' or 'https://' instead of 'file://'\n",
    "    im['img'] = {\n",
    "        '_content': {'url': f'file://data/coco/images/{im[\"file_name\"]}', 'type': 'image'}\n",
    "    }\n",
    "    raw[i] = {'captions': im['captions'], 'img': im['img']}\n",
    "\n",
    "with open('data/coco/data.json', 'w') as f:\n",
    "    json.dump(raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a45f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from superduperdb.client import the_client\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "\n",
    "docs = the_client.coco_example.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b03ae",
   "metadata": {},
   "source": [
    "We'll load the data and add most of it to the database. We'll hold back some data so that we can see how to update \n",
    "the database later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf022c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('data/coco/data.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "docs.insert_many(data[:-1000]), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f7c0",
   "metadata": {},
   "source": [
    "We previously added the type `image` to the `_content` subrecords earlier.\n",
    "So that we can load the data using this type, we need to add this type to the database.\n",
    "You can see in `examples/types.py` how the class encodes and decodes data. Suffice to say at this point, \n",
    "that each type has an `encode` and `decode` method, which convert to and from `bytes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2728cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.types import FloatTensor, Image\n",
    "\n",
    "docs.create_type('float_tensor', FloatTensor())\n",
    "docs.create_type('image', Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70298808",
   "metadata": {},
   "source": [
    "In the first AI task which we implement for the `docs` collection, we'll be setting up a model to retrieve relevant images using provided text. For this data, that means the `captions` field being used to retrieve the `img` field. In order to be able to keep an objective record of performance, we can set up an immutable validation dataset from the collection. We use a **splitter** to define how we'd like to test retrieval. This splits the documents into query and retrieved document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8565389",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_validation_set(\n",
    "    'text2image_retrieval', \n",
    "    filter={},\n",
    "    splitter=lambda x: ({'img': x['img']}, {'captions': [x['captions'][0]]}),\n",
    "    sample_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c91f7",
   "metadata": {},
   "source": [
    "We can see what the data points in the validation set look like by querying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c171e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'text2image_retrieval'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2550b",
   "metadata": {},
   "source": [
    "You can see that the sample \"query\" is split into the `_other` field. This is important when evaluating semantic indexes.\n",
    "\n",
    "Now let's start adding a model to the collection.\n",
    "A nice open source model to test text-2-image retrieval is [CLIP](https://openai.com/blog/clip/) which understands images and texts and embeds these in a common vector space.\n",
    "\n",
    "Note that we are specifying the type of the model output, so that the collection knows how to store the results, as well as \"activating\" the model with `active=True`. That means, whenever we add data which fall under the `filter`, then these will get processed by the model, and the outputs will be added to the collection documents.\n",
    "\n",
    "The `key` argument specifies which part of the document the model should act. If `key=\"_base\"` then the model takes the whole document as input. Since we'll be encoding documents as images, then we'll chose `key=\"img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import CLIP\n",
    "\n",
    "docs.create_model(\n",
    "    name='clip',\n",
    "    object=CLIP('RN50'),\n",
    "    filter={},\n",
    "    type='float_tensor',\n",
    "    key='img',\n",
    "    verbose=True,\n",
    "    active=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861db6a0",
   "metadata": {},
   "source": [
    "We'll create a companion model which uses the same underlying object as the previous model. That's specified by adding the name instead of the object in the `object` argument. In this case the model is not `active`, since we'll only be using it for querying the collection. We don't need to specify a `type` since that was done in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    name='clip_text',\n",
    "    object='clip',\n",
    "    key='captions',\n",
    "    active=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908e762",
   "metadata": {},
   "source": [
    "We'll also create a measure which tests how similar to each other two outputs might be. Since CLIP was trained with cosine-similarity we'll use that here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.measures import css\n",
    "\n",
    "docs.create_measure('css', css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8af6c",
   "metadata": {},
   "source": [
    "In order to be able to measure performance on the validation set, we'll add a **metric**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66911bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.metrics import PatK\n",
    "\n",
    "docs.create_metric('p_at_10', PatK(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d34b2f",
   "metadata": {},
   "source": [
    "Now we're ready to go to add a **semantic index**. This is a tuple of models, one of which is activated in order to populate the collection with vectors. The idea is that any of the models in the **semantic index** can be used to query the collection using nearest neighbour lookup based on the **measure** chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd71ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.models import CLIP\n",
    "\n",
    "docs.create_semantic_index(\n",
    "    'clip',\n",
    "    models=['clip', 'clip_text'],\n",
    "    measure='css',\n",
    "    metrics=['p_at_10'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a38189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'clip'\n",
    "for r in docs.find({'$like': {'document': {'_id': ObjectId('63d27372745cc274ef3518f2')}, 'n': 10}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76310241",
   "metadata": {},
   "source": [
    "Let's now evaluate the quality of this semantic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.validate_semantic_index('clip', ['text2image_retrieval'], ['p_at_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_semantic_indexes'].find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac54e49",
   "metadata": {},
   "source": [
    "We can see that we can get nice meaningful retrievals using the CLIP model from short descriptive pieces of text.\n",
    "This is very useful, since the model is now deployed to the database, listening for incoming queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_semantic_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e0e73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'clip'\n",
    "for r in docs.find({'$like': {'document': {'captions': ['Dog catches a frisbee']}, 'n': 5}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f2c87",
   "metadata": {},
   "source": [
    "In the next section of this example, let us train our own model from scratch. The model will be much simpler than the clip model, but will yield faster retrievals. It will be interesting to see how this compares to CLIP, and show-case SuperDuperDB as a framework for easily integrating and benchmarking AI models, in particular for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9293c",
   "metadata": {},
   "source": [
    "First we will implement a simpler sentence embedding, using a simple word-embedding approach based around Glove.\n",
    "Please look at the model in `examples.models.AverageOfGloves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://nlp.stanford.edu/data/glove.6B.zip -o data/glove.6B.zip\n",
    "!unzip data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb979e",
   "metadata": {},
   "source": [
    "We may register this model to the collection in the same way we did for the textual part of CLIP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from examples.models import AverageOfGloves\n",
    "\n",
    "with open('data/glove.6B/glove.6B.50d.txt') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "lines = [x.split(' ') for x in lines[:-1]]\n",
    "index = [x[0] for x in lines]\n",
    "vectors = [[float(y) for y in x[1:]] for x in lines]\n",
    "vectors = numpy.array(vectors)\n",
    "\n",
    "glove = AverageOfGloves(torch.from_numpy(vectors).type(torch.float), index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'average_glove',\n",
    "    object=glove,\n",
    "    key='captions',\n",
    "    active=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d4c37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'clip_projection',\n",
    "    object=torch.nn.Linear(1024, 50),\n",
    "    active=True,\n",
    "    key='img',\n",
    "    type='float_tensor',\n",
    "    features={'img': 'clip'},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecddf4",
   "metadata": {},
   "source": [
    "Let's also create a loss function, in order to be able to perform the learning task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aebdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.losses import ranking_loss\n",
    "\n",
    "docs.create_loss('ranking_loss', ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a44467",
   "metadata": {},
   "source": [
    "A semantic index training requires:\n",
    "\n",
    "- 1 or more models\n",
    "- A measure function to measure similarity between model outputs\n",
    "- A loss function\n",
    "- One or more validation sets\n",
    "- One or more metrics to measure performance\n",
    "\n",
    "We now have all of these things ready and registered with the database, so we can start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf5276",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_semantic_index(\n",
    "    'simple_image_search',\n",
    "    models=['clip_projection', 'average_glove'],\n",
    "    loss='ranking_loss',\n",
    "    filter={},\n",
    "    projection={'image': 0, '_like': 0},\n",
    "    metrics=['p_at_10'],\n",
    "    measure='css',\n",
    "    validation_sets=['text2image_retrieval'],\n",
    "    batch_size=250,\n",
    "    num_workers=0,\n",
    "    n_epochs=20,\n",
    "    lr=0.001,\n",
    "    log_weights=True,\n",
    "    download=True,\n",
    "    validation_interval=50,\n",
    "    no_improve_then_stop=5,\n",
    "    n_iterations=5000,\n",
    "    use_grads={'clip_projection': True, 'average_glove': False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0041c4c",
   "metadata": {},
   "source": [
    "We now can see that we've set and trained our own semantic index. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_semantic_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6771a45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "info = docs['_semantic_indexes'].find_one({'name': 'simple_image_search'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18871e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in info['metric_values']:\n",
    "    if k == 'loss':\n",
    "        print(info['metric_values'][k])\n",
    "        plt.figure()\n",
    "        plt.title('loss')\n",
    "        plt.plot(info['metric_values'][k])\n",
    "        continue\n",
    "    for result in info['metric_values'][k]:\n",
    "        plt.figure()\n",
    "        plt.title(f'{k}/{result}')\n",
    "        plt.plot(info['metric_values'][k][result])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in info['weights']:\n",
    "    plt.figure()\n",
    "    plt.title(parameter)\n",
    "    plt.plot(info['weights'][parameter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc334d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.refresh_model('clip_projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'simple_image_search'\n",
    "for r in docs.find({'$like': {'document': {'captions': ['Dog catches frisbee']}, 'n': 5}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ff23d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.models import NounWords\n",
    "docs.create_model('noun_words', NounWords(), verbose=True, key='captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aebe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_validation_set('attribute_prediction', sample_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tqdm\n",
    "all_nouns = []\n",
    "for r in tqdm.tqdm(docs.find({'_fold': 'train'}, {'_outputs.captions.noun_words': 1}), total=docs.count_documents({})):\n",
    "    all_nouns.extend(r['_outputs']['captions']['noun_words'])\n",
    "    \n",
    "counts = dict(collections.Counter(all_nouns))\n",
    "all_nouns = [w for w in counts if counts[w] > 30]\n",
    "total = docs.count_documents({})\n",
    "pos_weights = [counts[w] / total for w in all_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import FewHot, TopK\n",
    "from examples.metrics import jacquard_index\n",
    "\n",
    "docs.create_model('nouns_to_few_hot', FewHot(all_nouns))\n",
    "docs.create_postprocessor('top_5', TopK(all_nouns, 5))\n",
    "docs.create_forward('attribute_predictor', torch.nn.Linear(1024, len(all_nouns)))\n",
    "docs.create_loss('nouns_loss', torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weights)))\n",
    "docs.create_metric('jacquard_index', jacquard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a444d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import FewHot\n",
    "docs.create_model('nouns_to_few_hot', FewHot(post.tokens), active=False,\n",
    "                 key='_outputs.captions.noun_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be2dbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model('attribute_predictor', forward='attribute_predictor', postprocessor='top_5',\n",
    "                  key='img', features={'img': 'clip'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d80959",
   "metadata": {},
   "source": [
    "Let's test the model, using the `apply_model` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06695727",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.apply_model('attribute_predictor', docs.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e45e59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_imputation(\n",
    "    'noun_prediction',\n",
    "    model='attribute_predictor',\n",
    "    target='nouns_to_few_hot',\n",
    "    loss='nouns_loss',\n",
    "    metrics=['jacquard_index'],\n",
    "    validation_sets=['attribute_prediction'],\n",
    "    lr=0.001,\n",
    "    validation_interval=10,\n",
    "    n_iterations=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dc496",
   "metadata": {},
   "source": [
    "We can view the results of learning (metrics, loss etc.) by looking in the `_imputations` subcollection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfcd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from superduperdb.client import the_client\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "\n",
    "docs = the_client.coco_example.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4166411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "\n",
    "all_captions = []\n",
    "n = docs.count_documents({'_fold': 'train'})\n",
    "for r in tqdm.tqdm_notebook(docs.find({'_fold': 'train'}, {'captions': 1, '_id': 0}), total=n):\n",
    "    all_captions.extend(r['captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "all_captions = [re.sub('[^a-z ]', '', x.lower()).strip() for x in all_captions]\n",
    "words = ' '.join(all_captions).split(' ')\n",
    "counts = dict(collections.Counter(words))\n",
    "vocab = sorted([w for w in counts if counts[w] > 5 and w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import ConditionalLM, SimpleTokenizer\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "m = ConditionalLM(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cd4be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model('conditional_lm', object=m, active=False, features={'img': 'clip'}, key='_base')\n",
    "docs.create_model('captioning_tokenizer', tokenizer, key='caption', active=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.delete_model('conditional_lm', force=True)\n",
    "docs.delete_model('captioning_tokenizer', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e501979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.losses import auto_regressive_loss\n",
    "docs.create_loss('autoregressive_loss', auto_regressive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'attribute_prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.splitters import captioning_splitter\n",
    "\n",
    "docs.create_splitter('captioning_splitter', captioning_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_splitter(docs.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10344946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_validation_set('captioning', splitter=docs.splitters['captioning_splitter'],\n",
    "                           sample_size=500, chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb18cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'captioning'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa5079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading ids for {'_fold': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78560/78560 [00:00<00:00, 251116.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading records for {'_fold': 'valid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4223/4223 [00:00<00:00, 13220.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; loss: 2.997839229247149; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; loss: 2.9966535568237305; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; loss: 3.076786756515503; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; loss: 2.901592969894409; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; loss: 2.6879210472106934; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; loss: 2.722820520401001; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; loss: 2.9874303340911865; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; loss: 3.126953363418579; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; loss: 2.9845588207244873; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; loss: 3.059809923171997; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; loss: 2.9979238510131836; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; loss: 2.9937589168548584; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; loss: 2.9435641765594482; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; loss: 3.16536283493042; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; loss: 3.0007522106170654; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; loss: 2.7748944759368896; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; loss: 2.7708215713500977; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; loss: 2.8824245929718018; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; loss: 2.925311803817749; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; loss: 2.901021718978882; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; loss: 2.758570909500122; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; loss: 2.807732582092285; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; loss: 2.721203565597534; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; loss: 3.146812677383423; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; loss: 2.7373993396759033; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; loss: 3.0033254623413086; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; loss: 2.989243507385254; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; loss: 3.0350911617279053; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; loss: 2.8781402111053467; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; loss: 3.0982847213745117; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; loss: 2.991872549057007; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; loss: 2.9104654788970947; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; loss: 2.996716260910034; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; loss: 2.9108705520629883; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; loss: 2.8462438583374023; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; loss: 2.971713066101074; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; loss: 3.2212963104248047; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; loss: 3.094799280166626; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; loss: 3.0208539962768555; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; loss: 3.319326400756836; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; loss: 3.0017285346984863; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; loss: 2.8297371864318848; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; loss: 2.825871467590332; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; loss: 2.812410354614258; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; loss: 3.1291263103485107; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; loss: 2.9392752647399902; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; loss: 3.032214641571045; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; loss: 3.0501348972320557; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; loss: 3.038341760635376; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; loss: 2.910571575164795; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; loss: 3.272721290588379; \n",
      "fold: TRAIN; iteration: 50; epoch: 0; loss: 2.927846670150757; \n",
      "fold: TRAIN; iteration: 51; epoch: 0; loss: 2.985703468322754; \n",
      "fold: TRAIN; iteration: 52; epoch: 0; loss: 3.0828301906585693; \n",
      "fold: TRAIN; iteration: 53; epoch: 0; loss: 2.7460548877716064; \n",
      "fold: TRAIN; iteration: 54; epoch: 0; loss: 3.178971529006958; \n",
      "fold: TRAIN; iteration: 55; epoch: 0; loss: 2.8986763954162598; \n",
      "fold: TRAIN; iteration: 56; epoch: 0; loss: 3.0752933025360107; \n",
      "fold: TRAIN; iteration: 57; epoch: 0; loss: 3.0680713653564453; \n",
      "fold: TRAIN; iteration: 58; epoch: 0; loss: 3.0311574935913086; \n",
      "fold: TRAIN; iteration: 59; epoch: 0; loss: 2.805163621902466; \n",
      "fold: TRAIN; iteration: 60; epoch: 0; loss: 3.243602991104126; \n",
      "fold: TRAIN; iteration: 61; epoch: 0; loss: 2.977459192276001; \n",
      "fold: TRAIN; iteration: 62; epoch: 0; loss: 2.966531991958618; \n",
      "fold: TRAIN; iteration: 63; epoch: 0; loss: 2.8752379417419434; \n",
      "fold: TRAIN; iteration: 64; epoch: 0; loss: 2.924901008605957; \n",
      "fold: TRAIN; iteration: 65; epoch: 0; loss: 2.9090986251831055; \n",
      "fold: TRAIN; iteration: 66; epoch: 0; loss: 2.861773729324341; \n",
      "fold: TRAIN; iteration: 67; epoch: 0; loss: 2.9082205295562744; \n",
      "fold: TRAIN; iteration: 68; epoch: 0; loss: 2.9343574047088623; \n",
      "fold: TRAIN; iteration: 69; epoch: 0; loss: 2.935793399810791; \n",
      "fold: TRAIN; iteration: 70; epoch: 0; loss: 2.9617416858673096; \n",
      "fold: TRAIN; iteration: 71; epoch: 0; loss: 3.074796676635742; \n",
      "fold: TRAIN; iteration: 72; epoch: 0; loss: 2.8765981197357178; \n",
      "fold: TRAIN; iteration: 73; epoch: 0; loss: 3.081186294555664; \n",
      "fold: TRAIN; iteration: 74; epoch: 0; loss: 2.7671146392822266; \n",
      "fold: TRAIN; iteration: 75; epoch: 0; loss: 2.970212936401367; \n",
      "fold: TRAIN; iteration: 76; epoch: 0; loss: 2.936648368835449; \n",
      "fold: TRAIN; iteration: 77; epoch: 0; loss: 3.1312530040740967; \n",
      "fold: TRAIN; iteration: 78; epoch: 0; loss: 3.1051201820373535; \n",
      "fold: TRAIN; iteration: 79; epoch: 0; loss: 3.0820791721343994; \n",
      "fold: TRAIN; iteration: 80; epoch: 0; loss: 3.1793503761291504; \n",
      "fold: TRAIN; iteration: 81; epoch: 0; loss: 2.8256020545959473; \n",
      "fold: TRAIN; iteration: 82; epoch: 0; loss: 3.1567678451538086; \n",
      "fold: TRAIN; iteration: 83; epoch: 0; loss: 2.870800733566284; \n",
      "fold: TRAIN; iteration: 84; epoch: 0; loss: 3.301304817199707; \n",
      "fold: TRAIN; iteration: 85; epoch: 0; loss: 3.2727365493774414; \n",
      "fold: TRAIN; iteration: 86; epoch: 0; loss: 2.983400821685791; \n",
      "fold: TRAIN; iteration: 87; epoch: 0; loss: 2.9587366580963135; \n",
      "fold: TRAIN; iteration: 88; epoch: 0; loss: 3.10300874710083; \n",
      "fold: TRAIN; iteration: 89; epoch: 0; loss: 3.0071771144866943; \n",
      "fold: TRAIN; iteration: 90; epoch: 0; loss: 3.0959885120391846; \n",
      "fold: TRAIN; iteration: 91; epoch: 0; loss: 2.9554026126861572; \n",
      "fold: TRAIN; iteration: 92; epoch: 0; loss: 2.8245279788970947; \n",
      "fold: TRAIN; iteration: 93; epoch: 0; loss: 3.015768527984619; \n",
      "fold: TRAIN; iteration: 94; epoch: 0; loss: 3.00862455368042; \n",
      "fold: TRAIN; iteration: 95; epoch: 0; loss: 2.998661518096924; \n",
      "fold: TRAIN; iteration: 96; epoch: 0; loss: 3.1253292560577393; \n",
      "fold: TRAIN; iteration: 97; epoch: 0; loss: 3.0485970973968506; \n",
      "fold: TRAIN; iteration: 98; epoch: 0; loss: 2.934342622756958; \n",
      "fold: TRAIN; iteration: 99; epoch: 0; loss: 3.000040292739868; \n",
      "fold: TRAIN; iteration: 100; epoch: 0; loss: 2.928725242614746; \n",
      "fold: TRAIN; iteration: 101; epoch: 0; loss: 3.130194902420044; \n",
      "fold: TRAIN; iteration: 102; epoch: 0; loss: 2.9421420097351074; \n",
      "fold: TRAIN; iteration: 103; epoch: 0; loss: 3.1168909072875977; \n",
      "fold: TRAIN; iteration: 104; epoch: 0; loss: 3.0901827812194824; \n",
      "fold: TRAIN; iteration: 105; epoch: 0; loss: 2.8022546768188477; \n",
      "fold: TRAIN; iteration: 106; epoch: 0; loss: 2.804910898208618; \n",
      "fold: TRAIN; iteration: 107; epoch: 0; loss: 3.210585355758667; \n",
      "fold: TRAIN; iteration: 108; epoch: 0; loss: 2.9744796752929688; \n",
      "fold: TRAIN; iteration: 109; epoch: 0; loss: 2.894731044769287; \n",
      "fold: TRAIN; iteration: 110; epoch: 0; loss: 3.102292776107788; \n",
      "fold: TRAIN; iteration: 111; epoch: 0; loss: 2.7845959663391113; \n",
      "fold: TRAIN; iteration: 112; epoch: 0; loss: 2.97800350189209; \n",
      "fold: TRAIN; iteration: 113; epoch: 0; loss: 2.905947685241699; \n",
      "fold: TRAIN; iteration: 114; epoch: 0; loss: 2.973367691040039; \n",
      "fold: TRAIN; iteration: 115; epoch: 0; loss: 3.1998965740203857; \n",
      "fold: TRAIN; iteration: 116; epoch: 0; loss: 2.973515510559082; \n",
      "fold: TRAIN; iteration: 117; epoch: 0; loss: 3.225529193878174; \n",
      "fold: TRAIN; iteration: 118; epoch: 0; loss: 2.8630590438842773; \n",
      "fold: TRAIN; iteration: 119; epoch: 0; loss: 2.844637393951416; \n",
      "fold: TRAIN; iteration: 120; epoch: 0; loss: 2.8938732147216797; \n",
      "fold: TRAIN; iteration: 121; epoch: 0; loss: 2.8772077560424805; \n",
      "fold: TRAIN; iteration: 122; epoch: 0; loss: 2.8777520656585693; \n",
      "fold: TRAIN; iteration: 123; epoch: 0; loss: 2.994534492492676; \n",
      "fold: TRAIN; iteration: 124; epoch: 0; loss: 2.8640692234039307; \n",
      "fold: TRAIN; iteration: 125; epoch: 0; loss: 2.99405574798584; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 126; epoch: 0; loss: 2.9084203243255615; \n",
      "fold: TRAIN; iteration: 127; epoch: 0; loss: 2.871244192123413; \n",
      "fold: TRAIN; iteration: 128; epoch: 0; loss: 3.016848087310791; \n",
      "fold: TRAIN; iteration: 129; epoch: 0; loss: 3.1751317977905273; \n",
      "fold: TRAIN; iteration: 130; epoch: 0; loss: 3.0014355182647705; \n",
      "fold: TRAIN; iteration: 131; epoch: 0; loss: 2.9190731048583984; \n",
      "fold: TRAIN; iteration: 132; epoch: 0; loss: 3.1857874393463135; \n",
      "fold: TRAIN; iteration: 133; epoch: 0; loss: 3.129218339920044; \n",
      "fold: TRAIN; iteration: 134; epoch: 0; loss: 3.2196099758148193; \n",
      "fold: TRAIN; iteration: 135; epoch: 0; loss: 3.2447564601898193; \n",
      "fold: TRAIN; iteration: 136; epoch: 0; loss: 3.121063232421875; \n",
      "fold: TRAIN; iteration: 137; epoch: 0; loss: 3.178464412689209; \n",
      "fold: TRAIN; iteration: 138; epoch: 0; loss: 2.9884045124053955; \n",
      "fold: TRAIN; iteration: 139; epoch: 0; loss: 3.0209882259368896; \n",
      "fold: TRAIN; iteration: 140; epoch: 0; loss: 2.982297420501709; \n",
      "fold: TRAIN; iteration: 141; epoch: 0; loss: 3.1092722415924072; \n",
      "fold: TRAIN; iteration: 142; epoch: 0; loss: 2.937631130218506; \n",
      "fold: TRAIN; iteration: 143; epoch: 0; loss: 2.841836452484131; \n",
      "fold: TRAIN; iteration: 144; epoch: 0; loss: 2.6614162921905518; \n",
      "fold: TRAIN; iteration: 145; epoch: 0; loss: 2.841219425201416; \n",
      "fold: TRAIN; iteration: 146; epoch: 0; loss: 3.296557903289795; \n",
      "fold: TRAIN; iteration: 147; epoch: 0; loss: 2.8791418075561523; \n",
      "fold: TRAIN; iteration: 148; epoch: 0; loss: 2.788810968399048; \n",
      "fold: TRAIN; iteration: 149; epoch: 0; loss: 3.073261022567749; \n",
      "fold: TRAIN; iteration: 150; epoch: 0; loss: 2.8206405639648438; \n",
      "fold: TRAIN; iteration: 151; epoch: 0; loss: 3.0270731449127197; \n",
      "fold: TRAIN; iteration: 152; epoch: 0; loss: 2.847407817840576; \n",
      "fold: TRAIN; iteration: 153; epoch: 0; loss: 2.8440353870391846; \n",
      "fold: TRAIN; iteration: 154; epoch: 0; loss: 2.8663742542266846; \n",
      "fold: TRAIN; iteration: 155; epoch: 0; loss: 2.782088279724121; \n",
      "fold: TRAIN; iteration: 156; epoch: 0; loss: 2.9339590072631836; \n",
      "fold: TRAIN; iteration: 157; epoch: 0; loss: 2.9684200286865234; \n",
      "fold: TRAIN; iteration: 158; epoch: 0; loss: 2.863909959793091; \n",
      "fold: TRAIN; iteration: 159; epoch: 0; loss: 2.6573686599731445; \n",
      "fold: TRAIN; iteration: 160; epoch: 0; loss: 2.8840131759643555; \n",
      "fold: TRAIN; iteration: 161; epoch: 0; loss: 3.0536510944366455; \n",
      "fold: TRAIN; iteration: 162; epoch: 0; loss: 3.1600894927978516; \n",
      "fold: TRAIN; iteration: 163; epoch: 0; loss: 2.791701316833496; \n",
      "fold: TRAIN; iteration: 164; epoch: 0; loss: 3.0477733612060547; \n",
      "fold: TRAIN; iteration: 165; epoch: 0; loss: 3.019254684448242; \n",
      "fold: TRAIN; iteration: 166; epoch: 0; loss: 2.7970943450927734; \n",
      "fold: TRAIN; iteration: 167; epoch: 0; loss: 3.100888252258301; \n",
      "fold: TRAIN; iteration: 168; epoch: 0; loss: 3.0275814533233643; \n",
      "fold: TRAIN; iteration: 169; epoch: 0; loss: 2.9471282958984375; \n",
      "fold: TRAIN; iteration: 170; epoch: 0; loss: 3.121577262878418; \n",
      "fold: TRAIN; iteration: 171; epoch: 0; loss: 2.769124746322632; \n",
      "fold: TRAIN; iteration: 172; epoch: 0; loss: 2.9904439449310303; \n",
      "fold: TRAIN; iteration: 173; epoch: 0; loss: 2.7651031017303467; \n",
      "fold: TRAIN; iteration: 174; epoch: 0; loss: 2.912339687347412; \n",
      "fold: TRAIN; iteration: 175; epoch: 0; loss: 2.7202539443969727; \n",
      "fold: TRAIN; iteration: 176; epoch: 0; loss: 3.0600926876068115; \n",
      "fold: TRAIN; iteration: 177; epoch: 0; loss: 3.0353569984436035; \n",
      "fold: TRAIN; iteration: 178; epoch: 0; loss: 3.053807020187378; \n",
      "fold: TRAIN; iteration: 179; epoch: 0; loss: 2.9622907638549805; \n",
      "fold: TRAIN; iteration: 180; epoch: 0; loss: 2.9810733795166016; \n",
      "fold: TRAIN; iteration: 181; epoch: 0; loss: 3.0106656551361084; \n",
      "fold: TRAIN; iteration: 182; epoch: 0; loss: 2.901979446411133; \n",
      "fold: TRAIN; iteration: 183; epoch: 0; loss: 3.0503907203674316; \n",
      "fold: TRAIN; iteration: 184; epoch: 0; loss: 2.7766668796539307; \n",
      "fold: TRAIN; iteration: 185; epoch: 0; loss: 3.2180652618408203; \n",
      "fold: TRAIN; iteration: 186; epoch: 0; loss: 2.855001449584961; \n",
      "fold: TRAIN; iteration: 187; epoch: 0; loss: 3.0895586013793945; \n",
      "fold: TRAIN; iteration: 188; epoch: 0; loss: 2.8706862926483154; \n",
      "fold: TRAIN; iteration: 189; epoch: 0; loss: 3.301028251647949; \n",
      "fold: TRAIN; iteration: 190; epoch: 0; loss: 2.926896095275879; \n",
      "fold: TRAIN; iteration: 191; epoch: 0; loss: 2.7124674320220947; \n",
      "fold: TRAIN; iteration: 192; epoch: 0; loss: 2.9759912490844727; \n",
      "fold: TRAIN; iteration: 193; epoch: 0; loss: 3.086454391479492; \n",
      "fold: TRAIN; iteration: 194; epoch: 0; loss: 2.8489933013916016; \n",
      "fold: TRAIN; iteration: 195; epoch: 0; loss: 3.0946669578552246; \n",
      "fold: TRAIN; iteration: 196; epoch: 0; loss: 3.1990702152252197; \n",
      "fold: TRAIN; iteration: 197; epoch: 0; loss: 2.960259199142456; \n",
      "fold: TRAIN; iteration: 198; epoch: 0; loss: 2.917288303375244; \n",
      "fold: TRAIN; iteration: 199; epoch: 0; loss: 3.1399660110473633; \n",
      "fold: TRAIN; iteration: 200; epoch: 0; loss: 2.813908338546753; \n",
      "fold: TRAIN; iteration: 201; epoch: 0; loss: 2.717761754989624; \n",
      "fold: TRAIN; iteration: 202; epoch: 0; loss: 3.2669734954833984; \n",
      "fold: TRAIN; iteration: 203; epoch: 0; loss: 3.0647921562194824; \n",
      "fold: TRAIN; iteration: 204; epoch: 0; loss: 2.9553234577178955; \n",
      "fold: TRAIN; iteration: 205; epoch: 0; loss: 3.258492946624756; \n",
      "fold: TRAIN; iteration: 206; epoch: 0; loss: 3.151618242263794; \n",
      "fold: TRAIN; iteration: 207; epoch: 0; loss: 3.1737899780273438; \n",
      "fold: TRAIN; iteration: 208; epoch: 0; loss: 3.2642078399658203; \n",
      "fold: TRAIN; iteration: 209; epoch: 0; loss: 2.9890525341033936; \n",
      "fold: TRAIN; iteration: 210; epoch: 0; loss: 2.944171667098999; \n",
      "fold: TRAIN; iteration: 211; epoch: 0; loss: 3.0198302268981934; \n",
      "fold: TRAIN; iteration: 212; epoch: 0; loss: 3.086585283279419; \n",
      "fold: TRAIN; iteration: 213; epoch: 0; loss: 3.177530527114868; \n",
      "fold: TRAIN; iteration: 214; epoch: 0; loss: 2.9814162254333496; \n",
      "fold: TRAIN; iteration: 215; epoch: 0; loss: 2.814810276031494; \n",
      "fold: TRAIN; iteration: 216; epoch: 0; loss: 3.052896022796631; \n",
      "fold: TRAIN; iteration: 217; epoch: 0; loss: 3.181166410446167; \n",
      "fold: TRAIN; iteration: 218; epoch: 0; loss: 2.6527493000030518; \n",
      "fold: TRAIN; iteration: 219; epoch: 0; loss: 2.732084274291992; \n",
      "fold: TRAIN; iteration: 220; epoch: 0; loss: 3.0383217334747314; \n",
      "fold: TRAIN; iteration: 221; epoch: 0; loss: 2.963897943496704; \n",
      "fold: TRAIN; iteration: 222; epoch: 0; loss: 2.7534852027893066; \n",
      "fold: TRAIN; iteration: 223; epoch: 0; loss: 3.085150718688965; \n",
      "fold: TRAIN; iteration: 224; epoch: 0; loss: 2.862168788909912; \n",
      "fold: TRAIN; iteration: 225; epoch: 0; loss: 2.860292434692383; \n",
      "fold: TRAIN; iteration: 226; epoch: 0; loss: 3.041008949279785; \n",
      "fold: TRAIN; iteration: 227; epoch: 0; loss: 2.637650489807129; \n",
      "fold: TRAIN; iteration: 228; epoch: 0; loss: 3.2812726497650146; \n",
      "fold: TRAIN; iteration: 229; epoch: 0; loss: 2.9589102268218994; \n",
      "fold: TRAIN; iteration: 230; epoch: 0; loss: 2.8991568088531494; \n",
      "fold: TRAIN; iteration: 231; epoch: 0; loss: 2.781893253326416; \n",
      "fold: TRAIN; iteration: 232; epoch: 0; loss: 3.0903756618499756; \n",
      "fold: TRAIN; iteration: 233; epoch: 0; loss: 2.853999614715576; \n",
      "fold: TRAIN; iteration: 234; epoch: 0; loss: 2.997277021408081; \n",
      "fold: TRAIN; iteration: 235; epoch: 0; loss: 2.946732521057129; \n",
      "fold: TRAIN; iteration: 236; epoch: 0; loss: 3.0818827152252197; \n",
      "fold: TRAIN; iteration: 237; epoch: 0; loss: 2.925217866897583; \n",
      "fold: TRAIN; iteration: 238; epoch: 0; loss: 2.857367753982544; \n",
      "fold: TRAIN; iteration: 239; epoch: 0; loss: 2.8733980655670166; \n",
      "fold: TRAIN; iteration: 240; epoch: 0; loss: 3.1140313148498535; \n",
      "fold: TRAIN; iteration: 241; epoch: 0; loss: 3.0703258514404297; \n",
      "fold: TRAIN; iteration: 242; epoch: 0; loss: 3.0168063640594482; \n",
      "fold: TRAIN; iteration: 243; epoch: 0; loss: 3.0135622024536133; \n",
      "fold: TRAIN; iteration: 244; epoch: 0; loss: 2.8259377479553223; \n",
      "fold: TRAIN; iteration: 245; epoch: 0; loss: 2.627261161804199; \n",
      "fold: TRAIN; iteration: 246; epoch: 0; loss: 2.808474540710449; \n",
      "fold: TRAIN; iteration: 247; epoch: 0; loss: 2.9615273475646973; \n",
      "fold: TRAIN; iteration: 248; epoch: 0; loss: 2.9508416652679443; \n",
      "fold: TRAIN; iteration: 249; epoch: 0; loss: 3.1861114501953125; \n",
      "fold: TRAIN; iteration: 250; epoch: 0; loss: 2.942134141921997; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 251; epoch: 0; loss: 2.869356632232666; \n",
      "fold: TRAIN; iteration: 252; epoch: 0; loss: 2.88539457321167; \n",
      "fold: TRAIN; iteration: 253; epoch: 0; loss: 3.3817713260650635; \n",
      "fold: TRAIN; iteration: 254; epoch: 0; loss: 2.9944825172424316; \n",
      "fold: TRAIN; iteration: 255; epoch: 0; loss: 2.8265504837036133; \n",
      "fold: TRAIN; iteration: 256; epoch: 0; loss: 2.816737651824951; \n",
      "fold: TRAIN; iteration: 257; epoch: 0; loss: 2.910231351852417; \n",
      "fold: TRAIN; iteration: 258; epoch: 0; loss: 2.8525660037994385; \n",
      "fold: TRAIN; iteration: 259; epoch: 0; loss: 2.9716687202453613; \n",
      "fold: TRAIN; iteration: 260; epoch: 0; loss: 3.233034372329712; \n",
      "fold: TRAIN; iteration: 261; epoch: 0; loss: 3.5208239555358887; \n",
      "fold: TRAIN; iteration: 262; epoch: 0; loss: 2.8623907566070557; \n",
      "fold: TRAIN; iteration: 263; epoch: 0; loss: 3.046383857727051; \n",
      "fold: TRAIN; iteration: 264; epoch: 0; loss: 2.728412389755249; \n",
      "fold: TRAIN; iteration: 265; epoch: 0; loss: 2.7828173637390137; \n",
      "fold: TRAIN; iteration: 266; epoch: 0; loss: 2.954958438873291; \n",
      "fold: TRAIN; iteration: 267; epoch: 0; loss: 3.008359909057617; \n",
      "fold: TRAIN; iteration: 268; epoch: 0; loss: 3.0895843505859375; \n",
      "fold: TRAIN; iteration: 269; epoch: 0; loss: 3.04927921295166; \n",
      "fold: TRAIN; iteration: 270; epoch: 0; loss: 2.8875908851623535; \n",
      "fold: TRAIN; iteration: 271; epoch: 0; loss: 3.2927732467651367; \n",
      "fold: TRAIN; iteration: 272; epoch: 0; loss: 3.0542643070220947; \n",
      "fold: TRAIN; iteration: 273; epoch: 0; loss: 2.824110746383667; \n",
      "fold: TRAIN; iteration: 274; epoch: 0; loss: 2.7987020015716553; \n",
      "fold: TRAIN; iteration: 275; epoch: 0; loss: 3.0801405906677246; \n",
      "fold: TRAIN; iteration: 276; epoch: 0; loss: 2.9313321113586426; \n",
      "fold: TRAIN; iteration: 277; epoch: 0; loss: 2.951690912246704; \n",
      "fold: TRAIN; iteration: 278; epoch: 0; loss: 3.0471906661987305; \n",
      "fold: TRAIN; iteration: 279; epoch: 0; loss: 3.285568952560425; \n",
      "fold: TRAIN; iteration: 280; epoch: 0; loss: 3.0058255195617676; \n",
      "fold: TRAIN; iteration: 281; epoch: 0; loss: 2.7878692150115967; \n",
      "fold: TRAIN; iteration: 282; epoch: 0; loss: 2.8705334663391113; \n",
      "fold: TRAIN; iteration: 283; epoch: 0; loss: 2.6521551609039307; \n",
      "fold: TRAIN; iteration: 284; epoch: 0; loss: 3.144225835800171; \n",
      "fold: TRAIN; iteration: 285; epoch: 0; loss: 2.9790215492248535; \n",
      "fold: TRAIN; iteration: 286; epoch: 0; loss: 2.931536912918091; \n",
      "fold: TRAIN; iteration: 287; epoch: 0; loss: 2.9532623291015625; \n",
      "fold: TRAIN; iteration: 288; epoch: 0; loss: 3.019261121749878; \n",
      "fold: TRAIN; iteration: 289; epoch: 0; loss: 3.0169622898101807; \n",
      "fold: TRAIN; iteration: 290; epoch: 0; loss: 3.117936372756958; \n",
      "fold: TRAIN; iteration: 291; epoch: 0; loss: 3.138796329498291; \n",
      "fold: TRAIN; iteration: 292; epoch: 0; loss: 2.986691474914551; \n",
      "fold: TRAIN; iteration: 293; epoch: 0; loss: 3.1601364612579346; \n",
      "fold: TRAIN; iteration: 294; epoch: 0; loss: 2.802567481994629; \n",
      "fold: TRAIN; iteration: 295; epoch: 0; loss: 2.8808538913726807; \n",
      "fold: TRAIN; iteration: 296; epoch: 0; loss: 3.0798346996307373; \n",
      "fold: TRAIN; iteration: 297; epoch: 0; loss: 2.9657680988311768; \n",
      "fold: TRAIN; iteration: 298; epoch: 0; loss: 3.006734609603882; \n",
      "fold: TRAIN; iteration: 299; epoch: 0; loss: 2.7263128757476807; \n",
      "fold: TRAIN; iteration: 300; epoch: 0; loss: 2.809960126876831; \n",
      "fold: TRAIN; iteration: 301; epoch: 0; loss: 2.7031335830688477; \n",
      "fold: TRAIN; iteration: 302; epoch: 0; loss: 3.0102012157440186; \n",
      "fold: TRAIN; iteration: 303; epoch: 0; loss: 3.007918357849121; \n",
      "fold: TRAIN; iteration: 304; epoch: 0; loss: 2.9444403648376465; \n",
      "fold: TRAIN; iteration: 305; epoch: 0; loss: 3.006654739379883; \n",
      "fold: TRAIN; iteration: 306; epoch: 0; loss: 3.0222971439361572; \n",
      "fold: TRAIN; iteration: 307; epoch: 0; loss: 3.029980421066284; \n",
      "fold: TRAIN; iteration: 308; epoch: 0; loss: 3.2284579277038574; \n",
      "fold: TRAIN; iteration: 309; epoch: 0; loss: 3.3256139755249023; \n",
      "fold: TRAIN; iteration: 310; epoch: 0; loss: 2.847853183746338; \n",
      "fold: TRAIN; iteration: 311; epoch: 0; loss: 2.912112236022949; \n",
      "fold: TRAIN; iteration: 312; epoch: 0; loss: 2.6940383911132812; \n",
      "fold: TRAIN; iteration: 313; epoch: 0; loss: 2.9218356609344482; \n",
      "fold: TRAIN; iteration: 314; epoch: 0; loss: 2.8994171619415283; \n",
      "fold: TRAIN; iteration: 315; epoch: 0; loss: 2.9423816204071045; \n",
      "fold: TRAIN; iteration: 316; epoch: 0; loss: 3.237031936645508; \n",
      "fold: TRAIN; iteration: 317; epoch: 0; loss: 2.974966526031494; \n",
      "fold: TRAIN; iteration: 318; epoch: 0; loss: 2.869504690170288; \n",
      "fold: TRAIN; iteration: 319; epoch: 0; loss: 2.8133959770202637; \n",
      "fold: TRAIN; iteration: 320; epoch: 0; loss: 2.793680429458618; \n",
      "fold: TRAIN; iteration: 321; epoch: 0; loss: 3.0378453731536865; \n",
      "fold: TRAIN; iteration: 322; epoch: 0; loss: 2.87663197517395; \n",
      "fold: TRAIN; iteration: 323; epoch: 0; loss: 3.214474678039551; \n",
      "fold: TRAIN; iteration: 324; epoch: 0; loss: 2.8968029022216797; \n",
      "fold: TRAIN; iteration: 325; epoch: 0; loss: 3.174760103225708; \n",
      "fold: TRAIN; iteration: 326; epoch: 0; loss: 2.8330631256103516; \n",
      "fold: TRAIN; iteration: 327; epoch: 0; loss: 2.8104946613311768; \n",
      "fold: TRAIN; iteration: 328; epoch: 0; loss: 3.0877068042755127; \n",
      "fold: TRAIN; iteration: 329; epoch: 0; loss: 3.1457574367523193; \n",
      "fold: TRAIN; iteration: 330; epoch: 0; loss: 2.948422908782959; \n",
      "fold: TRAIN; iteration: 331; epoch: 0; loss: 2.9349052906036377; \n",
      "fold: TRAIN; iteration: 332; epoch: 0; loss: 3.054666757583618; \n",
      "fold: TRAIN; iteration: 333; epoch: 0; loss: 3.1100761890411377; \n",
      "fold: TRAIN; iteration: 334; epoch: 0; loss: 3.0417566299438477; \n",
      "fold: TRAIN; iteration: 335; epoch: 0; loss: 2.911363124847412; \n",
      "fold: TRAIN; iteration: 336; epoch: 0; loss: 3.1127190589904785; \n",
      "fold: TRAIN; iteration: 337; epoch: 0; loss: 3.1303555965423584; \n",
      "fold: TRAIN; iteration: 338; epoch: 0; loss: 2.7348296642303467; \n",
      "fold: TRAIN; iteration: 339; epoch: 0; loss: 2.9505252838134766; \n",
      "fold: TRAIN; iteration: 340; epoch: 0; loss: 2.929541826248169; \n",
      "fold: TRAIN; iteration: 341; epoch: 0; loss: 2.9979331493377686; \n",
      "fold: TRAIN; iteration: 342; epoch: 0; loss: 2.8773953914642334; \n",
      "fold: TRAIN; iteration: 343; epoch: 0; loss: 3.043708086013794; \n",
      "fold: TRAIN; iteration: 344; epoch: 0; loss: 2.9215636253356934; \n",
      "fold: TRAIN; iteration: 345; epoch: 0; loss: 3.026752233505249; \n",
      "fold: TRAIN; iteration: 346; epoch: 0; loss: 3.128472328186035; \n",
      "fold: TRAIN; iteration: 347; epoch: 0; loss: 2.979696273803711; \n",
      "fold: TRAIN; iteration: 348; epoch: 0; loss: 3.0826058387756348; \n",
      "fold: TRAIN; iteration: 349; epoch: 0; loss: 3.247380256652832; \n",
      "fold: TRAIN; iteration: 350; epoch: 0; loss: 2.7374656200408936; \n",
      "fold: TRAIN; iteration: 351; epoch: 0; loss: 2.8851819038391113; \n",
      "fold: TRAIN; iteration: 352; epoch: 0; loss: 2.945528507232666; \n",
      "fold: TRAIN; iteration: 353; epoch: 0; loss: 2.9128875732421875; \n",
      "fold: TRAIN; iteration: 354; epoch: 0; loss: 3.1535346508026123; \n",
      "fold: TRAIN; iteration: 355; epoch: 0; loss: 2.9658265113830566; \n",
      "fold: TRAIN; iteration: 356; epoch: 0; loss: 3.1329586505889893; \n",
      "fold: TRAIN; iteration: 357; epoch: 0; loss: 2.7750563621520996; \n",
      "fold: TRAIN; iteration: 358; epoch: 0; loss: 3.206643581390381; \n",
      "fold: TRAIN; iteration: 359; epoch: 0; loss: 3.027217388153076; \n",
      "fold: TRAIN; iteration: 360; epoch: 0; loss: 2.6764791011810303; \n",
      "fold: TRAIN; iteration: 361; epoch: 0; loss: 3.092209577560425; \n",
      "fold: TRAIN; iteration: 362; epoch: 0; loss: 2.9537405967712402; \n",
      "fold: TRAIN; iteration: 363; epoch: 0; loss: 3.0655388832092285; \n",
      "fold: TRAIN; iteration: 364; epoch: 0; loss: 3.064269781112671; \n",
      "fold: TRAIN; iteration: 365; epoch: 0; loss: 2.9965364933013916; \n",
      "fold: TRAIN; iteration: 366; epoch: 0; loss: 2.6476123332977295; \n",
      "fold: TRAIN; iteration: 367; epoch: 0; loss: 3.0801329612731934; \n",
      "fold: TRAIN; iteration: 368; epoch: 0; loss: 3.030670166015625; \n",
      "fold: TRAIN; iteration: 369; epoch: 0; loss: 2.927570104598999; \n",
      "fold: TRAIN; iteration: 370; epoch: 0; loss: 2.980147123336792; \n",
      "fold: TRAIN; iteration: 371; epoch: 0; loss: 2.982914447784424; \n",
      "fold: TRAIN; iteration: 372; epoch: 0; loss: 2.927844524383545; \n",
      "fold: TRAIN; iteration: 373; epoch: 0; loss: 2.8934860229492188; \n",
      "fold: TRAIN; iteration: 374; epoch: 0; loss: 2.9941039085388184; \n",
      "fold: TRAIN; iteration: 375; epoch: 0; loss: 3.0174453258514404; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 376; epoch: 0; loss: 2.8861026763916016; \n",
      "fold: TRAIN; iteration: 377; epoch: 0; loss: 3.078598737716675; \n",
      "fold: TRAIN; iteration: 378; epoch: 0; loss: 2.5586092472076416; \n",
      "fold: TRAIN; iteration: 379; epoch: 0; loss: 3.1780195236206055; \n",
      "fold: TRAIN; iteration: 380; epoch: 0; loss: 3.1768910884857178; \n",
      "fold: TRAIN; iteration: 381; epoch: 0; loss: 2.830040693283081; \n",
      "fold: TRAIN; iteration: 382; epoch: 0; loss: 3.0200395584106445; \n",
      "fold: TRAIN; iteration: 383; epoch: 0; loss: 3.1400368213653564; \n",
      "fold: TRAIN; iteration: 384; epoch: 0; loss: 2.776454210281372; \n",
      "fold: TRAIN; iteration: 385; epoch: 0; loss: 2.9129886627197266; \n",
      "fold: TRAIN; iteration: 386; epoch: 0; loss: 3.04372501373291; \n",
      "fold: TRAIN; iteration: 387; epoch: 0; loss: 2.9617626667022705; \n",
      "fold: TRAIN; iteration: 388; epoch: 0; loss: 2.8034110069274902; \n",
      "fold: TRAIN; iteration: 389; epoch: 0; loss: 2.905953884124756; \n",
      "fold: TRAIN; iteration: 390; epoch: 0; loss: 2.939920425415039; \n",
      "fold: TRAIN; iteration: 391; epoch: 0; loss: 2.987701416015625; \n",
      "fold: TRAIN; iteration: 392; epoch: 0; loss: 2.806626558303833; \n",
      "fold: TRAIN; iteration: 393; epoch: 0; loss: 3.012843608856201; \n",
      "fold: TRAIN; iteration: 394; epoch: 0; loss: 2.8930413722991943; \n",
      "fold: TRAIN; iteration: 395; epoch: 0; loss: 2.9670417308807373; \n",
      "fold: TRAIN; iteration: 396; epoch: 0; loss: 2.7944841384887695; \n",
      "fold: TRAIN; iteration: 397; epoch: 0; loss: 3.075674057006836; \n",
      "fold: TRAIN; iteration: 398; epoch: 0; loss: 2.9488794803619385; \n",
      "fold: TRAIN; iteration: 399; epoch: 0; loss: 2.7948496341705322; \n",
      "fold: TRAIN; iteration: 400; epoch: 0; loss: 3.110900640487671; \n",
      "fold: TRAIN; iteration: 401; epoch: 0; loss: 3.023571252822876; \n",
      "fold: TRAIN; iteration: 402; epoch: 0; loss: 2.760620355606079; \n",
      "fold: TRAIN; iteration: 403; epoch: 0; loss: 2.7018027305603027; \n",
      "fold: TRAIN; iteration: 404; epoch: 0; loss: 2.8364150524139404; \n",
      "fold: TRAIN; iteration: 405; epoch: 0; loss: 3.076606512069702; \n",
      "fold: TRAIN; iteration: 406; epoch: 0; loss: 2.7221519947052; \n",
      "fold: TRAIN; iteration: 407; epoch: 0; loss: 2.998063325881958; \n",
      "fold: TRAIN; iteration: 408; epoch: 0; loss: 2.9864563941955566; \n",
      "fold: TRAIN; iteration: 409; epoch: 0; loss: 2.9267194271087646; \n",
      "fold: TRAIN; iteration: 410; epoch: 0; loss: 3.041517972946167; \n",
      "fold: TRAIN; iteration: 411; epoch: 0; loss: 3.022385358810425; \n",
      "fold: TRAIN; iteration: 412; epoch: 0; loss: 2.689188241958618; \n",
      "fold: TRAIN; iteration: 413; epoch: 0; loss: 2.978104829788208; \n",
      "fold: TRAIN; iteration: 414; epoch: 0; loss: 2.7298994064331055; \n",
      "fold: TRAIN; iteration: 415; epoch: 0; loss: 3.0977721214294434; \n",
      "fold: TRAIN; iteration: 416; epoch: 0; loss: 2.7781646251678467; \n",
      "fold: TRAIN; iteration: 417; epoch: 0; loss: 2.898308515548706; \n",
      "fold: TRAIN; iteration: 418; epoch: 0; loss: 2.992321491241455; \n",
      "fold: TRAIN; iteration: 419; epoch: 0; loss: 3.027573347091675; \n",
      "fold: TRAIN; iteration: 420; epoch: 0; loss: 3.2629387378692627; \n",
      "fold: TRAIN; iteration: 421; epoch: 0; loss: 3.041348457336426; \n",
      "fold: TRAIN; iteration: 422; epoch: 0; loss: 3.056307792663574; \n",
      "fold: TRAIN; iteration: 423; epoch: 0; loss: 2.9134230613708496; \n",
      "fold: TRAIN; iteration: 424; epoch: 0; loss: 3.0082526206970215; \n",
      "fold: TRAIN; iteration: 425; epoch: 0; loss: 3.0294463634490967; \n",
      "fold: TRAIN; iteration: 426; epoch: 0; loss: 3.247255563735962; \n",
      "fold: TRAIN; iteration: 427; epoch: 0; loss: 2.9096992015838623; \n",
      "fold: TRAIN; iteration: 428; epoch: 0; loss: 3.1582953929901123; \n",
      "fold: TRAIN; iteration: 429; epoch: 0; loss: 2.989311456680298; \n",
      "fold: TRAIN; iteration: 430; epoch: 0; loss: 2.8998589515686035; \n",
      "fold: TRAIN; iteration: 431; epoch: 0; loss: 2.7752785682678223; \n",
      "fold: TRAIN; iteration: 432; epoch: 0; loss: 3.034613847732544; \n",
      "fold: TRAIN; iteration: 433; epoch: 0; loss: 3.033703327178955; \n",
      "fold: TRAIN; iteration: 434; epoch: 0; loss: 2.9016056060791016; \n",
      "fold: TRAIN; iteration: 435; epoch: 0; loss: 2.9840381145477295; \n",
      "fold: TRAIN; iteration: 436; epoch: 0; loss: 2.764896869659424; \n",
      "fold: TRAIN; iteration: 437; epoch: 0; loss: 2.7124054431915283; \n",
      "fold: TRAIN; iteration: 438; epoch: 0; loss: 2.9322333335876465; \n",
      "fold: TRAIN; iteration: 439; epoch: 0; loss: 2.6047024726867676; \n",
      "fold: TRAIN; iteration: 440; epoch: 0; loss: 2.935487747192383; \n",
      "fold: TRAIN; iteration: 441; epoch: 0; loss: 3.1914734840393066; \n",
      "fold: TRAIN; iteration: 442; epoch: 0; loss: 2.7326972484588623; \n",
      "fold: TRAIN; iteration: 443; epoch: 0; loss: 2.6667680740356445; \n",
      "fold: TRAIN; iteration: 444; epoch: 0; loss: 3.0465428829193115; \n",
      "fold: TRAIN; iteration: 445; epoch: 0; loss: 3.2732577323913574; \n",
      "fold: TRAIN; iteration: 446; epoch: 0; loss: 3.043821096420288; \n",
      "fold: TRAIN; iteration: 447; epoch: 0; loss: 2.970076084136963; \n",
      "fold: TRAIN; iteration: 448; epoch: 0; loss: 3.092076301574707; \n",
      "fold: TRAIN; iteration: 449; epoch: 0; loss: 2.865220308303833; \n",
      "fold: TRAIN; iteration: 450; epoch: 0; loss: 3.049311876296997; \n",
      "fold: TRAIN; iteration: 451; epoch: 0; loss: 3.0460619926452637; \n",
      "fold: TRAIN; iteration: 452; epoch: 0; loss: 2.899068832397461; \n",
      "fold: TRAIN; iteration: 453; epoch: 0; loss: 2.9174532890319824; \n",
      "fold: TRAIN; iteration: 454; epoch: 0; loss: 2.8332245349884033; \n",
      "fold: TRAIN; iteration: 455; epoch: 0; loss: 2.800964593887329; \n",
      "fold: TRAIN; iteration: 456; epoch: 0; loss: 3.0524260997772217; \n",
      "fold: TRAIN; iteration: 457; epoch: 0; loss: 2.9132697582244873; \n",
      "fold: TRAIN; iteration: 458; epoch: 0; loss: 2.9023211002349854; \n",
      "fold: TRAIN; iteration: 459; epoch: 0; loss: 2.8627588748931885; \n",
      "fold: TRAIN; iteration: 460; epoch: 0; loss: 2.97538423538208; \n",
      "fold: TRAIN; iteration: 461; epoch: 0; loss: 2.9896609783172607; \n",
      "fold: TRAIN; iteration: 462; epoch: 0; loss: 3.0639116764068604; \n",
      "fold: TRAIN; iteration: 463; epoch: 0; loss: 2.752286911010742; \n",
      "fold: TRAIN; iteration: 464; epoch: 0; loss: 2.88875150680542; \n",
      "fold: TRAIN; iteration: 465; epoch: 0; loss: 2.675931453704834; \n",
      "fold: TRAIN; iteration: 466; epoch: 0; loss: 2.734151601791382; \n",
      "fold: TRAIN; iteration: 467; epoch: 0; loss: 3.0226781368255615; \n",
      "fold: TRAIN; iteration: 468; epoch: 0; loss: 3.017122507095337; \n",
      "fold: TRAIN; iteration: 469; epoch: 0; loss: 3.1601195335388184; \n",
      "fold: TRAIN; iteration: 470; epoch: 0; loss: 3.0956804752349854; \n",
      "fold: TRAIN; iteration: 471; epoch: 0; loss: 3.0523293018341064; \n",
      "fold: TRAIN; iteration: 472; epoch: 0; loss: 3.1426174640655518; \n",
      "fold: TRAIN; iteration: 473; epoch: 0; loss: 2.8985278606414795; \n",
      "fold: TRAIN; iteration: 474; epoch: 0; loss: 2.999833345413208; \n",
      "fold: TRAIN; iteration: 475; epoch: 0; loss: 3.0743541717529297; \n",
      "fold: TRAIN; iteration: 476; epoch: 0; loss: 2.990828514099121; \n",
      "fold: TRAIN; iteration: 477; epoch: 0; loss: 2.7324652671813965; \n",
      "fold: TRAIN; iteration: 478; epoch: 0; loss: 3.1692724227905273; \n",
      "fold: TRAIN; iteration: 479; epoch: 0; loss: 2.679765224456787; \n",
      "fold: TRAIN; iteration: 480; epoch: 0; loss: 2.5465612411499023; \n",
      "fold: TRAIN; iteration: 481; epoch: 0; loss: 2.9231960773468018; \n",
      "fold: TRAIN; iteration: 482; epoch: 0; loss: 2.8489184379577637; \n",
      "fold: TRAIN; iteration: 483; epoch: 0; loss: 3.0790164470672607; \n",
      "fold: TRAIN; iteration: 484; epoch: 0; loss: 3.177544355392456; \n",
      "fold: TRAIN; iteration: 485; epoch: 0; loss: 3.0993151664733887; \n",
      "fold: TRAIN; iteration: 486; epoch: 0; loss: 3.10129451751709; \n",
      "fold: TRAIN; iteration: 487; epoch: 0; loss: 2.764543056488037; \n",
      "fold: TRAIN; iteration: 488; epoch: 0; loss: 3.2793893814086914; \n",
      "fold: TRAIN; iteration: 489; epoch: 0; loss: 2.999765634536743; \n",
      "fold: TRAIN; iteration: 490; epoch: 0; loss: 2.8883395195007324; \n",
      "fold: TRAIN; iteration: 491; epoch: 0; loss: 2.8552892208099365; \n",
      "fold: TRAIN; iteration: 492; epoch: 0; loss: 3.2331302165985107; \n",
      "fold: TRAIN; iteration: 493; epoch: 0; loss: 2.7151129245758057; \n",
      "fold: TRAIN; iteration: 494; epoch: 0; loss: 2.6903862953186035; \n",
      "fold: TRAIN; iteration: 495; epoch: 0; loss: 3.104633092880249; \n",
      "fold: TRAIN; iteration: 496; epoch: 0; loss: 3.1660711765289307; \n",
      "fold: TRAIN; iteration: 497; epoch: 0; loss: 2.831669330596924; \n",
      "fold: TRAIN; iteration: 498; epoch: 0; loss: 2.7908072471618652; \n",
      "fold: TRAIN; iteration: 499; epoch: 0; loss: 2.791386127471924; \n",
      "fold: TRAIN; iteration: 500; epoch: 0; loss: 3.0321991443634033; \n",
      "fold: TRAIN; iteration: 501; epoch: 0; loss: 3.107944965362549; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 502; epoch: 0; loss: 3.067944049835205; \n",
      "fold: TRAIN; iteration: 503; epoch: 0; loss: 2.8170249462127686; \n",
      "fold: TRAIN; iteration: 504; epoch: 0; loss: 2.9458861351013184; \n",
      "fold: TRAIN; iteration: 505; epoch: 0; loss: 3.154284954071045; \n",
      "fold: TRAIN; iteration: 506; epoch: 0; loss: 3.127666711807251; \n",
      "fold: TRAIN; iteration: 507; epoch: 0; loss: 2.8774712085723877; \n",
      "fold: TRAIN; iteration: 508; epoch: 0; loss: 2.7542312145233154; \n",
      "fold: TRAIN; iteration: 509; epoch: 0; loss: 3.114581823348999; \n",
      "fold: TRAIN; iteration: 510; epoch: 0; loss: 2.8777565956115723; \n",
      "fold: TRAIN; iteration: 511; epoch: 0; loss: 2.760838508605957; \n",
      "fold: TRAIN; iteration: 512; epoch: 0; loss: 2.917069435119629; \n",
      "fold: TRAIN; iteration: 513; epoch: 0; loss: 2.7543869018554688; \n",
      "fold: TRAIN; iteration: 514; epoch: 0; loss: 3.0673716068267822; \n",
      "fold: TRAIN; iteration: 515; epoch: 0; loss: 2.8726541996002197; \n",
      "fold: TRAIN; iteration: 516; epoch: 0; loss: 2.7845470905303955; \n",
      "fold: TRAIN; iteration: 517; epoch: 0; loss: 2.796623945236206; \n",
      "fold: TRAIN; iteration: 518; epoch: 0; loss: 3.0348663330078125; \n",
      "fold: TRAIN; iteration: 519; epoch: 0; loss: 2.8804287910461426; \n",
      "fold: TRAIN; iteration: 520; epoch: 0; loss: 2.6831722259521484; \n",
      "fold: TRAIN; iteration: 521; epoch: 0; loss: 3.0458130836486816; \n",
      "fold: TRAIN; iteration: 522; epoch: 0; loss: 2.9188148975372314; \n",
      "fold: TRAIN; iteration: 523; epoch: 0; loss: 2.8919031620025635; \n",
      "fold: TRAIN; iteration: 524; epoch: 0; loss: 3.1345694065093994; \n",
      "fold: TRAIN; iteration: 525; epoch: 0; loss: 2.6777701377868652; \n",
      "fold: TRAIN; iteration: 526; epoch: 0; loss: 2.7039690017700195; \n",
      "fold: TRAIN; iteration: 527; epoch: 0; loss: 2.963425397872925; \n",
      "fold: TRAIN; iteration: 528; epoch: 0; loss: 2.9818060398101807; \n",
      "fold: TRAIN; iteration: 529; epoch: 0; loss: 2.8191049098968506; \n",
      "fold: TRAIN; iteration: 530; epoch: 0; loss: 2.852466106414795; \n",
      "fold: TRAIN; iteration: 531; epoch: 0; loss: 3.026632308959961; \n",
      "fold: TRAIN; iteration: 532; epoch: 0; loss: 2.8863699436187744; \n",
      "fold: TRAIN; iteration: 533; epoch: 0; loss: 2.864767074584961; \n",
      "fold: TRAIN; iteration: 534; epoch: 0; loss: 2.9108524322509766; \n",
      "fold: TRAIN; iteration: 535; epoch: 0; loss: 2.8298110961914062; \n",
      "fold: TRAIN; iteration: 536; epoch: 0; loss: 3.0410068035125732; \n",
      "fold: TRAIN; iteration: 537; epoch: 0; loss: 2.9134223461151123; \n",
      "fold: TRAIN; iteration: 538; epoch: 0; loss: 2.9437499046325684; \n",
      "fold: TRAIN; iteration: 539; epoch: 0; loss: 2.8266897201538086; \n",
      "fold: TRAIN; iteration: 540; epoch: 0; loss: 2.9658520221710205; \n",
      "fold: TRAIN; iteration: 541; epoch: 0; loss: 3.3168463706970215; \n",
      "fold: TRAIN; iteration: 542; epoch: 0; loss: 3.176114559173584; \n",
      "fold: TRAIN; iteration: 543; epoch: 0; loss: 3.0965206623077393; \n",
      "fold: TRAIN; iteration: 544; epoch: 0; loss: 2.847336769104004; \n",
      "fold: TRAIN; iteration: 545; epoch: 0; loss: 3.0394208431243896; \n",
      "fold: TRAIN; iteration: 546; epoch: 0; loss: 2.9550082683563232; \n",
      "fold: TRAIN; iteration: 547; epoch: 0; loss: 2.800111770629883; \n",
      "fold: TRAIN; iteration: 548; epoch: 0; loss: 2.909747362136841; \n",
      "fold: TRAIN; iteration: 549; epoch: 0; loss: 3.010779619216919; \n",
      "fold: TRAIN; iteration: 550; epoch: 0; loss: 2.906372308731079; \n",
      "fold: TRAIN; iteration: 551; epoch: 0; loss: 2.730419397354126; \n",
      "fold: TRAIN; iteration: 552; epoch: 0; loss: 2.8667209148406982; \n",
      "fold: TRAIN; iteration: 553; epoch: 0; loss: 3.3504438400268555; \n",
      "fold: TRAIN; iteration: 554; epoch: 0; loss: 2.8151586055755615; \n",
      "fold: TRAIN; iteration: 555; epoch: 0; loss: 3.062838554382324; \n",
      "fold: TRAIN; iteration: 556; epoch: 0; loss: 3.1471807956695557; \n",
      "fold: TRAIN; iteration: 557; epoch: 0; loss: 3.0886728763580322; \n",
      "fold: TRAIN; iteration: 558; epoch: 0; loss: 3.0901029109954834; \n",
      "fold: TRAIN; iteration: 559; epoch: 0; loss: 3.0711734294891357; \n",
      "fold: TRAIN; iteration: 560; epoch: 0; loss: 2.7367866039276123; \n",
      "fold: TRAIN; iteration: 561; epoch: 0; loss: 2.860405206680298; \n",
      "fold: TRAIN; iteration: 562; epoch: 0; loss: 3.227787494659424; \n",
      "fold: TRAIN; iteration: 563; epoch: 0; loss: 2.9224658012390137; \n",
      "fold: TRAIN; iteration: 564; epoch: 0; loss: 3.0869104862213135; \n",
      "fold: TRAIN; iteration: 565; epoch: 0; loss: 3.011613130569458; \n",
      "fold: TRAIN; iteration: 566; epoch: 0; loss: 3.040634870529175; \n",
      "fold: TRAIN; iteration: 567; epoch: 0; loss: 2.7820780277252197; \n",
      "fold: TRAIN; iteration: 568; epoch: 0; loss: 2.917368173599243; \n",
      "fold: TRAIN; iteration: 569; epoch: 0; loss: 3.018510103225708; \n",
      "fold: TRAIN; iteration: 570; epoch: 0; loss: 3.2290947437286377; \n",
      "fold: TRAIN; iteration: 571; epoch: 0; loss: 3.2189879417419434; \n",
      "fold: TRAIN; iteration: 572; epoch: 0; loss: 3.153866767883301; \n",
      "fold: TRAIN; iteration: 573; epoch: 0; loss: 3.004054307937622; \n",
      "fold: TRAIN; iteration: 574; epoch: 0; loss: 2.7263760566711426; \n",
      "fold: TRAIN; iteration: 575; epoch: 0; loss: 2.8521206378936768; \n",
      "fold: TRAIN; iteration: 576; epoch: 0; loss: 3.0235674381256104; \n",
      "fold: TRAIN; iteration: 577; epoch: 0; loss: 3.0473437309265137; \n",
      "fold: TRAIN; iteration: 578; epoch: 0; loss: 3.0038063526153564; \n",
      "fold: TRAIN; iteration: 579; epoch: 0; loss: 2.9534108638763428; \n",
      "fold: TRAIN; iteration: 580; epoch: 0; loss: 3.134688138961792; \n",
      "fold: TRAIN; iteration: 581; epoch: 0; loss: 2.9968392848968506; \n",
      "fold: TRAIN; iteration: 582; epoch: 0; loss: 2.7004685401916504; \n",
      "fold: TRAIN; iteration: 583; epoch: 0; loss: 3.2713804244995117; \n",
      "fold: TRAIN; iteration: 584; epoch: 0; loss: 3.0250535011291504; \n",
      "fold: TRAIN; iteration: 585; epoch: 0; loss: 3.0840697288513184; \n",
      "fold: TRAIN; iteration: 586; epoch: 0; loss: 2.8358154296875; \n",
      "fold: TRAIN; iteration: 587; epoch: 0; loss: 3.0822019577026367; \n",
      "fold: TRAIN; iteration: 588; epoch: 0; loss: 2.753305435180664; \n",
      "fold: TRAIN; iteration: 589; epoch: 0; loss: 2.871901750564575; \n",
      "fold: TRAIN; iteration: 590; epoch: 0; loss: 2.676115036010742; \n",
      "fold: TRAIN; iteration: 591; epoch: 0; loss: 2.8037643432617188; \n",
      "fold: TRAIN; iteration: 592; epoch: 0; loss: 3.155595064163208; \n",
      "fold: TRAIN; iteration: 593; epoch: 0; loss: 2.933809280395508; \n",
      "fold: TRAIN; iteration: 594; epoch: 0; loss: 2.9224722385406494; \n",
      "fold: TRAIN; iteration: 595; epoch: 0; loss: 3.1212503910064697; \n",
      "fold: TRAIN; iteration: 596; epoch: 0; loss: 3.184861421585083; \n",
      "fold: TRAIN; iteration: 597; epoch: 0; loss: 2.6618459224700928; \n",
      "fold: TRAIN; iteration: 598; epoch: 0; loss: 2.8816113471984863; \n",
      "fold: TRAIN; iteration: 599; epoch: 0; loss: 3.2485415935516357; \n",
      "fold: TRAIN; iteration: 600; epoch: 0; loss: 2.889724016189575; \n",
      "fold: TRAIN; iteration: 601; epoch: 0; loss: 3.103849172592163; \n",
      "fold: TRAIN; iteration: 602; epoch: 0; loss: 3.0706241130828857; \n",
      "fold: TRAIN; iteration: 603; epoch: 0; loss: 3.1716747283935547; \n",
      "fold: TRAIN; iteration: 604; epoch: 0; loss: 3.1186413764953613; \n",
      "fold: TRAIN; iteration: 605; epoch: 0; loss: 2.665228843688965; \n",
      "fold: TRAIN; iteration: 606; epoch: 0; loss: 3.215191602706909; \n",
      "fold: TRAIN; iteration: 607; epoch: 0; loss: 2.980300188064575; \n",
      "fold: TRAIN; iteration: 608; epoch: 0; loss: 2.6836435794830322; \n",
      "fold: TRAIN; iteration: 609; epoch: 0; loss: 2.8473405838012695; \n",
      "fold: TRAIN; iteration: 610; epoch: 0; loss: 2.7227120399475098; \n",
      "fold: TRAIN; iteration: 611; epoch: 0; loss: 2.9845526218414307; \n",
      "fold: TRAIN; iteration: 612; epoch: 0; loss: 3.031397819519043; \n",
      "fold: TRAIN; iteration: 613; epoch: 0; loss: 2.781867027282715; \n",
      "fold: TRAIN; iteration: 614; epoch: 0; loss: 2.8530328273773193; \n",
      "fold: TRAIN; iteration: 615; epoch: 0; loss: 3.0142476558685303; \n",
      "fold: TRAIN; iteration: 616; epoch: 0; loss: 3.0101842880249023; \n",
      "fold: TRAIN; iteration: 617; epoch: 0; loss: 2.7645883560180664; \n",
      "fold: TRAIN; iteration: 618; epoch: 0; loss: 2.6324689388275146; \n",
      "fold: TRAIN; iteration: 619; epoch: 0; loss: 2.925067663192749; \n",
      "fold: TRAIN; iteration: 620; epoch: 0; loss: 3.0898940563201904; \n",
      "fold: TRAIN; iteration: 621; epoch: 0; loss: 3.1351380348205566; \n",
      "fold: TRAIN; iteration: 622; epoch: 0; loss: 2.9642674922943115; \n",
      "fold: TRAIN; iteration: 623; epoch: 0; loss: 2.940676212310791; \n",
      "fold: TRAIN; iteration: 624; epoch: 0; loss: 3.0600969791412354; \n",
      "fold: TRAIN; iteration: 625; epoch: 0; loss: 2.676658868789673; \n",
      "fold: TRAIN; iteration: 626; epoch: 0; loss: 2.9327173233032227; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 627; epoch: 0; loss: 2.707594394683838; \n",
      "fold: TRAIN; iteration: 628; epoch: 0; loss: 2.9440832138061523; \n",
      "fold: TRAIN; iteration: 629; epoch: 0; loss: 2.9361002445220947; \n",
      "fold: TRAIN; iteration: 630; epoch: 0; loss: 2.9029669761657715; \n",
      "fold: TRAIN; iteration: 631; epoch: 0; loss: 2.9932119846343994; \n",
      "fold: TRAIN; iteration: 632; epoch: 0; loss: 2.8238446712493896; \n",
      "fold: TRAIN; iteration: 633; epoch: 0; loss: 2.997023820877075; \n",
      "fold: TRAIN; iteration: 634; epoch: 0; loss: 3.0162267684936523; \n",
      "fold: TRAIN; iteration: 635; epoch: 0; loss: 2.922598361968994; \n",
      "fold: TRAIN; iteration: 636; epoch: 0; loss: 2.939257860183716; \n",
      "fold: TRAIN; iteration: 637; epoch: 0; loss: 2.8123373985290527; \n",
      "fold: TRAIN; iteration: 638; epoch: 0; loss: 2.8029754161834717; \n",
      "fold: TRAIN; iteration: 639; epoch: 0; loss: 3.18452787399292; \n",
      "fold: TRAIN; iteration: 640; epoch: 0; loss: 3.0418481826782227; \n",
      "fold: TRAIN; iteration: 641; epoch: 0; loss: 2.7058987617492676; \n",
      "fold: TRAIN; iteration: 642; epoch: 0; loss: 2.838975191116333; \n",
      "fold: TRAIN; iteration: 643; epoch: 0; loss: 3.032313823699951; \n",
      "fold: TRAIN; iteration: 644; epoch: 0; loss: 2.8298749923706055; \n",
      "fold: TRAIN; iteration: 645; epoch: 0; loss: 2.9457056522369385; \n",
      "fold: TRAIN; iteration: 646; epoch: 0; loss: 2.565464735031128; \n",
      "fold: TRAIN; iteration: 647; epoch: 0; loss: 2.6238481998443604; \n",
      "fold: TRAIN; iteration: 648; epoch: 0; loss: 2.886777877807617; \n",
      "fold: TRAIN; iteration: 649; epoch: 0; loss: 2.9383437633514404; \n",
      "fold: TRAIN; iteration: 650; epoch: 0; loss: 2.7729947566986084; \n",
      "fold: TRAIN; iteration: 651; epoch: 0; loss: 3.011564254760742; \n",
      "fold: TRAIN; iteration: 652; epoch: 0; loss: 2.7691032886505127; \n",
      "fold: TRAIN; iteration: 653; epoch: 0; loss: 3.176896572113037; \n",
      "fold: TRAIN; iteration: 654; epoch: 0; loss: 2.910158395767212; \n",
      "fold: TRAIN; iteration: 655; epoch: 0; loss: 3.0500214099884033; \n",
      "fold: TRAIN; iteration: 656; epoch: 0; loss: 2.9172399044036865; \n",
      "fold: TRAIN; iteration: 657; epoch: 0; loss: 2.6821765899658203; \n",
      "fold: TRAIN; iteration: 658; epoch: 0; loss: 3.106879949569702; \n",
      "fold: TRAIN; iteration: 659; epoch: 0; loss: 3.0320990085601807; \n",
      "fold: TRAIN; iteration: 660; epoch: 0; loss: 3.033107280731201; \n",
      "fold: TRAIN; iteration: 661; epoch: 0; loss: 2.598870277404785; \n",
      "fold: TRAIN; iteration: 662; epoch: 0; loss: 2.971284866333008; \n",
      "fold: TRAIN; iteration: 663; epoch: 0; loss: 2.960033655166626; \n",
      "fold: TRAIN; iteration: 664; epoch: 0; loss: 2.9869015216827393; \n",
      "fold: TRAIN; iteration: 665; epoch: 0; loss: 2.958787202835083; \n",
      "fold: TRAIN; iteration: 666; epoch: 0; loss: 2.9746294021606445; \n",
      "fold: TRAIN; iteration: 667; epoch: 0; loss: 3.1500866413116455; \n",
      "fold: TRAIN; iteration: 668; epoch: 0; loss: 2.8967578411102295; \n",
      "fold: TRAIN; iteration: 669; epoch: 0; loss: 2.7735488414764404; \n",
      "fold: TRAIN; iteration: 670; epoch: 0; loss: 3.093111991882324; \n",
      "fold: TRAIN; iteration: 671; epoch: 0; loss: 3.205317735671997; \n",
      "fold: TRAIN; iteration: 672; epoch: 0; loss: 3.00148344039917; \n",
      "fold: TRAIN; iteration: 673; epoch: 0; loss: 3.0794477462768555; \n",
      "fold: TRAIN; iteration: 674; epoch: 0; loss: 2.9824068546295166; \n",
      "fold: TRAIN; iteration: 675; epoch: 0; loss: 2.638944149017334; \n",
      "fold: TRAIN; iteration: 676; epoch: 0; loss: 2.650820255279541; \n",
      "fold: TRAIN; iteration: 677; epoch: 0; loss: 2.9492902755737305; \n",
      "fold: TRAIN; iteration: 678; epoch: 0; loss: 3.0480611324310303; \n",
      "fold: TRAIN; iteration: 679; epoch: 0; loss: 2.881887435913086; \n",
      "fold: TRAIN; iteration: 680; epoch: 0; loss: 2.9212841987609863; \n",
      "fold: TRAIN; iteration: 681; epoch: 0; loss: 2.903224468231201; \n",
      "fold: TRAIN; iteration: 682; epoch: 0; loss: 2.816831350326538; \n",
      "fold: TRAIN; iteration: 683; epoch: 0; loss: 2.734344720840454; \n",
      "fold: TRAIN; iteration: 684; epoch: 0; loss: 3.031158447265625; \n",
      "fold: TRAIN; iteration: 685; epoch: 0; loss: 2.873635768890381; \n",
      "fold: TRAIN; iteration: 686; epoch: 0; loss: 3.2066171169281006; \n",
      "fold: TRAIN; iteration: 687; epoch: 0; loss: 2.845560312271118; \n",
      "fold: TRAIN; iteration: 688; epoch: 0; loss: 2.7727062702178955; \n",
      "fold: TRAIN; iteration: 689; epoch: 0; loss: 3.1364593505859375; \n",
      "fold: TRAIN; iteration: 690; epoch: 0; loss: 2.9346632957458496; \n"
     ]
    }
   ],
   "source": [
    "docs.create_imputation(\n",
    "    'image_captioner',\n",
    "    model='conditional_lm',\n",
    "    loss='autoregressive_loss',\n",
    "    target='captioning_tokenizer',\n",
    "    splitter='captioning_splitter',\n",
    "    validation_sets=['captioning'],\n",
    "    batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd74bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_imputations'].delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de1319",
   "metadata": {},
   "source": [
    "Now we have trained and evaluated several models of various types. This includes multiple interacting models with mutual dependencies. In the case of our own efficient semantic search, and also the attribute predictor, these models are downstream of the image clip model, in the sense that at inference time, clip must be present in order to be able to execute these models. In the case of attribute prediction, the training task was downstream from the \n",
    "spacy pipeline for part-of-speech tagging; these tags were used to produce targets for training. However at run-time, the spacy pipeline won't be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74500ec3",
   "metadata": {},
   "source": [
    "The models which we've added and trained are now ready to go, and when new data is added or updated to the collection, they will automatically process this data, and insert the model outputs into the collection documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15fe60",
   "metadata": {},
   "source": [
    "Here is the complete set of models which exist in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6eedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1fe7c",
   "metadata": {},
   "source": [
    "Not all of these respond to incoming data, for that we need to specify the `active` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f54582",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models(active=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689545a",
   "metadata": {},
   "source": [
    "We can see that these models have processed all documents and their outputs saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3951ff",
   "metadata": {},
   "source": [
    "Now, let's test what happens when we add new data to the collection, by adding the remaining data points from the \n",
    "CoCo data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2653f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = [{**r, \"update\": True} for r in data[-1000:]]\n",
    "docs.insert_many(update, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Text vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef70f6d-a189-460a-8864-241a689624e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "APPLY = False\n",
    "COLLECTION_NAME = '<var:table_name>' if not APPLY else 'sample_text_vector_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock:///test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get useful sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7902bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import io\n",
    "\n",
    "def getter():\n",
    "    response = requests.get('https://superduperdb-public-demo.s3.amazonaws.com/text.json')\n",
    "    return json.loads(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad2cd3-65d9-41c9-82b9-e6e9700828fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    data = getter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede8ae1",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5965fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    from superduper import Document\n",
    "    ids = db.execute(db[COLLECTION_NAME].insert([Document(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fea927-ee4a-44cd-aaf2-634b574c316d",
   "metadata": {},
   "source": [
    "## Apply a chunker for search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90bda-e8c4-494e-a38c-837fb63689ae",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that applying a chunker is ***not*** mandatory for search.\n",
    "If your data is already chunked (e.g. short text snippets or audio) or if you\n",
    "are searching through something like images, which can't be chunked, then this\n",
    "won't be necessary.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20eaa0-a416-4483-938e-23f79845739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Model\n",
    "\n",
    "class Chunker(Model):\n",
    "    chunk_size: int = 200\n",
    "    signature: str = 'singleton'\n",
    "\n",
    "    def predict(self, text):\n",
    "        text = text.split()\n",
    "        chunks = [' '.join(text[i:i + self.chunk_size]) for i in range(0, len(text), self.chunk_size)]\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f",
   "metadata": {},
   "source": [
    "Now we apply this chunker to the data by wrapping the chunker in `Listener`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Listener\n",
    "\n",
    "upstream_listener = Listener(\n",
    "    model=Chunker('chunk_model', chunk_size=200, example='test ' * 50),\n",
    "    select=db[COLLECTION_NAME].select(),\n",
    "    key='x',\n",
    "    identifier=f'chunker_{COLLECTION_NAME}',\n",
    "    flatten=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31900eec-b516-4bef-939e-2e8f46252b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(upstream_listener, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5377c0-4c9b-4ba9-8f08-5e866b9220b5",
   "metadata": {},
   "source": [
    "## Select outputs of upstream listener"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f5f62-95c3-483b-ae74-a5cdb5c1c83d",
   "metadata": {},
   "source": [
    ":::note\n",
    "This is useful if you have performed a first step, such as pre-computing \n",
    "features, or chunking your data. You can use this query to \n",
    "operate on those outputs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build text embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10753ea4-9893-4056-813d-7d6ddf78ce02",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.vector_index import sqlvector\n",
    "from superduper_openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(identifier='text-embedding-ada-002', datatype=sqlvector(shape=(1536,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39314098-8462-4de9-8240-09005b928a86",
   "metadata": {},
   "source": [
    "Sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a9a60-41df-461d-b165-1d136ee25694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.vector_index import sqlvector\n",
    "from superduper_sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_transformers_embedding = SentenceTransformer(\n",
    "    identifier=\"sentence-transformers-embedding\",\n",
    "    model=\"BAAI/bge-small-en\",\n",
    "    datatype=sqlvector(shape=(1024,)),\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    predict_kwargs={\"show_progress_bar\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882dadc-878a-48d1-add7-e2931f9ec395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.model import ModelRouter\n",
    "\n",
    "embedding_model = ModelRouter(\n",
    "    'embedding',\n",
    "    models={'openai': openai_embedding, 'sentence_transformers': sentence_transformers_embedding},\n",
    "    model='<var:embedding_model>' if not APPLY else 'openai',\n",
    "    example='this is a test',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31843db-8638-458a-a770-96a79041be88",
   "metadata": {},
   "source": [
    "## Create vector-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663fa4b-c2ec-427d-bf8b-b8b109cc2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import VectorIndex, Listener\n",
    "\n",
    "vector_index_name = f'vector-index-{COLLECTION_NAME}'\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    vector_index_name,\n",
    "    indexing_listener=Listener(\n",
    "        key=upstream_listener.outputs,\n",
    "        select=db[upstream_listener.outputs].select(),\n",
    "        model=embedding_model,\n",
    "        identifier=f'embedding-listener-{COLLECTION_NAME}',\n",
    "        upstream=[upstream_listener],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c3505-54c5-4e68-84ec-3df8bea0fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(vector_index, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bf5b6-4644-4e4c-b65b-e6bafdc6b49f",
   "metadata": {},
   "source": [
    "By applying the RAG model to the database, it will subsequently be accessible for use in other services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6787c78-4b14-4a72-818b-450408a74331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Application\n",
    "\n",
    "app = Application(\n",
    "    f'text-vector-search-app-{COLLECTION_NAME}',\n",
    "    components=[\n",
    "        upstream_listener,\n",
    "        vector_index,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c16557-af76-4e70-83d9-2984e19a9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(app, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0306b-0969-49ab-95c4-0eb93c39f515",
   "metadata": {},
   "source": [
    "You can now load the model elsewhere and make predictions using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f668a-63c4-49ff-a9cc-93d65b500037",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'tell me about the use of pylance and vector-search'\n",
    "\n",
    "vector_search_query = db[f'_outputs__chunker_{COLLECTION_NAME}'].like(\n",
    "    {f'_outputs__chunker_{COLLECTION_NAME}': search_term},\n",
    "    n=10,\n",
    "    vector_index=vector_index_name,\n",
    ").select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866a0ab-8e72-4dc4-8a91-9ffe73f17faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    vector_search_query.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecffe2d-82f2-43cb-ba9e-56d56f1c7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import QueryTemplate, CFG\n",
    "\n",
    "qt = QueryTemplate(\n",
    "    'vector_search',\n",
    "    template=vector_search_query,\n",
    "    substitutions={\n",
    "        COLLECTION_NAME: 'table_name',\n",
    "        search_term: 'search_term',\n",
    "        'mongodb': 'data_backend',\n",
    "    },\n",
    "    types={\n",
    "        'search_term': {\n",
    "            'type': 'str',\n",
    "            'default': 'enter your question here...',\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': 'sample_text_vector_search'\n",
    "        },\n",
    "        'data_backend': {\n",
    "            'type': 'mongodb',\n",
    "            'choices': ['mongodb', 'ibis'],\n",
    "            'default': 'mongodb'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42119a4-6aef-46ec-a81d-cbe1167d8710",
   "metadata": {},
   "source": [
    "## Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e850c03-33c6-4c88-95d3-d14146a6a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template, CFG, Table, Schema\n",
    "from superduper.components.dataset import RemoteData\n",
    "\n",
    "template = Template(\n",
    "    'text_vector_search',\n",
    "    template=app,\n",
    "    default_table=Table(\n",
    "        'sample_text_vector_search',\n",
    "        schema=Schema('sample_text_vector_search/schema', fields={'x': 'str'}),\n",
    "        data=RemoteData(\n",
    "            'superduper-docs',\n",
    "            getter=getter,\n",
    "        )\n",
    "    ),\n",
    "    queries=[qt],\n",
    "    substitutions={COLLECTION_NAME: 'table_name', 'mongodb': 'data_backend'},\n",
    "    template_variables=['embedding_model', 'table_name', 'data_backend'],\n",
    "    types={\n",
    "        'embedding_model': {\n",
    "            'type': 'str',\n",
    "            'choices': ['openai', 'sentence_transformers'],\n",
    "            'default': 'openai',\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': 'sample_text_vector_search'\n",
    "        },\n",
    "        'data_backend': {\n",
    "            'type': 'mongodb',\n",
    "            'choices': ['mongodb', 'ibis'],\n",
    "            'default': 'mongodb'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924ba0d-7c01-4d6c-87fb-245531db7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "template.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

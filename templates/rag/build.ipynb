{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Retrieval augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef70f6d-a189-460a-8864-241a689624e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Oct-16 09:31:34.98\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.misc.plugins\u001b[0m:\u001b[36m13  \u001b[0m | \u001b[1mLoading plugin: mongodb\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:35.03\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m73  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:35.03\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.build\u001b[0m:\u001b[36m177 \u001b[0m | \u001b[1mConfiguration: \n",
      " +---------------+----------------------+\n",
      "| Configuration |        Value         |\n",
      "+---------------+----------------------+\n",
      "|  Data Backend | mongomock:///test_db |\n",
      "+---------------+----------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock:///test_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abae7f7-ad08-4dea-8198-626bb9e0f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = '<var:table_name>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get useful sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7902bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data = [{'x': r} for r in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede8ae1",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5965fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    from superduper import Document\n",
    "    \n",
    "    ids = db.execute(db[COLLECTION_NAME].insert([Document(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fea927-ee4a-44cd-aaf2-634b574c316d",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Apply a chunker for search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90bda-e8c4-494e-a38c-837fb63689ae",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that applying a chunker is ***not*** mandatory for search.\n",
    "If your data is already chunked (e.g. short text snippets or audio) or if you\n",
    "are searching through something like images, which can't be chunked, then this\n",
    "won't be necessary.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d20eaa0-a416-4483-938e-23f79845739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import model\n",
    "\n",
    "CHUNK_SIZE = 200\n",
    "\n",
    "@model(signature='singleton', example='test ' * 50)\n",
    "def chunker(text):\n",
    "    text = text.split()\n",
    "    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f",
   "metadata": {},
   "source": [
    "Now we apply this chunker to the data by wrapping the chunker in `Listener`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Listener\n",
    "\n",
    "upstream_listener = Listener(\n",
    "    model=chunker,\n",
    "    select=db[COLLECTION_NAME].select(),\n",
    "    key='x',\n",
    "    identifier='chunker',\n",
    "    flatten=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31900eec-b516-4bef-939e-2e8f46252b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(upstream_listener)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5377c0-4c9b-4ba9-8f08-5e866b9220b5",
   "metadata": {},
   "source": [
    "## Select outputs of upstream listener"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f5f62-95c3-483b-ae74-a5cdb5c1c83d",
   "metadata": {},
   "source": [
    ":::note\n",
    "This is useful if you have performed a first step, such as pre-computing \n",
    "features, or chunking your data. You can use this query to \n",
    "operate on those outputs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build text embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10753ea4-9893-4056-813d-7d6ddf78ce02",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from superduper import vector\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-<secret>'\n",
    "from superduper_openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(identifier='text-embedding-ada-002', datatype=vector(shape=(1024,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39314098-8462-4de9-8240-09005b928a86",
   "metadata": {},
   "source": [
    "Sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4a9a60-41df-461d-b165-1d136ee25694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.10.13/envs/superduper-3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from superduper import vector\n",
    "import sentence_transformers\n",
    "from superduper_sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_transformers_embedding = SentenceTransformer(\n",
    "    identifier=\"sentence-transformers-embedding\",\n",
    "    model=\"BAAI/bge-small-en\",\n",
    "    datatype=vector(shape=(1024,)),\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    predict_kwargs={\"show_progress_bar\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1882dadc-878a-48d1-add7-e2931f9ec395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.model import ModelRouter\n",
    "\n",
    "embedding_model = ModelRouter(\n",
    "    'embedding',\n",
    "    models={'openai': openai_embedding, 'sentence_transformers': sentence_transformers_embedding},\n",
    "    model='<var:embedding_model>',\n",
    "    example='this is a test',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31843db-8638-458a-a770-96a79041be88",
   "metadata": {},
   "source": [
    "## Create vector-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4663fa4b-c2ec-427d-bf8b-b8b109cc2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import VectorIndex, Listener\n",
    "\n",
    "vector_index_name = 'vector-index'\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    vector_index_name,\n",
    "    indexing_listener=Listener(\n",
    "        key=upstream_listener.outputs,\n",
    "        select=db[upstream_listener.outputs].select(),\n",
    "        model=embedding_model,\n",
    "        identifier='embedding-listener',\n",
    "        upstream=[upstream_listener],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509c3505-54c5-4e68-84ec-3df8bea0fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179a67b-4e40-496b-9851-98f32d42faa0",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f98e5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai import OpenAIChatCompletion\n",
    "\n",
    "llm_openai = OpenAIChatCompletion(identifier='llm-openai', model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bf39c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_anthropic import AnthropicCompletions\n",
    "import os\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-<secret>\"\n",
    "\n",
    "predict_kwargs = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.8,\n",
    "}\n",
    "\n",
    "llm_anthropic = AnthropicCompletions(identifier='llm-vllm', model='claude-2.1', predict_kwargs=predict_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95e48deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Oct-16 09:31:40.05\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper_vllm.model\u001b[0m:\u001b[36m31  \u001b[0m | \u001b[1mSetting num_gpus to 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper_vllm import VllmCompletion\n",
    "\n",
    "predict_kwargs = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.8,\n",
    "}\n",
    "\n",
    "llm_vllm = VllmCompletion(\n",
    "    identifier=\"llm-vllm\",\n",
    "    vllm_params={\n",
    "        'model': 'TheBloke/Mistral-7B-Instruct-v0.2-AWQ',\n",
    "        \"gpu_memory_utilization\": 0.7,\n",
    "        \"max_model_len\": 1024,\n",
    "        \"quantization\": \"awq\",\n",
    "    },\n",
    "    predict_kwargs=predict_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fdbfae2-af7d-4845-bce5-0cb230e3614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF mistral-7b-instruct-v0.2.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
    "# from superduper_llamacpp.model import LlamaCpp\n",
    "\n",
    "# llm_llamacpp = LlamaCpp(identifier=\"llm-llamacpp\", model_name_or_path=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c6a34f-692f-4338-a40d-c2b5acfbaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ModelRouter(\n",
    "    'llm',\n",
    "    models={\n",
    "        'openai': llm_openai,\n",
    "        'anthropic': llm_anthropic,\n",
    "        'vllm': llm_vllm,\n",
    "        # 'llamacpp': llm_llamacpp,\n",
    "    },\n",
    "    model='<var:llm_model>',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae6203-dcc4-493c-a8f8-f727f0f75778",
   "metadata": {},
   "source": [
    "## Answer question with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44baeb09-6f35-4cf2-b814-46283a59f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import model\n",
    "from superduper.components.model import RAGModel\n",
    "\n",
    "prompt_template = (\n",
    "    \"Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question: {query}\"\n",
    ")\n",
    "\n",
    "rag = RAGModel(\n",
    "    'rag-model',\n",
    "    select=db[upstream_listener.outputs].select().like({upstream_listener.outputs: '<var:query>'}, vector_index=vector_index_name, n=5),\n",
    "    prompt_template=prompt_template,\n",
    "    key=upstream_listener.outputs,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d3a0d3a-da1c-41ec-b16c-f281c46ad794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a82ea22-9694-4c65-b72f-c89ae49d1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    rag.predict('Tell me about vector-search')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bf5b6-4644-4e4c-b65b-e6bafdc6b49f",
   "metadata": {},
   "source": [
    "By applying the RAG model to the database, it will subsequently be accessible for use in other services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6787c78-4b14-4a72-818b-450408a74331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Application\n",
    "\n",
    "app = Application(\n",
    "    'rag-app',\n",
    "    components=[\n",
    "        upstream_listener,\n",
    "        vector_index,\n",
    "        rag,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c16557-af76-4e70-83d9-2984e19a9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0306b-0969-49ab-95c4-0eb93c39f515",
   "metadata": {},
   "source": [
    "You can now load the model elsewhere and make predictions using the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42119a4-6aef-46ec-a81d-cbe1167d8710",
   "metadata": {},
   "source": [
    "## Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e850c03-33c6-4c88-95d3-d14146a6a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Oct-16 09:31:40.07\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf listener:chunker already exists\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:40.07\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf model:chunker already exists\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:40.07\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:dill_lazy already exists\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:40.07\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf var-table-name-select already exists\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:40.08\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf datatype:vector[1024] already exists\u001b[0m\n",
      "\u001b[32m2024-Oct-16 09:31:40.08\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m471 \u001b[0m | \u001b[33m\u001b[1mLeaf model:llm-vllm already exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import Template\n",
    "\n",
    "template = Template(\n",
    "    'rag',\n",
    "    template=app,\n",
    "    data=data,\n",
    "    substitutions={'docs': 'table_name'},\n",
    "    template_variables=['llm_model', 'embedding_model', 'table_name'],\n",
    "    types={\n",
    "        'llm_model': {\n",
    "            'type': 'str',\n",
    "            'choices': ['openai', 'anthropic', 'vllm', 'llamacpp'],\n",
    "            'default': 'openai',\n",
    "        },\n",
    "        'embedding_model': {\n",
    "            'type': 'str',\n",
    "            'choices': ['openai', 'sentence_transformers'],\n",
    "            'default': 'openai',\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': '_sample_rag'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8924ba0d-7c01-4d6c-87fb-245531db7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "template.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

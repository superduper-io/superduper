{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {},
   "source": [
    "# Multimodal vector search - images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock:///test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get useful sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2a973-56bc-4a43-b375-6055bba40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b245a-6254-4219-a8e9-4a6360cff5c3",
   "metadata": {},
   "source": [
    "## Build multimodal embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b2646-8693-41dc-98e9-3c15b78ee68e",
   "metadata": {},
   "source": [
    "We define the output data type of a model as a vector for vector transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a19c2-c673-4bf9-9bea-f4bb279fc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper.components.vector_index import sqlvector\n",
    "\n",
    "output_datatype = sqlvector(shape=(1024,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40772155-8a01-4577-a9c9-7928fcd012f6",
   "metadata": {},
   "source": [
    "Then define two models, one for text embedding and one for image embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751ede0-4b9f-4f92-b4ec-f6b0e0740c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from superduper import vector, imported\n",
    "from superduper_torch import TorchModel\n",
    "\n",
    "rn50 = imported(clip.load)('RN50', device='cpu')\n",
    "\n",
    "compatible_model = TorchModel(\n",
    "    identifier='clip_text',\n",
    "    object=rn50[0],\n",
    "    preprocess=lambda x: clip.tokenize(x)[0],\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    datatype=output_datatype,\n",
    "    forward_method='encode_text',\n",
    ")\n",
    "\n",
    "embedding_model = TorchModel(\n",
    "    identifier='clip_image',\n",
    "    object=rn50[0].visual,\n",
    "    preprocess=rn50[1],\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    datatype=output_datatype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0119da-9cfd-4a60-8847-c3bfdf37697f",
   "metadata": {},
   "source": [
    "Because we use multimodal models, we define different keys to specify which model to use for embedding calculations in the vector_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e75fab-8504-4d17-a7d9-f98667a5d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_key = 'img' \n",
    "compatible_key = 'text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8b40d-3750-4d7b-aa60-62e07b734b04",
   "metadata": {},
   "source": [
    "## Create vector-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee3ff4-880e-477b-bbdf-5b8d89c56de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_name = 'my-vector-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cede653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import VectorIndex, Listener\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    vector_index_name,\n",
    "    indexing_listener=Listener(\n",
    "        key=indexing_key,                 # the `Document` key `model` should ingest to create embedding\n",
    "        select=db['docs'].select(),       # a `Select` query telling which data to search over\n",
    "        model=embedding_model,            # a `_Predictor` how to convert data to embeddings\n",
    "        identifier='indexing-listener',\n",
    "    ),\n",
    "    compatible_listener=Listener(\n",
    "        key=compatible_key,               # the `Document` key `model` should ingest to create embedding\n",
    "        model=compatible_model,           # a `_Predictor` how to convert data to embeddings\n",
    "        select=None,\n",
    "        identifier='compatible-listener',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508c32b-1db2-4b45-a1d3-8b0e352d59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Application\n",
    "\n",
    "application = Application(\n",
    "    'image-vector-search',\n",
    "    components=[vector_index],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339180f6-9855-4c5d-ae70-78040d72d170",
   "metadata": {},
   "source": [
    "## Add the data\n",
    "\n",
    "The order in which data is added is not important. *However* if your data requires a custom `Schema` in order to work, it's easier to add the `Application` first, and the data later. The advantage of this flexibility, is that once the `Application` is installed, it's waiting for incoming data, so that the `Application` is always up-to-date. This comes in particular handy with AI scenarios which need to respond to changing news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Document\n",
    "\n",
    "table_or_collection = db['docs']\n",
    "\n",
    "ids = db.execute(table_or_collection.insert([Document(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a87f9d-581a-419a-81b8-a743250413e9",
   "metadata": {},
   "source": [
    "## Perform a vector search\n",
    "\n",
    "We can perform the vector searches using two types of data:\n",
    "\n",
    "- Text: By text description, we can find images similar to the text description.\n",
    "- Image: By using an image, we can find images similar to the provided image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce565823-4655-488c-8684-2240107fa30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = Document({compatible_key: \"Find a black cat\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8059626-dff8-4fe0-b872-97b8eb8b1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "search_image = data[0]\n",
    "display(search_image)\n",
    "item = Document(search_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ba07d-1124-4d94-a117-60d2e72581f7",
   "metadata": {},
   "source": [
    "Once we have this search target, we can execute a search as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061de0b-2694-4b36-844c-7753a465360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = db['docs'].like(item, vector_index=vector_index_name, n=5).select()\n",
    "results = list(db.execute(select))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d9af9-a012-42bd-aad4-31b92d089caa",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ecea5-3a58-457c-ac50-ddc742484f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for result in results:\n",
    "    display(result[indexing_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1390e3b-d942-4442-9071-ef8045d96847",
   "metadata": {},
   "source": [
    "## Create a `Template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5cde1f-8d51-40c6-8d82-c2a38f0d0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = db.load('table', 'docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5f232-0ac6-4b72-a988-69099bfb4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data = data\n",
    "t.identifier = '_sample_multimodal_image_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bc2d4-5313-4584-8607-1eacfff09660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template\n",
    "\n",
    "template = Template(\n",
    "    'image-vector-search',\n",
    "    template=application,\n",
    "    default_table=t,\n",
    "    substitutions={'docs': 'table', 'cpu': 'device'},\n",
    ")\n",
    "\n",
    "template.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

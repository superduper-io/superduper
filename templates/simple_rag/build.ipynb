{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Simple retrieval augmented generation with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running superduper in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef70f6d-a189-460a-8864-241a689624e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "APPLY = True\n",
    "SAMPLE_COLLECTION_NAME = 'sample_simple_rag'\n",
    "COLLECTION_NAME = '<var:table_name>' if not APPLY else 'docs'\n",
    "ID_FIELD = '<var:id_field>' if not APPLY else 'id'\n",
    "OUTPUT_PREFIX = 'outputs__'\n",
    "EAGER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superduper import superduper, CFG\n",
    "import os\n",
    "\n",
    "db = superduper('mongomock://', initialize_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7902bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import io\n",
    "from superduper import logging\n",
    "\n",
    "\n",
    "def getter():\n",
    "    logging.info('Downloading data...')\n",
    "    response = requests.get('https://superduperdb-public-demo.s3.amazonaws.com/text.json')\n",
    "    logging.info('Downloading data... (Done)')\n",
    "    data = json.loads(response.content.decode('utf-8'))\n",
    "    return [{'x': r} for r in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8dd07-1b47-4dce-84dd-a081d1f5ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    data = getter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede8ae1",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5965fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    from superduper import Document, Table\n",
    "    table = Table(COLLECTION_NAME, fields={'x': 'str'})\n",
    "    db.apply(table, force=True)\n",
    "    ids = db[COLLECTION_NAME].insert(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885060-450c-4446-b5fb-e58591c0d1ff",
   "metadata": {},
   "source": [
    "Create plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879a4df-6f60-4c80-8fdd-285a1ef92c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Plugin\n",
    "\n",
    "plugin = Plugin(path='./rag_plugin.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fea927-ee4a-44cd-aaf2-634b574c316d",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Apply a chunker for search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90bda-e8c4-494e-a38c-837fb63689ae",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that applying a chunker is ***not*** mandatory for search.\n",
    "If your data is already chunked (e.g. short text snippets or audio) or if you\n",
    "are searching through something like images, which can't be chunked, then this\n",
    "won't be necessary.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Listener\n",
    "from rag_plugin import Chunker\n",
    "\n",
    "upstream_listener = Listener(\n",
    "    model=Chunker(identifier='chunker'),\n",
    "    select=db[COLLECTION_NAME],\n",
    "    key='x',\n",
    "    identifier='chunker',\n",
    "    flatten=True,\n",
    "    upstream=[plugin],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31900eec-b516-4bef-939e-2e8f46252b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY and EAGER:\n",
    "    db.apply(upstream_listener, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5377c0-4c9b-4ba9-8f08-5e866b9220b5",
   "metadata": {},
   "source": [
    "## Select outputs of upstream listener"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f5f62-95c3-483b-ae74-a5cdb5c1c83d",
   "metadata": {},
   "source": [
    ":::note\n",
    "This is useful if you have performed a first step, such as pre-computing \n",
    "features, or chunking your data. You can use this query to \n",
    "operate on those outputs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build text embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10753ea4-9893-4056-813d-7d6ddf78ce02",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from superduper_openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(\n",
    "    identifier='text-embedding',\n",
    "    model='text-embedding-ada-002',\n",
    "    datatype='vector[float32:1536]',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31843db-8638-458a-a770-96a79041be88",
   "metadata": {},
   "source": [
    "## Create vector-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663fa4b-c2ec-427d-bf8b-b8b109cc2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import VectorIndex, Listener\n",
    "\n",
    "vector_index_name = 'vectorindex'\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    vector_index_name,\n",
    "    indexing_listener=Listener(\n",
    "        key=upstream_listener.outputs,\n",
    "        select=db[upstream_listener.outputs],\n",
    "        model=openai_embedding,\n",
    "        identifier='embeddinglistener',\n",
    "        upstream=[upstream_listener],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c3505-54c5-4e68-84ec-3df8bea0fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY and EAGER:\n",
    "    db.apply(vector_index, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179a67b-4e40-496b-9851-98f32d42faa0",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75faf501-f0cf-4707-a165-5a05cfb14bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper_openai import OpenAIChatCompletion\n",
    "\n",
    "\n",
    "llm_openai = OpenAIChatCompletion(\n",
    "    identifier='llm-model',\n",
    "    model='gpt-3.5-turbo',\n",
    "    datatype='str',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae6203-dcc4-493c-a8f8-f727f0f75778",
   "metadata": {},
   "source": [
    "## Answer question with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44baeb09-6f35-4cf2-b814-46283a59f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_plugin import RAGModel\n",
    "\n",
    "\n",
    "prompt_template = (\n",
    "    \"Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n\"\n",
    "    \"These snippets are samples from our internal data-repositories, and should be used exclusively and as a matter\"\n",
    "    \" of priority to answer the question. Please answer in 20 words or less.\\n\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question: {query}\"\n",
    ")\n",
    "\n",
    "rag = RAGModel(\n",
    "    'simple_rag',\n",
    "    select=db[upstream_listener.outputs].select().like({upstream_listener.outputs: '<var:query>'}, vector_index=vector_index_name, n=5),\n",
    "    prompt_template=prompt_template,\n",
    "    key=upstream_listener.outputs,\n",
    "    llm=llm_openai,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a0d3a-da1c-41ec-b16c-f281c46ad794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY and EAGER:\n",
    "    db.apply(rag, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bf5b6-4644-4e4c-b65b-e6bafdc6b49f",
   "metadata": {},
   "source": [
    "By applying the RAG model to the database, it will subsequently be accessible for use in other services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974643b-e642-40ea-942f-4d90e0d1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Streamlit, Plugin\n",
    "from rag_plugin import demo_func\n",
    "\n",
    "demo = Streamlit('simple-rag-demo', demo_func=demo_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6787c78-4b14-4a72-818b-450408a74331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Application\n",
    "\n",
    "app = Application(\n",
    "    'simple-rag-app',\n",
    "    upstream=[plugin],\n",
    "    components=[\n",
    "        upstream_listener,\n",
    "        vector_index,\n",
    "        rag,\n",
    "        demo,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c16557-af76-4e70-83d9-2984e19a9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    db.apply(app, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82ea22-9694-4c65-b72f-c89ae49d1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    rag = db.load('RAGModel', 'simple_rag')\n",
    "    print(rag.predict('Tell me about vector-search in the project and the use of lance.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0306b-0969-49ab-95c4-0eb93c39f515",
   "metadata": {},
   "source": [
    "You can now load the model elsewhere and make predictions using the following command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42119a4-6aef-46ec-a81d-cbe1167d8710",
   "metadata": {},
   "source": [
    "## Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e850c03-33c6-4c88-95d3-d14146a6a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template, Table, Schema\n",
    "from superduper.components.dataset import RemoteData\n",
    "\n",
    "template = Template(\n",
    "    'simple_rag',\n",
    "    template=app,\n",
    "    substitutions={\n",
    "        COLLECTION_NAME: 'table_name',\n",
    "        'text-embedding-ada-002': 'embedding_model',\n",
    "        'gpt-3.5-turbo': 'llm_model',\n",
    "    },\n",
    "    template_variables=['table_name', 'id_field', 'embedding_model', 'llm_model'],\n",
    "    default_tables=[\n",
    "        Table(\n",
    "            'sample_simple_rag',\n",
    "            fields={'x': 'str'},\n",
    "            data=RemoteData(\n",
    "                'superduper-docs',\n",
    "                getter=getter,\n",
    "            )\n",
    "        ),\n",
    "    ],\n",
    "    types={\n",
    "        'id_field': {\n",
    "            'type': 'str',\n",
    "            'default': '_id',\n",
    "        },\n",
    "        'embedding_model': {\n",
    "            'type': 'str',\n",
    "            'default': 'text-embedding-ada-002',\n",
    "            'choices': ['text-embedding-ada-002', 'nomic-embed-text:latest'],\n",
    "        },\n",
    "        'llm_model': {\n",
    "            'type': 'str',\n",
    "            'default': 'gpt-3.5-turbo',\n",
    "            'choices': ['gpt-3.5-turbo', 'gpt-4-turbo', 'llama3.1:8b']\n",
    "        },\n",
    "        'table_name': {\n",
    "            'type': 'str',\n",
    "            'default': SAMPLE_COLLECTION_NAME,\n",
    "        }\n",
    "    },\n",
    "    schema={\n",
    "        \"id_field\": \"id_field\",\n",
    "        \"embedding_model\": \"embedding_model\",\n",
    "        \"llm_model\": \"llm_model\",\n",
    "        \"table_name\": \"table_name\",\n",
    "    },\n",
    "    db=db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef7117-3985-4501-a99a-6b0986d41b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

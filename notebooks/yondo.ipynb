{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d9035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.mongodb.client import SuperDuperClient\n",
    "\n",
    "c = SuperDuperClient()\n",
    "docs = c.yondo.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0edad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('63bc0aa9456b1bb8fc0a78dc'),\n",
       " 'key': 'html_template',\n",
       " 'value': '\\n<div><b>{{ r[\\'brand\\'] }} - {{ r[\\'title\\'] }}</b></div>\\n<img src=\"{{ r[\\'img\\'][\\'_content\\'][\\'url\\'] }}\" />\\n'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.database['_meta'].find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "class PILImage:\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        buffer = io.BytesIO()\n",
    "        x.save(buffer, format='png')\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        return Image.open(io.BytesIO(bytes_))\n",
    "\n",
    "\n",
    "class FloatTensor:\n",
    "    types = (torch.FloatTensor, torch.Tensor)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        x = x.numpy()\n",
    "        assert x.dtype == numpy.float32\n",
    "        return memoryview(x).tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        array = numpy.frombuffer(bytes_, dtype=numpy.float32)\n",
    "        return torch.from_numpy(array).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d212632",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_type('float_tensor', FloatTensor, serializer='dill')\n",
    "docs.create_type('image', PILImage(), serializer='dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d6db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from clip import load, tokenize\n",
    "\n",
    "\n",
    "class Image(torch.nn.Module):\n",
    "    def __init__(self, model, preprocess):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode_image(x)\n",
    "\n",
    "\n",
    "class Text(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode_text(x)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return tokenize(x)[0]\n",
    "    \n",
    "\n",
    "\n",
    "class CLIP(torch.nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        model, preprocess = load(name)\n",
    "        self.image = Image(model, preprocess)\n",
    "        self.text = Text(model)\n",
    "\n",
    "    def preprocess(self, r):\n",
    "        out = {}\n",
    "        if \"brand\" in r or \"title\" in r:\n",
    "            out[\"text\"] = self.text.preprocess(f'{r.get(\"brand\", \"\")} {r.get(\"title\", \"\")}')\n",
    "        if \"img\" in r:\n",
    "            out[\"image\"] = self.image.preprocess(r['img'])\n",
    "        assert out\n",
    "        return out\n",
    "\n",
    "    def forward(self, r):\n",
    "        assert r\n",
    "        key = next(iter(r.keys()))\n",
    "        bs = r[key].shape[0]\n",
    "        out = torch.zeros(bs, 1024).to(r[key].device)\n",
    "        n = 0\n",
    "        if 'image' in r:\n",
    "            tmp = self.image.forward(r['image'])\n",
    "            tmp = tmp.div(tmp.pow(2).sum(axis=1).sqrt()[:, None])\n",
    "            out += tmp\n",
    "            n += 1\n",
    "        if 'text' in r:\n",
    "            tmp = self.text.forward(r['text'])\n",
    "            tmp = tmp.div(tmp.pow(2).sum(axis=1).sqrt()[:, None])\n",
    "            out += tmp\n",
    "            n += 1\n",
    "        return out / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c5e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model('clip', CLIP('RN50'), serializer='dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.database.get_object_info('clip', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_objects'].find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x, y):\n",
    "    return x.matmul(y.T)\n",
    "\n",
    "\n",
    "def css(x, y):\n",
    "    x = x.div(x.norm(dim=1)[:, None])\n",
    "    y = y.div(y.norm(dim=1)[:, None])\n",
    "    return dot(x, y)\n",
    "\n",
    "docs.create_measure('css', css, serializer='dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a177a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_semantic_index(\n",
    "    'clip', ['clip'], ['_base'], 'css', loader_kwargs={'batch_size': 10, 'num_workers': 0},\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# lots of output - takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8178d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af902a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_watchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd859dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from clip import load, tokenize\n",
    "\n",
    "\n",
    "class ClassifierSimple(torch.nn.Module):\n",
    "    def __init__(self, categories, name):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        model, _ = load(name)\n",
    "        category_vectors = \\\n",
    "            model.encode_text(torch.cat([tokenize(x) for x in categories], 0))\n",
    "        category_vectors = category_vectors / category_vectors.norm(dim=1, keepdim=True)\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        self.register_buffer('category_vectors', category_vectors)\n",
    "        self.register_buffer('logit_scale', logit_scale)\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.category_vectors.device\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            x = x['_outputs']['_base']['clip']\n",
    "        else:\n",
    "            assert isinstance(x, torch.Tensor)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / x.norm(dim=1, keepdim=True)\n",
    "        logits_per_image = self.logit_scale * x @ self.category_vectors.t()\n",
    "        out = logits_per_image.softmax(dim=-1)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        pos = x.topk(1)[1].item()\n",
    "        return self.categories[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'silhouettes', \n",
    "    ClassifierSimple(\n",
    "        name='RN50',\n",
    "        categories=[\n",
    "            'accessory',\n",
    "            'blouse',\n",
    "            'coat',\n",
    "            'dress',\n",
    "            'hat',\n",
    "            'hoodie',\n",
    "            'jacket',\n",
    "            'pullover',\n",
    "            'shoes',\n",
    "            'skirt',\n",
    "            't-shirt',\n",
    "            'trousers',\n",
    "        ]\n",
    "    ),\n",
    "    serializer='dill',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1eae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.delete_watcher('silhouettes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_watcher(\n",
    "    'silhouettes',\n",
    "    'silhouettes',\n",
    "    features={'_base': 'clip'},\n",
    "    loader_kwargs={'batch_size': 10, 'num_workers': 0},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef45ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one(like={'title': 'leopard print t-shirt'}, semantic_index='clip')['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c82ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.remote = False\n",
    "docs.find_one(like={'img': {'_content': {'url': 'https://thumblr.uniid.it/product/238107/09ef5396fac2.jpg', 'type': 'image'}}},\n",
    "              semantic_index='clip', download=True)['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c335d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "c.yondo.types['float_tensor'].encode(torch.randn(32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

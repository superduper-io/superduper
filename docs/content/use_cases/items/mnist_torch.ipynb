{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9897997-dee8-4947-9327-b96fe06a5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from matplotlib) (5.13.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kartiksharma/Work/superduperdb/code/superduperdb/.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24af19",
   "metadata": {},
   "source": [
    "# Training and maintaining MNIST predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905783f",
   "metadata": {},
   "source": [
    "In this notebook we'll be implementing a classic machine learning classification task: MNIST hand written digit\n",
    "recognition, using a convolution neural network, but with a twist: we'll be implementing the task *in database* using SuperDuperDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3812091",
   "metadata": {},
   "source": [
    "SuperDuperDB supports MongoDB as a databackend. Correspondingly, we'll import the python MongoDB client `pymongo`\n",
    "and \"wrap\" our database to convert it to a SuperDuper `Datalayer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28adbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "WARNING:root:mongomock://test\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017\"\n",
    "# mongodb_uri = \"mongodb://superduper:superduper@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from superduperdb import superduper\n",
    "db = superduper(mongodb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e891",
   "metadata": {},
   "source": [
    "Now that we've connected to SuperDuperDB, let's add some data. MNIST is a good show case for one of the \n",
    "key benefits of SuperDuperDB - adding \"difficult\" data types. This can be done using an `Encoder` \n",
    "which is a key wrapper in SuperDuperDB's arsenal. The `Encoder` works closely together with the `Document` \n",
    "wrapper. Together they allow Python dictionaries containing non-JSONable/ `bytes` objects, to be insert into\n",
    "SuperDuperDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0934cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:found 0 uris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pymongo.results.InsertManyResult at 0x7fcc956edd00>,\n",
       " TaskWorkflow(database=<superduperdb.db.base.db.DB object at 0x7fcc66650a60>, G=<networkx.classes.digraph.DiGraph object at 0x7fcc674d5ee0>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb.ext.pillow.image import pil_image as i\n",
    "from superduperdb.container.document import Document as D\n",
    "from superduperdb.db.mongodb.query import Collection\n",
    "\n",
    "import random\n",
    "\n",
    "collection = Collection(name='mnist')\n",
    "\n",
    "mnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\n",
    "data = [D({'img': i(x[0]), 'class': x[1]}) for x in mnist_data]\n",
    "random.shuffle(data)\n",
    "data = data[:11000]\n",
    "\n",
    "db.execute(\n",
    "    collection.insert_many(data[:-1000], encoders=[i])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5341135",
   "metadata": {},
   "source": [
    "Now that we've inserted the images and their classes to the database, let's query some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36f9c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document({'img': Encodable(encoder=Encoder(identifier='pil_image', decoder=<Artifact artifact=<superduperdb.ext.pillow.image.DecoderPILImage object at 0x7fcc6777ba60> serializer=dill>, encoder=<Artifact artifact=<function encode_pil_image at 0x7fcc666558b0> serializer=dill>, shape=None, version=0), x=<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FCC960F24F0>, uri=None), 'class': 2, '_fold': 'train', '_id': ObjectId('651da8bd49486fb8b96384bb')})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = db.execute(collection.find_one())\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413d4c5",
   "metadata": {},
   "source": [
    "When we query the data, it's in exactly the format we inserted it. In particular, we can use the `PIL.Image` instances\n",
    "to inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fb7c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APC9IsF1TWLOwe6htFuZliM8xwke443MfSvUpfgRO8TLp/i3Rry63IqwhwMkn5ucnGBz059q4nxj4B1zwNJarq6QFLoMYZIJN6ttxkdARjcK5eitTw/4e1PxNq0GnaZayTSyuFLKpKxg9WY9gOua7P4nalZWOm6H4I028F7FoaP9pugQVknY5IXqQF5GM45x2rzitXw1pMWu+JdO0qa6FrFdTrG0xGdoPoO57D3r6W1S18A6B4Ll8K2vii10fzFQSXMEyG4fDDJYrySduD7V5NfeGPhZp9rdOvjK8vpjCwhWKDpJglSeORlSP+BL9a8toooor//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEklEQVR4AWNgoD9ghFjJXPbH5cGZ6iX1wq8w3RD1Dwje/vvX8mjtmXxbNHlukCQMPIVJskAY3+28Hr81YGCw1mTg4uJRuQOTRqfD/v3LQBeD87nu/pkF56AzIv/B7WRCl+MKRxdB8DXW/HviiOCispb8+1eHKoLghXz9e0wQwUViifou+PtvNZIAElNkxcV/J8r4kUQQzLKrz3//Y0XwkVly6/99/XuBGSjEzszgqwCWgoYtg99yTgZOBuF09acqZ1Sfdp5r34TQaf8DEiW/f//7C2T+/5cHkoOGUDAbRCEzMwMj2+XHLa/A8QJNCblxxgwM+wQeHGJguKGxNnj2v1//gaqhklLrHqzj2PgRon1ASQDf0W1mrf3a4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['img'].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fde8bb",
   "metadata": {},
   "source": [
    "Now let's create our model. SuperDuperDB supports these frameworks, out-of-the-box:\n",
    "\n",
    "- `torch`\n",
    "- `sklearn`\n",
    "- `transformers`\n",
    "- `sentence_transformers`\n",
    "- `openai`\n",
    "- `langchain`\n",
    "\n",
    "In this case, we're going to use PyTorch, since it's great for computer vision use-cases.\n",
    "We can combine `torch` with `torchvision` in SuperDuperDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb425e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(6),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = torch.nn.Linear(400, 120)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(120, 84)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def postprocess(x):\n",
    "    return int(x.topk(1)[1].item())\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n",
    "    )(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91155314",
   "metadata": {},
   "source": [
    "We've created `postprocess` and `preprocess` functions to handle the communication with the SuperDuperDB\n",
    "`Datalayer`. In order to create a native SuperDuperDB model, we wrap the model, preprocessing and postprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d47855b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = superduper(LeNet5(10), preprocess=preprocess, postprocess=postprocess)\n",
    "db.add(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde9224",
   "metadata": {},
   "source": [
    "The model predicts human readable outputs, directly from the `PIL.Image` objects. All \n",
    "models in SuperDuperDB are equipped with a `sklearn`-style `.predict` method. This makes \n",
    "it easy to know how each AI-framework will operate in combination with the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae586949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 10/10 [00:00<00:00, 24.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([r['img'] for r in data[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0457e",
   "metadata": {},
   "source": [
    "Now we're ready to \"train\" or \"fit\" the model. Trainable models in SuperDuperDB are equipped \n",
    "with a `sklearn`-like `.fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c610c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:model/lenet5/0 already exists - doing nothing\n",
      "INFO:root:fold: TRAIN; iteration: 0; objective: 2.2976460456848145; \n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 200.71it/s]\n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 176.47it/s]\n",
      "INFO:root:fold: VALID; iteration: 0; my_valid/acc: 1.0; objective: 2.3450374603271484; \n",
      "INFO:root:fold: TRAIN; iteration: 1; objective: 2.283189296722412; \n",
      "INFO:root:fold: TRAIN; iteration: 2; objective: 2.379317045211792; \n",
      "INFO:root:fold: TRAIN; iteration: 3; objective: 2.2560408115386963; \n",
      "INFO:root:fold: TRAIN; iteration: 4; objective: 2.263888120651245; \n",
      "INFO:root:fold: TRAIN; iteration: 5; objective: 2.2617416381835938; \n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 191.10it/s]\n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 174.40it/s]\n",
      "INFO:root:fold: VALID; iteration: 5; my_valid/acc: 1.0; objective: 2.1934499740600586; \n",
      "INFO:root:fold: TRAIN; iteration: 6; objective: 2.267531633377075; \n",
      "INFO:root:fold: TRAIN; iteration: 7; objective: 2.0316591262817383; \n",
      "INFO:root:fold: TRAIN; iteration: 8; objective: 2.0753679275512695; \n",
      "INFO:root:fold: TRAIN; iteration: 9; objective: 2.301872968673706; \n",
      "INFO:root:fold: TRAIN; iteration: 10; objective: 1.9658355712890625; \n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 184.13it/s]\n",
      "100%|█████████████████████████████████████████████████████| 4/4 [00:00<00:00, 162.05it/s]\n",
      "INFO:root:fold: VALID; iteration: 10; my_valid/acc: 1.0; objective: 2.2717578411102295; \n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from superduperdb.container.metric import Metric\n",
    "from superduperdb.container.dataset import Dataset\n",
    "from superduperdb.ext.torch.model import TorchTrainerConfiguration\n",
    "\n",
    "\n",
    "job = model.fit(\n",
    "    X='img',\n",
    "    y='class',\n",
    "    db=db,\n",
    "    select=collection.find(),\n",
    "    configuration=TorchTrainerConfiguration(\n",
    "        identifier='my_configuration',\n",
    "        objective=cross_entropy,\n",
    "        loader_kwargs={'batch_size': 10},\n",
    "        max_iterations=10,\n",
    "        validation_interval=5,\n",
    "    ),\n",
    "    metrics=[Metric(identifier='acc', object=lambda x, y: sum([xx == yy for xx, yy in zip(x, y)]) / len(x))],\n",
    "    validation_sets=[\n",
    "        Dataset(\n",
    "            identifier='my_valid',\n",
    "            select=Collection(name='mnist').find({'_fold': 'valid'}),\n",
    "        )\n",
    "    ],\n",
    "    distributed=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "200d3be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:to will be overriden with `to`\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = db.load('model', model.identifier)\n",
    "\n",
    "plt.plot(model.metric_values['my_valid/acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199b952",
   "metadata": {},
   "source": [
    "Now that the model has been trained, we can use it to \"listen\" the data for incoming changes. \n",
    "This is set up with a simple predict \"on\" the database (without loading all the data client-side).\n",
    "\n",
    "The `listen` toggle \"activates\" the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e53249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Adding model lenet5 to db\n",
      "WARNING:root:model/lenet5/0 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "WARNING:root:model/lenet5/0 already exists - doing nothing\n",
      "INFO:root:Adding model lenet5 to db\n",
      "WARNING:root:model/lenet5/0 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "100it [00:00, 15762.13it/s]\n",
      "100%|█████████████████████████████████████████████████| 100/100 [00:00<00:00, 217.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model.predict(X='img', db=db, select=collection.find(), listen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daae786",
   "metadata": {},
   "source": [
    "We can see that predictions are available in `_outputs.img.lenet5`. The `.unpack()` method strips the document down to just the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc71a143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'class': 2,\n",
       " '_fold': 'train',\n",
       " '_id': ObjectId('651da8bd49486fb8b96384bb'),\n",
       " '_outputs': {'img': {'lenet5': 2}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(collection.find_one()).unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580aba3",
   "metadata": {},
   "source": [
    "The models \"activated\" can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8912f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lenet5/img']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.show('listener')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78a2a1",
   "metadata": {},
   "source": [
    "We can verify that the model is activated, by inserting the rest of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1aa56d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:found 0 uris\n",
      "WARNING:root:to will be overriden with `to`\n",
      "INFO:root:Adding model lenet5 to db\n",
      "WARNING:root:model/lenet5/0 already exists - doing nothing\n",
      "INFO:root:Done.\n",
      "100%|███████████████████████████████████████████████| 1000/1000 [00:04<00:00, 203.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pymongo.results.InsertManyResult at 0x7fcc6736e8b0>,\n",
       " TaskWorkflow(database=<superduperdb.db.base.db.DB object at 0x7fcc66650a60>, G=<networkx.classes.digraph.DiGraph object at 0x7fcc67337430>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r in data[-1000:]:\n",
    "    r['update'] = True\n",
    "\n",
    "db.execute(collection.insert_many(data[-1000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb48a30",
   "metadata": {},
   "source": [
    "You can see that the inserted data, are now also populated with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8161983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': {'lenet5': 9}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(collection.find_one({'update': True}))['_outputs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

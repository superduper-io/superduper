{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6843aed6",
   "metadata": {},
   "source": [
    "# Turn your classical-database into a vector-database with SuperDuperDB\n",
    "\n",
    "In this notebook we show how you can use SuperDuperDB to turn your classical database into a vector-search database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2adf0f-330d-4af7-b782-3e8530a7cc7c",
   "metadata": {},
   "source": [
    "In this example, we'll be using the `sentence_transformers` with `superduperdb` python package.\n",
    "In addition, we'll be accessing the OpenAI API. In order to get these working you'll need to install the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install superduperdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04229106-d340-43ef-b4cf-0a2addcf17b1",
   "metadata": {},
   "source": [
    "And set the `OPEN_AI_KEY` as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f50639-1c70-4b2e-898b-c08a9cf99f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110906e",
   "metadata": {},
   "source": [
    "In order to access SuperDuperDB, we'll wrap our standard database connector with the `superduper` decorator.\n",
    "This will transform the functionality of your database into a **super-duper** database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7047d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb import superduper\n",
    "import pymongo\n",
    "\n",
    "db = pymongo.MongoClient().documents\n",
    "db = superduper(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028abdfb",
   "metadata": {},
   "source": [
    "In this notebook we upload some wikipedia documents from a wikipedia dump. You can find this raw data here https://dumps.wikimedia.org/enwiki/.\n",
    "\n",
    "We've preprocessed the data, extracting titles and abstracts from each document. We can use this as a test bed for search, by simulating a \"typed query\" using the title, and indexing the document based on the abstracts only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84948ce4-bd76-4cd8-96f9-27f03777aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random \n",
    "\n",
    "with open(f'{os.environ[\"HOME\"]}/data/wikipedia/abstracts.json') as f:\n",
    "    data = json.load(f)\n",
    "data = random.sample(data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb728b3-6656-40ee-8b81-5a7974beaae5",
   "metadata": {},
   "source": [
    "Here's a snapshot of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58927e41-9073-40c5-9f6e-3ee15cc84420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Tatyana Kasatkina',\n",
       "  'abstract': 'Tatyana Aleksandrovna Kasatkina (; born 1963 in Moscow, Soviet Union) is a Russian philosopher, philologist, culture expert, religious scholar and writer. She is an expert in the field of theory of culture, theory of literature, philosophy, religious studies, the works of Fyodor Dostoyevsky and Russian literature of the 19th-21st centuries.'},\n",
       " {'title': 'Choristoneura orae',\n",
       "  'abstract': 'Choristoneura orae, the spruce budworm, is a moth of the family Tortricidae. It is found in North America.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6486fd2-35d8-431d-90cc-76f665eb0526",
   "metadata": {},
   "source": [
    "We now insert the data into MongoDB using the SuperDuperDB client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621da76-42b6-4d6c-8fe4-f68b5d827bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.db.mongodb.query import Collection\n",
    "\n",
    "collection = Collection(name='wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.document import Document\n",
    "\n",
    "db.execute(collection.insert_many([Document(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e94c5-6156-49ea-85a3-288e961fa138",
   "metadata": {},
   "source": [
    "We can verify that the documents are in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = db.execute(collection.find_one())\n",
    "r.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1c34f",
   "metadata": {},
   "source": [
    "Creating a vector-index in SuperDuperDB involves two things:\n",
    "\n",
    "- Creating a model which is used to compute vectors (in this case `OpenAIEmbedding`)\n",
    "- Daemonizing this model on a key (`Listener`), so that when new data are added, these are vectorized using the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e64056-aefa-420a-ba81-69f715d18482",
   "metadata": {},
   "source": [
    "Sentence Transformers are supported by SuperDuperDB, with a wrapper that allows the chosen model to \n",
    "communicate directly with SuperDuperDB. The `encoder` argument specifies how the outputs of the models\n",
    "are saved in the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ed858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "from superduperdb.container.model import Model\n",
    "from superduperdb.ext.numpy.array import array\n",
    "\n",
    "model = Model(\n",
    "    identifier='all-MiniLM-L6-v2',\n",
    "    object=sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "    encoder=array('float32', shape=(384,)),\n",
    "    predict_method='encode',\n",
    "    batch_predict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87b136-fd58-43f7-94bc-816484953e9f",
   "metadata": {},
   "source": [
    "SuperDuperDB also has inbuilt support for OpenAI. You can also integrate APIs from clients, such as the CoherAI\n",
    "client using the Model wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6be7c-8621-4564-823d-6663c91481cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.ext.openai.model import OpenAIEmbedding\n",
    "\n",
    "model = OpenAIEmbedding(model='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a46a85-aa20-4bd7-b7df-9b5d8a45bdf0",
   "metadata": {},
   "source": [
    "We can test our model (whichever we've chosen) like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcf9d1-baf6-49d7-939d-2a9ba1f428fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict('This is a test', one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126da2fb-d9db-4c57-a12c-2328ba19fbbd",
   "metadata": {},
   "source": [
    "We've verified our model gives us vectorial outputs, now let's add the search functionality using this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e60606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.container.vector_index import VectorIndex\n",
    "from superduperdb.container.listener import Listener\n",
    "from superduperdb.ext.numpy.array import array\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier=f'wiki-index-{model.identifier}',\n",
    "        indexing_listener=Listener(\n",
    "            model=model,\n",
    "            key='abstract',\n",
    "            select=collection.find(),\n",
    "            predict_kwargs={'max_chunk_size': 1000},\n",
    "        ),\n",
    "        compatible_listener=Listener(\n",
    "            model=model,\n",
    "            key='title',\n",
    "            select=collection.find(),\n",
    "            active=False,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df9561-3fb3-488e-85c3-f10d49c54c57",
   "metadata": {},
   "source": [
    "We can inspect the functionality which was added like this. The above command creates several components in the single call:\n",
    "\n",
    "- *model*\n",
    "- *listener*\n",
    "- *vector_index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf29c9-92ab-44ed-a62c-65949f7d2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ba502-f7ed-4fc1-8423-3b2b0337a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('listener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da066cf-f0e7-4475-b692-31135e6820fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('vector_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf5c0f-a6c8-46d0-a76d-821cf4fbb6df",
   "metadata": {},
   "source": [
    "We can now test a few vector searches. The way to do this in combination with your classical database\n",
    "(in this case MongoDB) is to pre-pend the standard query, with a similarity comparison via `like`.\n",
    "\n",
    "The item inside `like` is vectorized and compared with the stored vectors. In order for this to work, the keys in the \n",
    "first parameter to `like` must match those configured in the `Listener` instances inside the `VectorIndex`. The results are then filtered\n",
    "using the classical query part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ed478",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.execute(\n",
    "    collection\n",
    "        .like({'title': 'articles about sport'}, n=10, vector_index=f'wiki-index-{model.identifier}')\n",
    "        .find({}, {'title': 1})\n",
    ")\n",
    "\n",
    "for r in cur:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff25aae-49ef-4946-8086-07a0b3531557",
   "metadata": {},
   "source": [
    "The benefit of having this combination is demonstrated in this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.execute(\n",
    "    collection\n",
    "        .like({'title': 'articles about sport'}, n=100, vector_index=f'wiki-index-{model.identifier}')\n",
    "        .find({'title': {'$regex': '.*Australia'}})\n",
    ")\n",
    "\n",
    "for r in cur:\n",
    "    print(r['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d9035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.mongodb.client import SuperDuperClient\n",
    "from IPython.display import display, Image as I\n",
    "\n",
    "c = SuperDuperClient()\n",
    "docs = c.yondo.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "I('../docs/img/architecture_detailed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9981c128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy\n",
    "import PIL.Image\n",
    "import PIL.JpegImagePlugin, PIL.PngImagePlugin\n",
    "import torch\n",
    "\n",
    "\n",
    "class PILImage:\n",
    "    types = (PIL.JpegImagePlugin.JpegImageFile, PIL.PngImagePlugin.PngImageFile)\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        buffer = io.BytesIO()\n",
    "        x.save(buffer, format='png')\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        return PIL.Image.open(io.BytesIO(bytes_))\n",
    "\n",
    "\n",
    "class FloatTensor:\n",
    "    types = (torch.FloatTensor, torch.Tensor)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        x = x.numpy()\n",
    "        assert x.dtype == numpy.float32\n",
    "        return memoryview(x).tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        array = numpy.frombuffer(bytes_, dtype=numpy.float32)\n",
    "        return torch.from_numpy(array).type(torch.float)\n",
    "    \n",
    "docs.create_type('float_tensor', FloatTensor, serializer='dill')\n",
    "docs.create_type('image', PILImage(), serializer='dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d6db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from clip import load, tokenize\n",
    "\n",
    "\n",
    "class Image(torch.nn.Module):\n",
    "    def __init__(self, model, preprocess):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode_image(x)\n",
    "\n",
    "\n",
    "class Text(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.encode_text(x)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return tokenize(x)[0]\n",
    "    \n",
    "\n",
    "\n",
    "class CLIP(torch.nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        model, preprocess = load(name)\n",
    "        self.image = Image(model, preprocess)\n",
    "        self.text = Text(model)\n",
    "\n",
    "    def preprocess(self, r):\n",
    "        out = {}\n",
    "        if \"brand\" in r or \"title\" in r:\n",
    "            out[\"text\"] = self.text.preprocess(f'{r.get(\"brand\", \"\")} {r.get(\"title\", \"\")}')\n",
    "        if \"img\" in r:\n",
    "            out[\"image\"] = self.image.preprocess(r['img'])\n",
    "        assert out\n",
    "        return out\n",
    "\n",
    "    def forward(self, r):\n",
    "        assert r\n",
    "        key = next(iter(r.keys()))\n",
    "        bs = r[key].shape[0]\n",
    "        out = torch.zeros(bs, 1024).to(r[key].device)\n",
    "        n = 0\n",
    "        if 'image' in r:\n",
    "            tmp = self.image.forward(r['image'])\n",
    "            tmp = tmp.div(tmp.pow(2).sum(axis=1).sqrt()[:, None])\n",
    "            out += tmp\n",
    "            n += 1\n",
    "        if 'text' in r:\n",
    "            tmp = self.text.forward(r['text'])\n",
    "            tmp = tmp.div(tmp.pow(2).sum(axis=1).sqrt()[:, None])\n",
    "            out += tmp\n",
    "            n += 1\n",
    "        return out / n\n",
    "\n",
    "    \n",
    "docs.create_model('clip', CLIP('RN50'), serializer='dill', type='float_tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x, y):\n",
    "    return x.matmul(y.T)\n",
    "\n",
    "\n",
    "def css(x, y):\n",
    "    x = x.div(x.norm(dim=1)[:, None])\n",
    "    y = y.div(y.norm(dim=1)[:, None])\n",
    "    return dot(x, y)\n",
    "\n",
    "docs.create_measure('css', css, serializer='dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102fabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsetting output field _outputs._base.clip\n"
     ]
    }
   ],
   "source": [
    "docs.delete_semantic_index('clip', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98a177a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job_ids = docs.create_semantic_index(\n",
    "    'clip', ['clip'], ['_base'], 'css', loader_kwargs={'batch_size': 10, 'num_workers': 0},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c95a92a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'identifier': 'fe52a521-ae91-4148-8e67-c8d15a34ab6b',\n",
       "  'time': datetime.datetime(2023, 4, 14, 15, 30, 0, 246000),\n",
       "  'status': 'failed',\n",
       "  'method': '_process_documents_with_watcher'},\n",
       " {'identifier': '5c2afda4-421b-46e4-ae8c-7422f19709f7',\n",
       "  'time': datetime.datetime(2023, 4, 14, 21, 25, 13, 123000),\n",
       "  'status': 'running',\n",
       "  'method': '_process_documents_with_watcher'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d466bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing chunk (1/7)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with clip\n",
      " 47%|####6     | 233/500 [05:54<06:45,  1.52s/it]"
     ]
    }
   ],
   "source": [
    "docs.watch_job(job_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09387a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.cancel_job('fe52a521-ae91-4148-8e67-c8d15a34ab6b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea63e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = docs.find_one()\n",
    "\n",
    "print('anchor image:')\n",
    "display(r['img'])\n",
    "\n",
    "for r in docs.find(like={'_id': r['_id']}, semantic_index='clip'):\n",
    "    print(r['_score'])\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3e5f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in docs.find(like={'title': 'leopard print t-shirt'}, semantic_index='clip'):\n",
    "    print(r['_score'])\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddee6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as I\n",
    "\n",
    "url = 'https://thumblr.uniid.it/product/238107/09ef5396fac2.jpg'\n",
    "docs.remote = True\n",
    "\n",
    "display(I(url=url, width=200))\n",
    "\n",
    "cur = docs.find(like={'img': {'_content': {'url': url, 'type': 'image'}}}, semantic_index='clip', download=True)\n",
    "for r in cur:\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd859dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from clip import load, tokenize\n",
    "\n",
    "\n",
    "class ClassifierSimple(torch.nn.Module):\n",
    "    def __init__(self, categories, name):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        model, _ = load(name)\n",
    "        category_vectors = \\\n",
    "            model.encode_text(torch.cat([tokenize(x) for x in categories], 0))\n",
    "        category_vectors = category_vectors / category_vectors.norm(dim=1, keepdim=True)\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        self.register_buffer('category_vectors', category_vectors)\n",
    "        self.register_buffer('logit_scale', logit_scale)\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.category_vectors.device\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            x = x['_outputs']['_base']['clip']\n",
    "        else:\n",
    "            assert isinstance(x, torch.Tensor)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / x.norm(dim=1, keepdim=True)\n",
    "        logits_per_image = self.logit_scale * x @ self.category_vectors.t()\n",
    "        out = logits_per_image.softmax(dim=-1)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        pos = x.topk(1)[1].item()\n",
    "        return self.categories[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'silhouettes', \n",
    "    ClassifierSimple(\n",
    "        name='RN50',\n",
    "        categories=[\n",
    "            'accessory',\n",
    "            'blouse',\n",
    "            'coat',\n",
    "            'dress',\n",
    "            'hat',\n",
    "            'hoodie',\n",
    "            'jacket',\n",
    "            'pullover',\n",
    "            'shoes',\n",
    "            'skirt',\n",
    "            't-shirt',\n",
    "            'trousers',\n",
    "        ]\n",
    "    ),\n",
    "    serializer='dill',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5821ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = docs.find_one()\n",
    "print(r['title'])\n",
    "display(r['img'])\n",
    "docs.apply_model('silhouettes', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898efe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_watchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170deb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_watcher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = docs.create_watcher(\n",
    "    'silhouettes',\n",
    "    features={'_base': 'clip'},\n",
    "    loader_kwargs={'batch_size': 10, 'num_workers': 0},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb998b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e434830",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(docs.find().limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = list(docs.find({}, {'_id': 0, '_outputs': 0, '_fold': 0, 'img._content.bytes': 0}, raw=True).limit(50))\n",
    "for r in update:\n",
    "    r['update'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d57a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, job_ids = docs.insert_many(update)\n",
    "job_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c59e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(job_ids['_download_content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(job_ids['watcher', 'clip/_base'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(job_ids['watcher', 'silhouettes/_base'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one({'update': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.delete_many({'update': True})\n",
    "\n",
    "docs.delete_measure('css', force=True)\n",
    "docs.delete_semantic_index('clip', force=True)\n",
    "\n",
    "docs.delete_watcher('silhouettes/_base', force=True)\n",
    "docs.delete_watcher('clip/_base', force=True)\n",
    "\n",
    "docs.delete_model('silhouettes', force=True)\n",
    "docs.delete_model('clip', force=True)\n",
    "\n",
    "docs.delete_type('float_tensor', force=True)\n",
    "docs.delete_type('image', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bson\n",
    "\n",
    "h = list(docs.find({}, {'_outputs._base.clip': 1}, raw=True))\n",
    "h = {f'{i}': hh for i, hh in enumerate(h)}\n",
    "\n",
    "with open('clip_bak.bson', 'wb') as f:\n",
    "    f.write(bson.BSON.encode(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bson\n",
    "with open('clip_bak.bson', 'rb') as f:\n",
    "    h = bson.BSON.decode(f.read())\n",
    "    \n",
    "h = [h[f'{i}'] for i in range(len(h))]\n",
    "\n",
    "docs.bulk_write([\n",
    "    UpdateOne({'_id': h[i]['_id']}, {'$set': {f'_outputs._base.clip': h[i]}})\n",
    "    for i in range(len(h))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.bulk_write([\n",
    "    UpdateOne({'_id': h[i]['_id']}, {'$set': {f'_outputs._base.clip': h[i]}})\n",
    "    for i in range(len(h))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

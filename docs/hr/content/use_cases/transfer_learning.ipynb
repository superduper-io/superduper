{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.7"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "c288025e-2326-4e8b-ab52-6fb8a5f9560f", "metadata": {}, "source": ["<!-- TABS -->\n", "# Transfer learning"]}, {"cell_type": "markdown", "id": "f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6", "metadata": {}, "source": ["<!-- TABS -->\n", "## Configure your production system"]}, {"cell_type": "markdown", "id": "81e7cd59-67d0-4776-aea1-4864aa768f95", "metadata": {}, "source": [":::note\n", "If you would like to use the production features \n", "of SuperDuperDB, then you should set the relevant \n", "connections and configurations in a configuration \n", "file. Otherwise you are welcome to use \"development\" mode \n", "to get going with SuperDuperDB quickly.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "62014646-ccd4-4d10-ac26-1c470f88f2f2", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.mkdirs('.superduperdb', exist_ok=True)\n", "os.environ['SUPERDUPERDB_CONFIG_FILE'] = '.superduperdb/config.yaml'"]}, {"cell_type": "code", "execution_count": null, "id": "8e50edd2-438d-44ab-9da0-0b72197df262", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Community>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: lance\n", "databackend: mongodb://<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1ad9ee67-6402-45ea-8311-3efb039b5df3", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Atlas>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: native\n", "databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9c9e8351-b17f-4882-bda6-5ad51dbc7e1f", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: sqlite://<path-to-db>.db\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mysql://<user>:<password>@<host>:<port>/database\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9b7ac715-712c-4ec7-be90-0aaa22518977", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mssql://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "f21fad9c-cc0e-4cf5-83f0-41a3a614c6af", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: postgres://<user>:<password>@<host>:<port</<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1badb5a3-823c-4463-ab79-6f4f9239dabe", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: snowflake://<user>:<password>@<account>/<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "ae7807d9-9fc1-4c18-8027-a512f827783d", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: clickhouse://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "fc40c13b-9bc5-47ac-86d6-ef7a379c45ee", "metadata": {}, "outputs": [], "source": ["with open(os.environ['SUPERDUPERDB_CONFIG_FILE'], 'w') as f:\n", "    f.write(CFG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Start your cluster"]}, {"cell_type": "markdown", "metadata": {}, "source": [":::note\n", "Starting a SuperDuperDB cluster is useful in production and model development\n", "if you want to enable scalable compute, access to the models by multiple users for collaboration, \n", "monitoring.\n", "\n", "If you don't need this, then it is simpler to start in development mode.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Experimental Cluster>\n", "!python -m superduperdb local_cluster"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Docker-Compose>\n", "!make testenv_image\n", "!make testenv_init"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from superduperdb import superduper\n", "\n", "db = superduper()"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from superduperdb import superduper\n", "\n", "db = superduper('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from superduperdb import superduper\n", "\n", "user = 'superduper'\n", "password = 'superduper'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from superduperdb import superduper\n", "\n", "user = 'sa'\n", "password = 'Superduper#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = superduper(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "from superduperdb import superduper\n", "\n", "user = 'superduper'\n", "password = 'superduper'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = superduper(f\"postgres://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from superduperdb import superduper\n", "\n", "user = \"superduperuser\"\n", "password = \"superduperpassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = superduper(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from superduperdb import superduper\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from superduperdb import superduper\n", "\n", "db = superduper(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "4e7902bd", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/text.json\n", "import json\n", "\n", "with open('text.json', 'r') as f:\n", "    data = json.load(f)"]}, {"cell_type": "code", "execution_count": null, "id": "0828031a", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "!curl -O s3://superduperdb-public-demo/images.zip && unzip images.zip\n", "import os\n", "\n", "data = [f'images/{x}' for x in os.listdir('./images')]"]}, {"cell_type": "code", "execution_count": null, "id": "8abcadac", "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "!curl -O s3://superduperdb-public-demo/audio.zip && unzip audio.zip\n", "import os\n", "\n", "data = [f'audios/{x}' for x in os.listdir('./audios')]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Setup tables or collections"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "# Note this is an optional step for MongoDB\n", "# Users can also work directly with `DataType` if they want to add\n", "# custom data\n", "from superduperdb import Schema, DataType\n", "from superduperdb.backends.mongodb import Collection\n", "\n", "table_or_collection = Collection('documents')\n", "USE_SCHEMA = False\n", "\n", "if USE_SCHEMA and isinstance(datatype, DataType):\n", "    schema = Schema(fields={'x': datatype})\n", "    db.apply(schema)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from superduperdb.backends.ibis import Table\n", "from superduperdb.backends.ibis.field_types import FieldType\n", "\n", "if isinstance(datatype, DataType):\n", "    schema = Schema(fields={'x': datatype})\n", "else:\n", "    schema = Schema(fields={'x': FieldType(datatype)})\n", "\n", "table_or_collection = Table('documents', schema=schema)\n", "\n", "db.apply(table_or_collection)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert data\n", "\n", "In order to create data, we need to create a `Schema` for encoding our special `Datatype` column(s) in the databackend."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import Document\n", "\n", "def do_insert(data):\n", "    schema = None\n", "    \n", "    if schema is None and datatype is None:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data[:N_DATA]))\n", "    elif schema is None and datatype is not None:\n", "        data = [Document({'x': datatype(x)}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data[:N_DATA]))\n", "    else:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data[:N_DATA], schema='my_schema'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from superduperdb import Document\n", "\n", "def do_insert(data):\n", "    db.execute(table_or_collection.insert([Document({'x': x}) for x in data))"]}, {"cell_type": "code", "execution_count": null, "id": "b5ba80bb-73c3-4894-b193-7ef05b22d3fb", "metadata": {}, "outputs": [], "source": ["do_insert(data[:-len(data) // 4])"]}, {"cell_type": "markdown", "id": "c2da0ab6-8fc0-41fc-b8c9-0f8a127d9e8d", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build and train classifier"]}, {"cell_type": "code", "execution_count": null, "id": "d3b94fca-3a0b-433f-88cf-aab5b71b8596", "metadata": {}, "outputs": [], "source": ["# <tab: Scikit-Learn>\n", "from sklearn.linear_model import LogisticRegression\n", "from superduperdb.ext.sklearn.model import SklearnTrainer, Estimator\n", "\n", "# Create a Logistic Regression model\n", "model = LogisticRegression()\n", "model = Estimator(\n", "    object=model,\n", "    identifier='my-model',\n", "    train_X=('X', 'y'),\n", "    train_select=Collection('clt').find(),\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "5256e0fb-db16-411e-a1c1-8d44feb26c29", "metadata": {}, "outputs": [], "source": ["# <tab: Torch>\n", "from torch import nn\n", "from superduperdb.ext.torch.model import TorchModel\n", "from superduperdb.ext.torch.training import TorchTrainer\n", "\n", "\n", "class SimpleModel(nn.Module):\n", "    def __init__(self, input_size=16, hidden_size=32, num_classes=3):\n", "        super(SimpleModel, self).__init__()\n", "        self.fc1 = nn.Linear(input_size, hidden_size)\n", "        self.relu = nn.ReLU()\n", "        self.fc2 = nn.Linear(hidden_size, num_classes)\n", "\n", "    def forward(self, x):\n", "        out = self.fc1(x)\n", "        out = self.relu(out)\n", "        out = self.fc2(out)\n", "        return out\n", "\n", "# Loss function\n", "def my_loss(X, y):\n", "    return torch.nn.functional.binary_cross_entropy_with_logits(\n", "        X[:, 0], y.type(torch.float)\n", "    )\n", "\n", "\n", "# Create a Logistic Regression model\n", "model = SimpleModel()\n", "model = TorchModel(\n", "    identifier='my-model',\n", "    object=model,         \n", "    trainer=TorchTrainer(\n", "        identifier='my_trainer',\n", "        objective=my_loss,\n", "        loader_kwargs={'batch_size': 10},\n", "        max_iterations=100,\n", "        validation_interval=10,\n", "    ),\n", "    train_X=('X', 'y'),\n", "    train_select=Collection('clt').find(),\n", ")"]}, {"cell_type": "markdown", "id": "ac6fbe06-37d8-451c-a7ed-6ab217f73b7e", "metadata": {}, "source": ["The following command adds the model to the system and trains the model in one command."]}, {"cell_type": "code", "execution_count": null, "id": "decad591-5934-45b6-a332-a47fc61a0aa8", "metadata": {}, "outputs": [], "source": ["db.apply(model)"]}]}
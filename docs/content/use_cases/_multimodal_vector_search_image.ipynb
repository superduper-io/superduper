{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Multimodal vector search - Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db0ce690-8ff7-4988-a377-6b0d8a1fa9f8",
   "metadata": {},
   "source": [
    "<snippet: connect_to_superduperdb: *>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a84db8b-e9ec-4356-b045-b718de8ccb6c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<snippet: get_useful_sample_data: Image>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a702b1-faf9-4edb-8a55-efc4add84a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [{'img': d} for d in data[:100]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa0c03b6-891a-4f54-9954-7a2282150b17",
   "metadata": {},
   "source": [
    "<snippet: insert_simple_data: *>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1725b87-e687-46cc-a169-7cbe0baabe3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<snippet: build_multimodal_embedding_models: Text-Image>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0119da-9cfd-4a60-8847-c3bfdf37697f",
   "metadata": {},
   "source": [
    "Because we use multimodal models, we define different keys to specify which model to use for embedding calculations in the vector_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e75fab-8504-4d17-a7d9-f98667a5d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_key = 'img' # we use img key for img embedding\n",
    "compatible_key = 'text' # we use text key for text embedding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7eaca47f-32ab-4776-abc0-f6fa2eeb9043",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<snippet: create_vector_index: 2-Modalities>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a87f9d-581a-419a-81b8-a743250413e9",
   "metadata": {},
   "source": [
    "## Perform a vector search\n",
    "\n",
    "We can perform the vector searches using two types of data:\n",
    "\n",
    "- Text: By text description, we can find images similar to the text description.\n",
    "- Image: By using an image, we can find images similar to the provided image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce565823-4655-488c-8684-2240107fa30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "item = Document({compatible_key: \"Find a black dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8059626-dff8-4fe0-b872-97b8eb8b1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Image>\n",
    "from IPython.display import display\n",
    "search_image = data[0]\n",
    "display(search_image)\n",
    "item = Document({indexing_key: search_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ba07d-1124-4d94-a117-60d2e72581f7",
   "metadata": {},
   "source": [
    "Once we have this search target, we can execute a search as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061de0b-2694-4b36-844c-7753a465360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = query_table_or_collection.like(item, vector_index=vector_index_name, n=5).select()\n",
    "results = list(db.execute(select))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d9af9-a012-42bd-aad4-31b92d089caa",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ecea5-3a58-457c-ac50-ddc742484f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "for result in results:\n",
    "    display(result[indexing_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b4878-39a2-444d-8e17-72a00e6c246d",
   "metadata": {},
   "source": [
    "## Check the system stays updated\n",
    "\n",
    "You can add new data; once the data is added, all related models will perform calculations according to the underlying constructed model and listener, simultaneously updating the vector index to ensure that each query uses the latest data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef97f5a-bb41-46ca-a85e-489824741216",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datas = [{'img': d} for d in data[100:200]]\n",
    "ids = db.execute(table_or_collection.insert(new_datas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

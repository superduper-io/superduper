{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44798f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bf038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat configs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34229af6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apis': {'providers': {},\n",
      "          'retry': {'stop_after_attempt': 2,\n",
      "                    'wait_max': 10.0,\n",
      "                    'wait_min': 4.0,\n",
      "                    'wait_multiplier': 1.0}},\n",
      " 'cdc': False,\n",
      " 'dask': {'deserializers': [],\n",
      "          'ip': 'localhost',\n",
      "          'local': True,\n",
      "          'password': '',\n",
      "          'port': 8786,\n",
      "          'serializers': [],\n",
      "          'username': ''},\n",
      " 'data_layers': {'artifact': {'cls': 'mongodb',\n",
      "                              'connection': 'pymongo',\n",
      "                              'kwargs': {'host': 'localhost',\n",
      "                                         'password': 'testmongodbpassword',\n",
      "                                         'port': 27018,\n",
      "                                         'username': 'testmongodbuser'},\n",
      "                              'name': '_filesystem:test_db'},\n",
      "                 'data_backend': {'cls': 'mongodb',\n",
      "                                  'connection': 'pymongo',\n",
      "                                  'kwargs': {'host': 'localhost',\n",
      "                                             'password': 'testmongodbpassword',\n",
      "                                             'port': 27018,\n",
      "                                             'username': 'testmongodbuser'},\n",
      "                                  'name': 'test_db'},\n",
      "                 'metadata': {'cls': 'mongodb',\n",
      "                              'connection': 'pymongo',\n",
      "                              'kwargs': {'host': 'localhost',\n",
      "                                         'password': 'testmongodbpassword',\n",
      "                                         'port': 27018,\n",
      "                                         'username': 'testmongodbuser'},\n",
      "                              'name': 'test_db'}},\n",
      " 'distributed': True,\n",
      " 'logging': {'kwargs': {},\n",
      "             'level': <LogLevel.INFO: 'INFO'>,\n",
      "             'type': <LogType.STDERR: 'STDERR'>},\n",
      " 'model_server': {'host': '127.0.0.1',\n",
      "                  'password': '',\n",
      "                  'port': 5001,\n",
      "                  'username': ''},\n",
      " 'notebook': {'ip': '0.0.0.0', 'password': '', 'port': 8888, 'token': ''},\n",
      " 'ray': {'deployments': [],\n",
      "         'host': '127.0.0.1',\n",
      "         'password': '',\n",
      "         'port': 0,\n",
      "         'username': ''},\n",
      " 'server': {'host': '127.0.0.1', 'port': 3223, 'protocol': 'http'},\n",
      " 'vector_search': {'host': 'localhost',\n",
      "                   'password': '',\n",
      "                   'port': 19530,\n",
      "                   'type': {'backfill_batch_size': 100, 'inmemory': True},\n",
      "                   'username': ''}}\n"
     ]
    }
   ],
   "source": [
    "from superduperdb import CFG\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(CFG.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d334809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "INFO:distributed.scheduler:State start\n",
      "INFO:distributed.diskutils:Found stale lock file and directory '/var/folders/y9/b74b9yj906s_wtj0rrh2lf7c0000gn/T/dask-scratch-space/scheduler-5pai380q', purging\n",
      "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:63625\n",
      "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:63628'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:63629'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:63630'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:63631'\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:63636', name: 0, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:63636\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:63638\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:63640', name: 2, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:63640\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:63644\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:63639', name: 1, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:63639\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:63642\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:63645', name: 3, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:63645\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:63647\n",
      "INFO:distributed.scheduler:Receive client connection: Client-888ce17a-2bf5-11ee-80fd-1e00f226d550\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:63648\n"
     ]
    }
   ],
   "source": [
    "from superduperdb.datalayer.base.build import build_datalayer\n",
    "\n",
    "db = build_datalayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3ae27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.db.client.drop_database('testdb')\n",
    "db.db.client.drop_database('_filesystem:testdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a538ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not get an identifier from submitted function, creating one!\n",
      "INFO:root:found 0 uris\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import torch\n",
    "\n",
    "from superduperdb import superduper\n",
    "from superduperdb.core.document import Document as D\n",
    "from superduperdb.encoders.torch.tensor import tensor\n",
    "from superduperdb.datalayer.mongodb.query import Collection\n",
    "\n",
    "m = superduper(\n",
    "    torch.nn.Linear(128, 7),\n",
    "    encoder=tensor(torch.float, shape=(7,))\n",
    ")\n",
    "\n",
    "t32 = tensor(torch.float, shape=(128,))\n",
    "\n",
    "output = db.execute(\n",
    "    Collection('localcluster').insert_many(\n",
    "        [D({'x': t32(torch.randn(128))}) for _ in range(1000)], \n",
    "        encoders=(t32,)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a653d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:model/linear/3 already exists - doing nothing\n",
      "WARNING:root:model/linear/3 already exists - doing nothing\n"
     ]
    }
   ],
   "source": [
    "job = m.predict(\n",
    "    X='x',\n",
    "    db=db,\n",
    "    select=Collection('localcluster').find(),\n",
    "    distributed=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6af0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.metadata.watch_job(j.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4680c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dodo/SuperDuperDB/superduperdb/superduperdb/encoders/torch/tensor.py:25: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  return torch.from_numpy(array)\n",
      "\r",
      "  0%|          | 0/7000 [00:00<?, ?it/s]\r",
      " 34%|###3      | 2349/7000 [00:00<00:00, 23485.04it/s]\r",
      " 67%|######7   | 4698/7000 [00:00<00:00, 23183.09it/s]\r",
      "100%|##########| 7000/7000 [00:00<00:00, 22774.44it/s]\n"
     ]
    }
   ],
   "source": [
    "job.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d111789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/SuperDuperDB/superduperdb/superduperdb/encoders/torch/tensor.py:25: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  return torch.from_numpy(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document({'_id': ObjectId('64c177575cce49a2cef30816'), 'x': Encodable(x=tensor([-0.6558,  1.3469, -0.1023, -0.6400, -1.1020, -0.2042,  0.4275, -1.6092,\n",
       "        -1.1424, -1.5908,  0.8309, -0.6172, -0.2117,  0.1292, -0.8760,  0.2354,\n",
       "         0.3222,  0.9577, -0.8312, -1.3584,  0.8627, -0.0859,  0.6106,  0.3820,\n",
       "         0.4593, -0.1626, -0.8851, -0.5929, -0.5583,  1.7698, -1.0682, -0.3768,\n",
       "         0.3096, -1.2281, -0.9119, -2.2015,  0.3347, -0.1978, -0.2175, -2.5556,\n",
       "         1.0651, -0.4832,  1.7287,  1.3304, -0.9887,  2.1100,  1.1202,  1.8639,\n",
       "        -0.3058,  0.3077,  0.4013, -0.4476, -1.8056, -1.2059, -0.6340, -0.9280,\n",
       "        -0.6431,  0.2956,  0.4677, -0.8410, -0.4470, -0.0849, -0.1979, -0.2644,\n",
       "         0.2893, -1.1252, -1.2417,  0.4027,  0.6283, -0.5515,  1.2066,  0.1537,\n",
       "         1.4630, -0.0776, -0.9622,  0.5075,  0.6045, -0.7392, -0.3099,  0.2250,\n",
       "        -0.8468,  1.9685, -1.2142, -0.3170,  1.9368, -0.9898,  0.8335, -0.5729,\n",
       "        -1.9115, -0.2388,  0.1474, -0.2815, -0.0776, -0.0228, -0.8766, -0.6325,\n",
       "        -2.8039, -0.6978, -0.3069, -0.1114, -0.7849, -0.3208,  1.4163, -1.6389,\n",
       "         1.4503,  0.4003, -1.0956, -2.3235,  1.5676, -2.2221,  0.5445,  0.3613,\n",
       "         2.7211, -0.1602, -0.2324, -1.9736,  0.4314, -0.5663,  0.3337, -0.6462,\n",
       "        -1.0694, -2.1725,  0.9928,  0.0165,  0.2859, -1.1345,  0.8620,  0.4220]), encoder=Encoder(identifier='torch.float32[128]', decoder=<Artifact artifact=<superduperdb.encoders.torch.tensor.DecodeTensor object at 0x17ed3c750> serializer=dill>, encoder=<Artifact artifact=<superduperdb.encoders.torch.tensor.EncodeTensor object at 0x17edc8c90> serializer=dill>, shape=[128], version=6)), '_fold': 'train', '_outputs': {'x': {'linear': Encodable(x=tensor([ 0.3160, -0.0021, -0.8208,  0.0262,  1.5559,  0.0448, -0.4712]), encoder=Encoder(identifier='torch.float32[7]', decoder=<Artifact artifact=<superduperdb.encoders.torch.tensor.DecodeTensor object at 0x17edfccd0> serializer=dill>, encoder=<Artifact artifact=<superduperdb.encoders.torch.tensor.EncodeTensor object at 0x17ecbb310> serializer=dill>, shape=[7], version=3))}}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(Collection('localcluster').find_one())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

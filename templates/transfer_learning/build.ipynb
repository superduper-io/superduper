{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c288025e-2326-4e8b-ab52-6fb8a5f9560f",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to superduper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Aug-30 21:34:07.16\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.misc.plugins\u001b[0m:\u001b[36m13  \u001b[0m | \u001b[1mLoading plugin: mongodb\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:07.29\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m103 \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:07.29\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.build\u001b[0m:\u001b[36m171 \u001b[0m | \u001b[1mConfiguration: \n",
      " +---------------+----------------------+\n",
      "| Configuration |        Value         |\n",
      "+---------------+----------------------+\n",
      "|  Data Backend | mongomock:///test_db |\n",
      "+---------------+----------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import superduper\n",
    "\n",
    "db = superduper('mongomock:///test_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2e7b-3f54-4263-b778-0fef60596efb",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Get useful sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547751e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1298k  100 1298k    0     0  1127k      0  0:00:01  0:00:01 --:--:-- 1130k\n"
     ]
    }
   ],
   "source": [
    "# <tab: Text-Classification>\n",
    "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/text_classification.json\n",
    "import json\n",
    "\n",
    "with open(\"text_classification.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Image-Classification>\n",
    "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/images_classification.zip && unzip images_classification.zip\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "with open('images/images.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "data = [{'x': Image.open(d['image_path']), 'y': d['label']} for d in data]\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb0bc4-826f-43fe-bd34-869bf69f2db0",
   "metadata": {},
   "source": [
    "After obtaining the data, we insert it into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7598ec1a-4f23-46f0-ae9f-617bce855e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text-Classification>\n",
    "datas = [{'txt': d['x'], 'label': d['y']} for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e856c2-7407-431f-a7de-3a6d51d17be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Image-Classification>\n",
    "datas = [{'image': d['x'], 'label': d['y']} for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ebee5",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Insert simple data\n",
    "\n",
    "After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d0f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Aug-30 21:34:13.87\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m363 \u001b[0m | \u001b[1mTable docs does not exist, auto creating...\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:13.87\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m369 \u001b[0m | \u001b[1mCreating table docs with schema {('label', 'int'), ('_fold', 'str'), ('txt', 'str')}\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:13.88\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.document\u001b[0m:\u001b[36m415 \u001b[0m | \u001b[33m\u001b[1mLeaf str already exists\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:13.98\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m344 \u001b[0m | \u001b[1mInserted 1000 documents into docs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from superduper import Document\n",
    "\n",
    "table_or_collection = db['docs']\n",
    "\n",
    "ids = db.execute(table_or_collection.insert([Document(data) for data in datas]))\n",
    "select = table_or_collection.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e703b58-a46d-4b1f-98fd-f50d46b168fe",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2e1588-fec8-45a6-b678-fef05fc7b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.11.7/envs/superduper-3.11/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/dodo/.pyenv/versions/3.11.7/envs/superduper-3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Aug-30 21:34:23.96\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m94  \u001b[0m | \u001b[1mRequesting listener setup on CDC service\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:23.96\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.listener\u001b[0m:\u001b[36m104 \u001b[0m | \u001b[1mSkipping listener setup on CDC service since no URI is set\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:23.96\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.jobs.queue\u001b[0m:\u001b[36m210 \u001b[0m | \u001b[1mRunning jobs for listener::features\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:23.96\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.backends.local.compute\u001b[0m:\u001b[36m67  \u001b[0m | \u001b[1mSubmitting job. function:<function method_job at 0x1121a74c0>\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:23.99\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.model\u001b[0m:\u001b[36m720 \u001b[0m | \u001b[1mRequesting prediction in db - [embedding] with predict_id features\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.11.7/envs/superduper-3.11/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Aug-30 21:34:28.66\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.components.model\u001b[0m:\u001b[36m853 \u001b[0m | \u001b[1mAdding 1000 model outputs to `db`\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:29.94\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.base.datalayer\u001b[0m:\u001b[36m344 \u001b[0m | \u001b[1mInserted 1000 documents into _outputs__features\u001b[0m\n",
      "\u001b[32m2024-Aug-30 21:34:29.94\u001b[0m| \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.backends.local.compute\u001b[0m:\u001b[36m73  \u001b[0m | \u001b[32m\u001b[1mJob submitted on <superduper.backends.local.compute.LocalComputeBackend object at 0x2a63a6950>.  function:<function method_job at 0x1121a74c0> future:2638f7c5-655d-47e6-ba13-a214afd3dd3c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# <tab: Text>\n",
    "key = 'txt'\n",
    "import sentence_transformers\n",
    "from superduper import vector, Listener\n",
    "from superduper_sentence_transformers import SentenceTransformer\n",
    "\n",
    "superdupermodel = SentenceTransformer(\n",
    "    identifier=\"embedding\",\n",
    "    object=sentence_transformers.SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    postprocess=lambda x: x.tolist(),\n",
    ")\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=superdupermodel,\n",
    "        select=select,\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de589c-4d75-4483-b2ca-77d5c25c2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Image>\n",
    "key = 'image'\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from superduper_torch import TorchModel\n",
    "from superduper import Listener\n",
    "from PIL import Image\n",
    "\n",
    "class TorchVisionEmbedding:\n",
    "    def __init__(self):\n",
    "        # Load the pre-trained ResNet-18 model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        self.resnet.eval()\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        # Preprocess the image\n",
    "        preprocess = preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        tensor_image = preprocess(image)\n",
    "        return tensor_image\n",
    "        \n",
    "model = TorchVisionEmbedding()\n",
    "superdupermodel = TorchModel(identifier='my-vision-model-torch', object=model.resnet, preprocess=model.preprocess, postprocess=lambda x: x.numpy().tolist())\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=superdupermodel,\n",
    "        select=select,\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9329cd-1ef3-4997-ba2f-9353091907a8",
   "metadata": {},
   "source": [
    "## Choose features key from feature listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9651e3a6-89f3-41db-80e6-afc294f4daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_key = listener.outputs\n",
    "training_select = select.outputs(listener.predict_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ddf88-468b-4ca5-b78b-37f8c3231ef7",
   "metadata": {},
   "source": [
    "We can find the calculated feature data from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1b85e7-a562-4efe-8af1-16889bd35bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = list(training_select.limit(1).execute())[0][input_key]\n",
    "feature_size = len(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da0ab6-8fc0-41fc-b8c9-0f8a127d9e8d",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b94fca-3a0b-433f-88cf-aab5b71b8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Scikit-Learn>\n",
    "from superduper_sklearn import Estimator, SklearnTrainer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = Estimator(\n",
    "    identifier=\"my-model\",\n",
    "    object=SVC(),\n",
    "    trainer=SklearnTrainer(\n",
    "        \"my-trainer\",\n",
    "        key=(input_key, \"label\"),\n",
    "        select=training_select,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256e0fb-db16-411e-a1c1-8d44feb26c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Torch>\n",
    "import torch\n",
    "from torch import nn\n",
    "from superduper_torch.model import TorchModel\n",
    "from superduper_torch.training import TorchTrainer\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=32, num_classes=3):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "preprocess = lambda x: torch.tensor(x)\n",
    "\n",
    "# Postprocess function for the model output    \n",
    "def postprocess(x):\n",
    "    return int(x.topk(1)[1].item())\n",
    "\n",
    "def data_transform(features, label):\n",
    "    return torch.tensor(features), label\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "# feature_length is the input feature size\n",
    "model = SimpleModel(feature_size, num_classes=num_classes)\n",
    "model = TorchModel(\n",
    "    identifier='my-model',\n",
    "    object=model,         \n",
    "    preprocess=preprocess,\n",
    "    postprocess=postprocess,\n",
    "    trainer=TorchTrainer(\n",
    "        key=(input_key, 'label'),\n",
    "        identifier='my_trainer',\n",
    "        objective=cross_entropy,\n",
    "        loader_kwargs={'batch_size': 10},\n",
    "        max_iterations=1000,\n",
    "        validation_interval=100,\n",
    "        select=select,\n",
    "        transform=data_transform,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af37887-59bc-4e13-b3b1-fee7d6108473",
   "metadata": {},
   "source": [
    "Define a validation for evaluating the effect after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94fb7506-2abc-41fe-b259-8c4922d79516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Dataset, Metric, Validation\n",
    "\n",
    "\n",
    "def acc(x, y):\n",
    "    return sum([xx == yy for xx, yy in zip(x, y)]) / len(x)\n",
    "\n",
    "\n",
    "accuracy = Metric(identifier=\"acc\", object=acc)\n",
    "validation = Validation(\n",
    "    \"transfer_learning_performance\",\n",
    "    key=(input_key, \"label\"),\n",
    "    datasets=[\n",
    "        Dataset(identifier=\"my-valid\", select=training_select.add_fold('valid'))\n",
    "    ],\n",
    "    metrics=[accuracy],\n",
    ")\n",
    "model.validation = validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513478b1-2736-4fa5-bc2a-6fdb9c8e232d",
   "metadata": {},
   "source": [
    "If we execute the apply function, then the model will be added to the database, and because the model has a Trainer, it will perform training tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a39054-aef2-480a-a57e-7180914e6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-Aug-30 21:34:35.43\u001b[0m| \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36msuperduper.backends.local.artifacts\u001b[0m:\u001b[36m85  \u001b[0m | \u001b[33m\u001b[1mFile /tmp/test_db/11f4c3e68e30071c92163ece040096ea80e23755 already exists\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " Estimator(trainer=SklearnTrainer(identifier='my-trainer', uuid='4ed22cfa3a9c4175ae89b7511eda1afb', upstream=None, plugins=None, cache=False, key=('_outputs__features', 'label'), select=docs.select().outputs(\"features\"), transform=None, metric_values={}, signature='*args', data_prefetch=False, prefetch_size=1000, prefetch_factor=100, in_memory=True, compute_kwargs={}, fit_params={}, predict_params={}, y_preprocess=None), identifier='my-model', uuid='1e6b4f4000ac4cb8b5123e2cc944a071', upstream=None, plugins=None, cache=False, signature='singleton', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=Validation(identifier='transfer_learning_performance', uuid='b01186bf87cb49b0a6dcf86f53a660c5', upstream=None, plugins=None, cache=False, metrics=[Metric(identifier='acc', uuid='e83f664b7f6947cfb67947e472b7d467', upstream=None, plugins=None, cache=False, object=<function acc at 0x2d41cae80>)], key=('_outputs__features', 'label'), datasets=[Dataset(identifier=my-valid, select=docs.select().outputs(\"features\").filter({'_fold': {'$eq': 'valid'}}))]), metric_values={}, num_workers=0, object=SVC(), preprocess=None, postprocess=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.apply(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee4cd992-fd5e-4fa7-9464-ab36cea57c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_base': '?my-model',\n",
       " '_builds': {'docs-select-outputs-features': {'_path': 'superduper_mongodb.query.parse_query',\n",
       "   'documents': [],\n",
       "   'query': 'docs.select().outputs(\"features\")'},\n",
       "  'my-trainer': {'_path': 'superduper_sklearn.model.SklearnTrainer',\n",
       "   'uuid': '4ed22cfa3a9c4175ae89b7511eda1afb',\n",
       "   'upstream': None,\n",
       "   'plugins': None,\n",
       "   'cache': False,\n",
       "   'key': ('_outputs__features', 'label'),\n",
       "   'select': '?docs-select-outputs-features',\n",
       "   'transform': None,\n",
       "   'metric_values': {},\n",
       "   'signature': '*args',\n",
       "   'data_prefetch': False,\n",
       "   'prefetch_size': 1000,\n",
       "   'prefetch_factor': 100,\n",
       "   'in_memory': True,\n",
       "   'compute_kwargs': {},\n",
       "   'fit_params': {},\n",
       "   'predict_params': {},\n",
       "   'y_preprocess': None,\n",
       "   'type_id': 'trainer',\n",
       "   'version': 0,\n",
       "   'hidden': False},\n",
       "  'dill': {'_path': 'superduper.components.datatype.get_serializer',\n",
       "   'method': 'dill',\n",
       "   'encodable': 'artifact',\n",
       "   'type_id': 'datatype',\n",
       "   'version': None,\n",
       "   'uuid': '2e98be744c274ffabc472e74bcdb8b13'},\n",
       "  '85f40a9ab4d99d2e5423f6d53af04361677af2f3': {'_path': 'superduper.components.datatype.Artifact',\n",
       "   'uuid': '9409e2db87a248ce9474ef416d2aa20e',\n",
       "   'datatype': '?dill',\n",
       "   'uri': None,\n",
       "   'blob': '&:blob:85f40a9ab4d99d2e5423f6d53af04361677af2f3'},\n",
       "  'acc': {'_path': 'superduper.components.metric.Metric',\n",
       "   'uuid': 'e83f664b7f6947cfb67947e472b7d467',\n",
       "   'upstream': None,\n",
       "   'plugins': None,\n",
       "   'cache': False,\n",
       "   'object': '?85f40a9ab4d99d2e5423f6d53af04361677af2f3',\n",
       "   'type_id': 'metric',\n",
       "   'version': 0,\n",
       "   'hidden': False},\n",
       "  'docs-select-outputs-features-filter-fold-eq-valid': {'_path': 'superduper_mongodb.query.parse_query',\n",
       "   'documents': [{'_fold': {'<$>eq': 'valid'}}],\n",
       "   'query': 'docs.select().outputs(\"features\").filter(documents[0])'},\n",
       "  'my-valid': {'_path': 'superduper.components.dataset.Dataset',\n",
       "   'uuid': 'fbfc2740aa9b4ec083b1efb5d77d485d',\n",
       "   'upstream': None,\n",
       "   'plugins': None,\n",
       "   'cache': False,\n",
       "   'select': '?docs-select-outputs-features-filter-fold-eq-valid',\n",
       "   'sample_size': None,\n",
       "   'random_seed': None,\n",
       "   'creation_date': None,\n",
       "   'raw_data': None,\n",
       "   'pin': False,\n",
       "   'type_id': 'dataset',\n",
       "   'version': 0,\n",
       "   'hidden': False},\n",
       "  'transfer_learning_performance': {'_path': 'superduper.components.model.Validation',\n",
       "   'uuid': 'b01186bf87cb49b0a6dcf86f53a660c5',\n",
       "   'upstream': None,\n",
       "   'plugins': None,\n",
       "   'cache': False,\n",
       "   'metrics': ['?acc'],\n",
       "   'key': ('_outputs__features', 'label'),\n",
       "   'datasets': ['?my-valid'],\n",
       "   'type_id': 'validation',\n",
       "   'version': 0,\n",
       "   'hidden': False},\n",
       "  'pickle': {'_path': 'superduper.components.datatype.get_serializer',\n",
       "   'method': 'pickle',\n",
       "   'encodable': 'artifact',\n",
       "   'type_id': 'datatype',\n",
       "   'version': None,\n",
       "   'uuid': '95a1bfb70864406fb45bee1f36fdac82'},\n",
       "  '11f4c3e68e30071c92163ece040096ea80e23755': {'_path': 'superduper.components.datatype.Artifact',\n",
       "   'uuid': '5000a74f7967415090381b8e0a210e95',\n",
       "   'datatype': '?pickle',\n",
       "   'uri': None,\n",
       "   'blob': '&:blob:11f4c3e68e30071c92163ece040096ea80e23755'},\n",
       "  'my-model': {'_path': 'superduper_sklearn.model.Estimator',\n",
       "   'trainer': '?my-trainer',\n",
       "   'uuid': '1e6b4f4000ac4cb8b5123e2cc944a071',\n",
       "   'upstream': None,\n",
       "   'plugins': None,\n",
       "   'cache': False,\n",
       "   'signature': 'singleton',\n",
       "   'datatype': None,\n",
       "   'output_schema': None,\n",
       "   'flatten': False,\n",
       "   'model_update_kwargs': {},\n",
       "   'predict_kwargs': {},\n",
       "   'compute_kwargs': {},\n",
       "   'validation': '?transfer_learning_performance',\n",
       "   'metric_values': {},\n",
       "   'num_workers': 0,\n",
       "   'object': '?11f4c3e68e30071c92163ece040096ea80e23755',\n",
       "   'preprocess': None,\n",
       "   'postprocess': None,\n",
       "   'type_id': 'model',\n",
       "   'version': 0,\n",
       "   'hidden': False}},\n",
       " '_blobs': {'85f40a9ab4d99d2e5423f6d53af04361677af2f3': b'\\x80\\x04\\x95\\x9b\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\ndill._dill\\x94\\x8c\\x10_create_function\\x94\\x93\\x94(h\\x00\\x8c\\x0c_create_code\\x94\\x93\\x94(C\\x02\\x02\\x01\\x94K\\x02K\\x00K\\x00K\\x02K\\x07K\\x03Cp\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x84\\x00t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00|\\x01\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00D\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00z\\x0b\\x00\\x00S\\x00\\x94Nh\\x04(C\\x00\\x94K\\x01K\\x00K\\x00K\\x03K\\x04K\\x13C \\x97\\x00g\\x00|\\x00]\\x0b\\\\\\x02\\x00\\x00}\\x01}\\x02|\\x01|\\x02k\\x02\\x00\\x00\\x00\\x00\\x91\\x02\\x8c\\x0cS\\x00\\x94))\\x8c\\x02.0\\x94\\x8c\\x02xx\\x94\\x8c\\x02yy\\x94\\x87\\x94\\x8cN/var/folders/3h/p6qzszds1c7gtbmt_2qq0tvm0000gn/T/ipykernel_89266/1161105566.py\\x94\\x8c\\n<listcomp>\\x94\\x8c\\x17acc.<locals>.<listcomp>\\x94K\\x05C \\x80\\x00\\xd0\\x0f1\\xd0\\x0f1\\xd0\\x0f1\\x99V\\x98R\\xa0\\x12\\x90\\x02\\x90b\\x92\\x08\\xd0\\x0f1\\xd0\\x0f1\\xd0\\x0f1\\x94h\\x07))t\\x94R\\x94\\x86\\x94\\x8c\\x03sum\\x94\\x8c\\x03zip\\x94\\x8c\\x03len\\x94\\x87\\x94\\x8c\\x01x\\x94\\x8c\\x01y\\x94\\x86\\x94h\\r\\x8c\\x03acc\\x94h\\x1bK\\x04C2\\x80\\x00\\xdd\\x0b\\x0e\\xd0\\x0f1\\xd0\\x0f1\\xa5s\\xa81\\xa8a\\xa1y\\xa4y\\xd0\\x0f1\\xd1\\x0f1\\xd4\\x0f1\\xd1\\x0b2\\xd4\\x0b2\\xb5S\\xb8\\x11\\xb1V\\xb4V\\xd1\\x0b;\\xd0\\x04;\\x94h\\x07))t\\x94R\\x94}\\x94\\x8c\\x08__name__\\x94\\x8c\\x08__main__\\x94sh\\x1bNNt\\x94R\\x94}\\x94}\\x94\\x8c\\x0f__annotations__\\x94}\\x94s\\x86\\x94bh\\x1f(\\x8c\\x03len\\x94\\x8c\\x08builtins\\x94\\x8c\\x03len\\x94\\x93\\x94\\x8c\\x03sum\\x94h*\\x8c\\x03sum\\x94\\x93\\x94\\x8c\\x03zip\\x94h\\x00\\x8c\\n_load_type\\x94\\x93\\x94h\\x15\\x85\\x94R\\x94u0.',\n",
       "  '11f4c3e68e30071c92163ece040096ea80e23755': b'\\x80\\x04\\x95O\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x14sklearn.svm._classes\\x94\\x8c\\x03SVC\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x17decision_function_shape\\x94\\x8c\\x03ovr\\x94\\x8c\\nbreak_ties\\x94\\x89\\x8c\\x06kernel\\x94\\x8c\\x03rbf\\x94\\x8c\\x06degree\\x94K\\x03\\x8c\\x05gamma\\x94\\x8c\\x05scale\\x94\\x8c\\x05coef0\\x94G\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x03tol\\x94G?PbM\\xd2\\xf1\\xa9\\xfc\\x8c\\x01C\\x94G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x02nu\\x94G\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x07epsilon\\x94G\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\tshrinking\\x94\\x88\\x8c\\x0bprobability\\x94\\x89\\x8c\\ncache_size\\x94K\\xc8\\x8c\\x0cclass_weight\\x94N\\x8c\\x07verbose\\x94\\x89\\x8c\\x08max_iter\\x94J\\xff\\xff\\xff\\xff\\x8c\\x0crandom_state\\x94N\\x8c\\x10_sklearn_version\\x94\\x8c\\x051.5.1\\x94ub.'},\n",
       " '_files': {}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab9838-9e5e-4402-a572-bd8339020963",
   "metadata": {},
   "source": [
    "Get the training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7478a2a-3071-4d71-9ab8-95d7d7dd3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = db.load('model', model.identifier)\n",
    "model.metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e5cd40-d5f5-4408-8f3b-857f1d4dd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduper import Template\n",
    "\n",
    "t = Template('transfer-learner', template=model, substitutions={'docs': 'table'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c5253f-7b62-4a49-bbe4-b102375e6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.export('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

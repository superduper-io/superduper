{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.2"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Multimodal vector search - Video"]}, {"cell_type": "markdown", "id": "f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6", "metadata": {}, "source": ["<!-- TABS -->\n", "## Configure your production system"]}, {"cell_type": "markdown", "id": "81e7cd59-67d0-4776-aea1-4864aa768f95", "metadata": {}, "source": [":::note\n", "If you would like to use the production features \n", "of SuperDuperDB, then you should set the relevant \n", "connections and configurations in a configuration \n", "file. Otherwise you are welcome to use \"development\" mode \n", "to get going with SuperDuperDB quickly.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "62014646-ccd4-4d10-ac26-1c470f88f2f2", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.makedirs('.superduperdb', exist_ok=True)\n", "os.environ['SUPERDUPERDB_CONFIG'] = '.superduperdb/config.yaml'"]}, {"cell_type": "code", "execution_count": null, "id": "8e50edd2-438d-44ab-9da0-0b72197df262", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Community>\n", "CFG = '''\n", "data_backend: mongodb://127.0.0.1:27017/documents\n", "artifact_store: filesystem://./artifact_store\n", "cluster:\n", "  cdc:\n", "    strategy: null\n", "    uri: ray://127.0.0.1:20000\n", "  compute:\n", "    uri: ray://127.0.0.1:10001\n", "  vector_search:\n", "    backfill_batch_size: 100\n", "    type: in_memory\n", "    uri: http://127.0.0.1:21000\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1ad9ee67-6402-45ea-8311-3efb039b5df3", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Atlas>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: native\n", "databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9c9e8351-b17f-4882-bda6-5ad51dbc7e1f", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: sqlite://<path-to-db>.db\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mysql://<user>:<password>@<host>:<port>/database\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9b7ac715-712c-4ec7-be90-0aaa22518977", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mssql://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "f21fad9c-cc0e-4cf5-83f0-41a3a614c6af", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: postgres://<user>:<password>@<host>:<port</<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1badb5a3-823c-4463-ab79-6f4f9239dabe", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: snowflake://<user>:<password>@<account>/<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "ae7807d9-9fc1-4c18-8027-a512f827783d", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: clickhouse://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "fc40c13b-9bc5-47ac-86d6-ef7a379c45ee", "metadata": {}, "outputs": [], "source": ["with open(os.environ['SUPERDUPERDB_CONFIG'], 'w') as f:\n", "    f.write(CFG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Start your cluster"]}, {"cell_type": "markdown", "metadata": {}, "source": [":::note\n", "Starting a SuperDuperDB cluster is useful in production and model development\n", "if you want to enable scalable compute, access to the models by multiple users for collaboration, \n", "monitoring.\n", "\n", "If you don't need this, then it is simpler to start in development mode.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Experimental Cluster>\n", "!python -m superduperdb local-cluster up"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Docker-Compose>\n", "!make build_sandbox\n", "!make testenv_init"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from superduperdb import superduper\n", "db = superduper('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from superduperdb import superduper\n", "\n", "user = 'superduper'\n", "password = 'superduper'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from superduperdb import superduper\n", "\n", "user = 'sa'\n", "password = 'Superduper#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = superduper(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "!pip install psycopg2\n", "from superduperdb import superduper\n", "\n", "user = 'postgres'\n", "password = 'postgres'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "db_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n", "\n", "db = superduper(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from superduperdb import superduper\n", "\n", "user = \"superduperuser\"\n", "password = \"superduperpassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = superduper(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from superduperdb import superduper\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from superduperdb import superduper\n", "\n", "db = superduper(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "1b6f7ccb", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "!curl -O https://superduperdb-public-demo.s3.amazonaws.com/videos.zip && unzip videos.zip\n", "import os\n", "\n", "data = [f'videos/{x}' for x in os.listdir('./videos')]\n", "sample_datapoint = data[-1]\n", "\n", "from superduperdb.ext.pillow import pil_image\n", "chunked_model_datatype = pil_image"]}, {"cell_type": "code", "execution_count": null, "id": "44a702b1-faf9-4edb-8a55-efc4add84a83", "metadata": {}, "outputs": [], "source": ["datas = [{'x': d} for d in data[:3]]"]}, {"cell_type": "markdown", "id": "b31257e4-06fa-4cc7-9626-bb4d03fdc029", "metadata": {}, "source": ["<!-- TABS -->\n", "## Create datatype"]}, {"cell_type": "markdown", "id": "43284218", "metadata": {}, "source": ["Data types such as \"text\" or \"integer\" which are natively support by your `db.databackend` don't need a datatype.\n", "\n", "Otherwise do one of the following:"]}, {"cell_type": "code", "execution_count": null, "id": "e844c762-3391-401d-9047-ed8617a9c946", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "from superduperdb import DataType\n", "\n", "# Create an instance of the Encoder with the identifier 'video_on_file' and load_hybrid set to False\n", "datatype = DataType(\n", "    identifier='video_on_file',\n", "    encodable='file',\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Setup tables or collections"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from superduperdb.components.table import Table\n", "from superduperdb import Schema\n", "\n", "schema = Schema(identifier=\"schema\", fields={\"x\": datatype})\n", "table_or_collection = Table(\"documents\", schema=schema)\n", "db.apply(table_or_collection)"]}, {"cell_type": "markdown", "id": "a947c52e-919e-4440-b1d6-914e690314d4", "metadata": {}, "source": ["Inserting data, all fields will be matched with the schema for data conversion."]}, {"cell_type": "code", "execution_count": null, "id": "afead32f-fc4c-4b11-9d31-d38bf061c232", "metadata": {}, "outputs": [], "source": ["db['documents'].insert(datas).execute()\n", "select = db['documents'].select()"]}, {"cell_type": "markdown", "id": "54fea927-ee4a-44cd-aaf2-634b574c316d", "metadata": {}, "source": ["<!-- TABS -->\n", "## Apply a chunker for search"]}, {"cell_type": "markdown", "id": "06d90bda-e8c4-494e-a38c-837fb63689ae", "metadata": {}, "source": [":::note\n", "Note that applying a chunker is ***not*** mandatory for search.\n", "If your data is already chunked (e.g. short text snippets or audio) or if you\n", "are searching through something like images, which can't be chunked, then this\n", "won't be necessary.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "f093a6d0-9d2f-4ecf-b1bd-0027302c62de", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "!pip install opencv-python\n", "import cv2\n", "import tqdm\n", "from PIL import Image\n", "from superduperdb.ext.pillow import pil_image\n", "from superduperdb import objectmodel, Schema\n", "\n", "\n", "@objectmodel(\n", "    flatten=True,\n", "    model_update_kwargs={'document_embedded': False},\n", ")\n", "def chunker(video_file):\n", "    # Set the sampling frequency for frames\n", "    sample_freq = 10\n", "    \n", "    # Open the video file using OpenCV\n", "    cap = cv2.VideoCapture(video_file)\n", "    \n", "    # Initialize variables\n", "    frame_count = 0\n", "    fps = cap.get(cv2.CAP_PROP_FPS)\n", "    extracted_frames = []\n", "    progress = tqdm.tqdm()\n", "\n", "    # Iterate through video frames\n", "    while True:\n", "        ret, frame = cap.read()\n", "        if not ret:\n", "            break\n", "        \n", "        # Get the current timestamp based on frame count and FPS\n", "        current_timestamp = frame_count // fps\n", "        \n", "        # Sample frames based on the specified frequency\n", "        if frame_count % sample_freq == 0:\n", "            extracted_frames.append({\n", "                'image': Image.fromarray(frame[:,:,::-1]),  # Convert BGR to RGB\n", "                'current_timestamp': current_timestamp,\n", "            })\n", "        frame_count += 1\n", "        progress.update(1)\n", "    \n", "    # Release resources\n", "    cap.release()\n", "    cv2.destroyAllWindows()\n", "    \n", "    # Return the list of extracted frames\n", "    return extracted_frames"]}, {"cell_type": "markdown", "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f", "metadata": {}, "source": ["Now we apply this chunker to the data by wrapping the chunker in `Listener`:"]}, {"cell_type": "code", "execution_count": null, "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3", "metadata": {}, "outputs": [], "source": ["from superduperdb import Listener\n", "\n", "upstream_listener = Listener(\n", "    model=chunker,\n", "    select=select,\n", "    key='x',\n", "    uuid=\"chunk\",\n", ")\n", "\n", "db.apply(upstream_listener)"]}, {"cell_type": "markdown", "id": "907721f8-d5bf-4623-8871-3ab9a05001d7", "metadata": {}, "source": ["## Build multimodal embedding models"]}, {"cell_type": "markdown", "id": "033e1eaf-2cdb-499a-ba83-cf080a1a6fda", "metadata": {}, "source": ["We define the output data type of a model as a vector for vector transformation."]}, {"cell_type": "code", "execution_count": null, "id": "28848ff1-45ab-4926-8676-777edf237347", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb.components.vector_index import vector\n", "output_datatpye = vector(shape=(1024,))"]}, {"cell_type": "code", "execution_count": null, "id": "6acf66c5-7369-4aa8-a8a0-5842bd17b469", "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from superduperdb.components.vector_index import sqlvector\n", "output_datatpye = sqlvector(shape=(1024,))"]}, {"cell_type": "markdown", "id": "143bf946-64b7-4452-8d20-44f2f9ae3fd6", "metadata": {}, "source": ["Then define two models, one for text embedding and one for image embedding."]}, {"cell_type": "code", "execution_count": null, "id": "f33513d3-9f86-4108-8f8b-4a6251bdd9fd", "metadata": {}, "outputs": [], "source": ["# <tab: Text-Image>\n", "!pip install git+https://github.com/openai/CLIP.git\n", "import clip\n", "from superduperdb import vector\n", "from superduperdb.ext.torch import TorchModel\n", "\n", "# Load the CLIP model and obtain the preprocessing function\n", "model, preprocess = clip.load(\"ViT-B/32\", device='cpu')\n", "\n", "# Create a TorchModel for text encoding\n", "compatible_model = TorchModel(\n", "    identifier='clip_text', # Unique identifier for the model\n", "    object=model, # CLIP model\n", "    preprocess=lambda x: clip.tokenize(x)[0],  # Model input preprocessing using CLIP \n", "    postprocess=lambda x: x.tolist(), # Convert the model output to a list\n", "    datatype=output_datatpye,  # Vector encoder with shape (1024,)\n", "    forward_method='encode_text', # Use the 'encode_text' method for forward pass \n", ")\n", "\n", "# Create a TorchModel for visual encoding\n", "model = TorchModel(\n", "    identifier='clip_image',  # Unique identifier for the model\n", "    object=model.visual,  # Visual part of the CLIP model    \n", "    preprocess=preprocess, # Visual preprocessing using CLIP\n", "    postprocess=lambda x: x.tolist(), # Convert the output to a list \n", "    datatype=output_datatpye, # Vector encoder with shape (1024,)\n", ")"]}, {"cell_type": "markdown", "id": "3d0119da-9cfd-4a60-8847-c3bfdf37697f", "metadata": {}, "source": ["Because we use multimodal models, we define different keys to specify which model to use for embedding calculations in the vector_index."]}, {"cell_type": "code", "execution_count": null, "id": "12e75fab-8504-4d17-a7d9-f98667a5d6aa", "metadata": {}, "outputs": [], "source": ["compatible_key = 'text' # we use text key for text embedding\n", "indexing_key = upstream_listener.outputs_key + '.image' # we use indexing_key for image embedding, use the image field of the result\n", "select = upstream_listener.outputs_select"]}, {"cell_type": "markdown", "id": "41b8b40d-3750-4d7b-aa60-62e07b734b04", "metadata": {}, "source": ["## Create vector-index"]}, {"cell_type": "code", "execution_count": null, "id": "66ee3ff4-880e-477b-bbdf-5b8d89c56de2", "metadata": {}, "outputs": [], "source": ["vector_index_name = 'my-vector-index'"]}, {"cell_type": "code", "execution_count": null, "id": "4cede653", "metadata": {}, "outputs": [], "source": ["# <tab: 2-Modalities>\n", "from superduperdb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        ),\n", "        compatible_listener=Listener(\n", "            key=compatible_key,      # the `Document` key `model` should ingest to create embedding\n", "            model=compatible_model,         # a `_Predictor` how to convert data to embeddings\n", "            active=False,\n", "            select=None,\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "067a1203-8dbc-4d0a-aa4a-705d99902d52", "metadata": {}, "outputs": [], "source": ["query_table_or_collection = select.table_or_collection"]}, {"cell_type": "markdown", "id": "b8a87f9d-581a-419a-81b8-a743250413e9", "metadata": {}, "source": ["## Perform a vector search\n", "\n", "We can perform the vector searches using text description:"]}, {"cell_type": "code", "execution_count": null, "id": "ce565823-4655-488c-8684-2240107fa30d", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "from superduperdb import Document\n", "item = Document({compatible_key: \"The moment of a soccer shot\"})"]}, {"cell_type": "markdown", "id": "fc3ba07d-1124-4d94-a117-60d2e72581f7", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows."]}, {"cell_type": "code", "execution_count": null, "id": "a061de0b-2694-4b36-844c-7753a465360f", "metadata": {}, "outputs": [], "source": ["select = query_table_or_collection.like(item, vector_index=vector_index_name, n=5).select()\n", "results = list(db.execute(select))"]}, {"cell_type": "markdown", "id": "9b6d9af9-a012-42bd-aad4-31b92d089caa", "metadata": {}, "source": ["## Visualize Results"]}, {"cell_type": "code", "execution_count": null, "id": "9e2ecea5-3a58-457c-ac50-ddc742484f2d", "metadata": {}, "outputs": [], "source": ["from IPython.display import display\n", "for result in results:\n", "    display(Document(result.unpack())[indexing_key])"]}, {"cell_type": "markdown", "id": "693b4878-39a2-444d-8e17-72a00e6c246d", "metadata": {}, "source": ["## Check the system stays updated\n", "\n", "You can add new data; once the data is added, all related models will perform calculations according to the underlying constructed model and listener, simultaneously updating the vector index to ensure that each query uses the latest data."]}, {"cell_type": "code", "execution_count": null, "id": "5ef97f5a-bb41-46ca-a85e-489824741216", "metadata": {}, "outputs": [], "source": ["new_datas = [{'x': data[-1]}]\n", "ids = db['documents'].insert(new_datas).execute()"]}]}